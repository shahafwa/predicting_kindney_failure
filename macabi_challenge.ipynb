{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "macabi_challenge.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCMfUh_9q3mS"
      },
      "source": [
        "# Risk of acute renal - Made by Shahaf Wagner"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dlF9e2JLVA6"
      },
      "source": [
        "# Install Captum if no already installed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQOynkIxhbYx"
      },
      "source": [
        "# !pip install captum #install captum in case you don't have it, just uncomment this row"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7PI0pCxLcbY"
      },
      "source": [
        "# import everything we need"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-hWJdg3KQ1z"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "from sklearn.impute import IterativeImputer, SimpleImputer\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader,TensorDataset,random_split,SubsetRandomSampler, ConcatDataset\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import StratifiedKFold, KFold\n",
        "\n",
        "from captum.attr import IntegratedGradients\n",
        "from captum.attr import LayerConductance\n",
        "from captum.attr import NeuronConductance"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XB1zX1HFrDgm"
      },
      "source": [
        "Create labels for timeframe of the acute renal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "F_edpiH3hrI7",
        "outputId": "c41b491c-516e-4a44-a66c-ecb7ff5d2a58"
      },
      "source": [
        "full_data = pd.read_csv('diab_ckd_data.csv')\n",
        "\n",
        "def conditions(df):\n",
        "    if (df['EVENT_CRF'] == 1) and (df['TIME_CRF'] <= 2):\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "full_data['2_years'] = np.where( ( (full_data['EVENT_CRF'] == 1) & (full_data['TIME_CRF'] <=2 ) ) , 1, 0)\n",
        "full_data['5_years'] = np.where( ( (full_data['EVENT_CRF'] == 1) & (full_data['TIME_CRF'] <=5 ) ) , 1, 0)\n",
        "full_data['10_years'] = np.where( ( (full_data['EVENT_CRF'] == 1) & (full_data['TIME_CRF'] <=10 ) ) , 1, 0)\n",
        "\n",
        "full_data = full_data[full_data['2_years'].notna()]\n",
        "full_data = full_data[full_data['5_years'].notna()]\n",
        "full_data = full_data[full_data['10_years'].notna()]\n",
        "\n",
        "full_data = full_data.drop(['TIME_CRF'],axis=1)\n",
        "full_data = full_data.drop(['EVENT_CRF'],axis=1)\n",
        "\n",
        "full_data.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>IDS</th>\n",
              "      <th>IS_MALE</th>\n",
              "      <th>AGE_AT_SDATE</th>\n",
              "      <th>AGE_GROUP</th>\n",
              "      <th>SES_GROUP</th>\n",
              "      <th>MIGZAR</th>\n",
              "      <th>IS_HYPERTENSION</th>\n",
              "      <th>SE_HYPERTENSION</th>\n",
              "      <th>IS_ISCHEMIC_MI</th>\n",
              "      <th>SE_ISCHEMIC_MI</th>\n",
              "      <th>IS_CVA_TIA</th>\n",
              "      <th>SE_CVA_TIA</th>\n",
              "      <th>IS_DEMENTIA</th>\n",
              "      <th>SE_DEMENTIA</th>\n",
              "      <th>IS_ART_SCLE_GEN</th>\n",
              "      <th>SE_ART_SCLE_GEN</th>\n",
              "      <th>IS_TROMBOPHILIA</th>\n",
              "      <th>SE_TROMBOPHILIA</th>\n",
              "      <th>IS_IBD</th>\n",
              "      <th>SE_IBD</th>\n",
              "      <th>BMI_AT_BASELINE</th>\n",
              "      <th>SYSTOLA_AT_BASELINE</th>\n",
              "      <th>DIASTOLA_AT_BASELINE</th>\n",
              "      <th>Creatinine_B_AT_BASELINE</th>\n",
              "      <th>Albumin_B_AT_BASELINE</th>\n",
              "      <th>Urea_B_AT_BASELINE</th>\n",
              "      <th>Glucose_B_AT_BASELINE</th>\n",
              "      <th>HbA1C_AT_BASELINE</th>\n",
              "      <th>RBCRed_Blood_Cells_AT_BASELINE</th>\n",
              "      <th>Hemoglobin_AT_BASELINE</th>\n",
              "      <th>Ferritin_AT_BASELINE</th>\n",
              "      <th>AST_GOT_AT_BASELINE</th>\n",
              "      <th>ALT_GPT_AT_BASELINE</th>\n",
              "      <th>Bilirubin_Total_AT_BASELINE</th>\n",
              "      <th>Na_Sodium_B_AT_BASELINE</th>\n",
              "      <th>K_Potassium_B_AT_BASELINE</th>\n",
              "      <th>CaCalcium_B_AT_BASELINE</th>\n",
              "      <th>HDLCholesterol_AT_BASELINE</th>\n",
              "      <th>LDLCholesterol_AT_BASELINE</th>\n",
              "      <th>Triglycerides_AT_BASELINE</th>\n",
              "      <th>PTH_AT_BASELINE</th>\n",
              "      <th>2_years</th>\n",
              "      <th>5_years</th>\n",
              "      <th>10_years</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>122931</td>\n",
              "      <td>0</td>\n",
              "      <td>72.97</td>\n",
              "      <td>[60, 75)</td>\n",
              "      <td>HI</td>\n",
              "      <td>GENERAL</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>19.89</td>\n",
              "      <td>122.0</td>\n",
              "      <td>65.5</td>\n",
              "      <td>1.30</td>\n",
              "      <td>3.9</td>\n",
              "      <td>71.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9.55</td>\n",
              "      <td>3.87</td>\n",
              "      <td>11.70</td>\n",
              "      <td>NaN</td>\n",
              "      <td>34.0</td>\n",
              "      <td>22.2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>138.5</td>\n",
              "      <td>4.60</td>\n",
              "      <td>9.25</td>\n",
              "      <td>31.80</td>\n",
              "      <td>69.0</td>\n",
              "      <td>271.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>98909</td>\n",
              "      <td>0</td>\n",
              "      <td>70.30</td>\n",
              "      <td>[60, 75)</td>\n",
              "      <td>MID</td>\n",
              "      <td>GENERAL</td>\n",
              "      <td>1</td>\n",
              "      <td>6.85</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>41.23</td>\n",
              "      <td>150.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>0.90</td>\n",
              "      <td>NaN</td>\n",
              "      <td>33.5</td>\n",
              "      <td>162.5</td>\n",
              "      <td>7.20</td>\n",
              "      <td>4.96</td>\n",
              "      <td>12.70</td>\n",
              "      <td>NaN</td>\n",
              "      <td>22.5</td>\n",
              "      <td>24.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>136.5</td>\n",
              "      <td>4.45</td>\n",
              "      <td>NaN</td>\n",
              "      <td>62.60</td>\n",
              "      <td>116.7</td>\n",
              "      <td>114.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>65611</td>\n",
              "      <td>0</td>\n",
              "      <td>53.46</td>\n",
              "      <td>[45, 60)</td>\n",
              "      <td>MID</td>\n",
              "      <td>HAREDI</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>137.0</td>\n",
              "      <td>7.85</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>54.00</td>\n",
              "      <td>136.8</td>\n",
              "      <td>81.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>95847</td>\n",
              "      <td>0</td>\n",
              "      <td>81.75</td>\n",
              "      <td>[75, 120)</td>\n",
              "      <td>MID</td>\n",
              "      <td>GENERAL</td>\n",
              "      <td>1</td>\n",
              "      <td>5.18</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>130.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>0.85</td>\n",
              "      <td>NaN</td>\n",
              "      <td>35.0</td>\n",
              "      <td>153.0</td>\n",
              "      <td>7.20</td>\n",
              "      <td>5.07</td>\n",
              "      <td>14.50</td>\n",
              "      <td>NaN</td>\n",
              "      <td>106.0</td>\n",
              "      <td>132.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>140.0</td>\n",
              "      <td>4.70</td>\n",
              "      <td>NaN</td>\n",
              "      <td>41.15</td>\n",
              "      <td>139.2</td>\n",
              "      <td>233.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>91914</td>\n",
              "      <td>1</td>\n",
              "      <td>85.35</td>\n",
              "      <td>[75, 120)</td>\n",
              "      <td>HI</td>\n",
              "      <td>GENERAL</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>24.45</td>\n",
              "      <td>122.5</td>\n",
              "      <td>73.0</td>\n",
              "      <td>0.74</td>\n",
              "      <td>4.5</td>\n",
              "      <td>50.5</td>\n",
              "      <td>117.5</td>\n",
              "      <td>6.70</td>\n",
              "      <td>4.74</td>\n",
              "      <td>14.65</td>\n",
              "      <td>184.5</td>\n",
              "      <td>21.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>1.1</td>\n",
              "      <td>137.0</td>\n",
              "      <td>4.25</td>\n",
              "      <td>8.90</td>\n",
              "      <td>64.00</td>\n",
              "      <td>148.8</td>\n",
              "      <td>81.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      IDS  IS_MALE  AGE_AT_SDATE  ... 2_years 5_years 10_years\n",
              "0  122931        0         72.97  ...       1       1        1\n",
              "1   98909        0         70.30  ...       0       0        0\n",
              "2   65611        0         53.46  ...       0       0        0\n",
              "3   95847        0         81.75  ...       0       0        0\n",
              "4   91914        1         85.35  ...       0       0        0\n",
              "\n",
              "[5 rows x 44 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQBBVhkPrJRV"
      },
      "source": [
        "Check amount of missing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exz8ZrFahvDt",
        "outputId": "009eac3c-e27e-4a82-829e-ae27c7e14eba"
      },
      "source": [
        "print(full_data.notnull().sum())\n",
        "print(\"\\nMissing Data:\\n\")\n",
        "print(full_data.isnull().sum())"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "IDS                               135475\n",
            "IS_MALE                           135475\n",
            "AGE_AT_SDATE                      135475\n",
            "AGE_GROUP                         135475\n",
            "SES_GROUP                         135475\n",
            "MIGZAR                            135475\n",
            "IS_HYPERTENSION                   135475\n",
            "SE_HYPERTENSION                    50946\n",
            "IS_ISCHEMIC_MI                    135475\n",
            "SE_ISCHEMIC_MI                      4733\n",
            "IS_CVA_TIA                        135475\n",
            "SE_CVA_TIA                          1531\n",
            "IS_DEMENTIA                       135475\n",
            "SE_DEMENTIA                          709\n",
            "IS_ART_SCLE_GEN                   135475\n",
            "SE_ART_SCLE_GEN                     1523\n",
            "IS_TROMBOPHILIA                   135475\n",
            "SE_TROMBOPHILIA                     2501\n",
            "IS_IBD                            135475\n",
            "SE_IBD                               737\n",
            "BMI_AT_BASELINE                    85150\n",
            "SYSTOLA_AT_BASELINE               113904\n",
            "DIASTOLA_AT_BASELINE              113904\n",
            "Creatinine_B_AT_BASELINE          123659\n",
            "Albumin_B_AT_BASELINE              83345\n",
            "Urea_B_AT_BASELINE                117540\n",
            "Glucose_B_AT_BASELINE             124844\n",
            "HbA1C_AT_BASELINE                 118421\n",
            "RBCRed_Blood_Cells_AT_BASELINE    120605\n",
            "Hemoglobin_AT_BASELINE            120558\n",
            "Ferritin_AT_BASELINE               36863\n",
            "AST_GOT_AT_BASELINE                94911\n",
            "ALT_GPT_AT_BASELINE               118531\n",
            "Bilirubin_Total_AT_BASELINE        65183\n",
            "Na_Sodium_B_AT_BASELINE           112035\n",
            "K_Potassium_B_AT_BASELINE         113268\n",
            "CaCalcium_B_AT_BASELINE            88694\n",
            "HDLCholesterol_AT_BASELINE        123146\n",
            "LDLCholesterol_AT_BASELINE        117107\n",
            "Triglycerides_AT_BASELINE         123727\n",
            "PTH_AT_BASELINE                     3934\n",
            "2_years                           135475\n",
            "5_years                           135475\n",
            "10_years                          135475\n",
            "dtype: int64\n",
            "\n",
            "Missing Data:\n",
            "\n",
            "IDS                                    0\n",
            "IS_MALE                                0\n",
            "AGE_AT_SDATE                           0\n",
            "AGE_GROUP                              0\n",
            "SES_GROUP                              0\n",
            "MIGZAR                                 0\n",
            "IS_HYPERTENSION                        0\n",
            "SE_HYPERTENSION                    84529\n",
            "IS_ISCHEMIC_MI                         0\n",
            "SE_ISCHEMIC_MI                    130742\n",
            "IS_CVA_TIA                             0\n",
            "SE_CVA_TIA                        133944\n",
            "IS_DEMENTIA                            0\n",
            "SE_DEMENTIA                       134766\n",
            "IS_ART_SCLE_GEN                        0\n",
            "SE_ART_SCLE_GEN                   133952\n",
            "IS_TROMBOPHILIA                        0\n",
            "SE_TROMBOPHILIA                   132974\n",
            "IS_IBD                                 0\n",
            "SE_IBD                            134738\n",
            "BMI_AT_BASELINE                    50325\n",
            "SYSTOLA_AT_BASELINE                21571\n",
            "DIASTOLA_AT_BASELINE               21571\n",
            "Creatinine_B_AT_BASELINE           11816\n",
            "Albumin_B_AT_BASELINE              52130\n",
            "Urea_B_AT_BASELINE                 17935\n",
            "Glucose_B_AT_BASELINE              10631\n",
            "HbA1C_AT_BASELINE                  17054\n",
            "RBCRed_Blood_Cells_AT_BASELINE     14870\n",
            "Hemoglobin_AT_BASELINE             14917\n",
            "Ferritin_AT_BASELINE               98612\n",
            "AST_GOT_AT_BASELINE                40564\n",
            "ALT_GPT_AT_BASELINE                16944\n",
            "Bilirubin_Total_AT_BASELINE        70292\n",
            "Na_Sodium_B_AT_BASELINE            23440\n",
            "K_Potassium_B_AT_BASELINE          22207\n",
            "CaCalcium_B_AT_BASELINE            46781\n",
            "HDLCholesterol_AT_BASELINE         12329\n",
            "LDLCholesterol_AT_BASELINE         18368\n",
            "Triglycerides_AT_BASELINE          11748\n",
            "PTH_AT_BASELINE                   131541\n",
            "2_years                                0\n",
            "5_years                                0\n",
            "10_years                               0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBXT7SW3osyU"
      },
      "source": [
        "Many parts of the data are completely missing, so we better drop them"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "tCxb-tyqjbx9",
        "outputId": "99ce97f4-e504-4b90-98fe-2311cd822dd2"
      },
      "source": [
        "for column in full_data:\n",
        "  if full_data.isnull().sum()[column] > len(full_data)*0.4:\n",
        "    full_data = full_data.drop([column],axis=1)\n",
        "full_data.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>IDS</th>\n",
              "      <th>IS_MALE</th>\n",
              "      <th>AGE_AT_SDATE</th>\n",
              "      <th>AGE_GROUP</th>\n",
              "      <th>SES_GROUP</th>\n",
              "      <th>MIGZAR</th>\n",
              "      <th>IS_HYPERTENSION</th>\n",
              "      <th>IS_ISCHEMIC_MI</th>\n",
              "      <th>IS_CVA_TIA</th>\n",
              "      <th>IS_DEMENTIA</th>\n",
              "      <th>IS_ART_SCLE_GEN</th>\n",
              "      <th>IS_TROMBOPHILIA</th>\n",
              "      <th>IS_IBD</th>\n",
              "      <th>BMI_AT_BASELINE</th>\n",
              "      <th>SYSTOLA_AT_BASELINE</th>\n",
              "      <th>DIASTOLA_AT_BASELINE</th>\n",
              "      <th>Creatinine_B_AT_BASELINE</th>\n",
              "      <th>Albumin_B_AT_BASELINE</th>\n",
              "      <th>Urea_B_AT_BASELINE</th>\n",
              "      <th>Glucose_B_AT_BASELINE</th>\n",
              "      <th>HbA1C_AT_BASELINE</th>\n",
              "      <th>RBCRed_Blood_Cells_AT_BASELINE</th>\n",
              "      <th>Hemoglobin_AT_BASELINE</th>\n",
              "      <th>AST_GOT_AT_BASELINE</th>\n",
              "      <th>ALT_GPT_AT_BASELINE</th>\n",
              "      <th>Na_Sodium_B_AT_BASELINE</th>\n",
              "      <th>K_Potassium_B_AT_BASELINE</th>\n",
              "      <th>CaCalcium_B_AT_BASELINE</th>\n",
              "      <th>HDLCholesterol_AT_BASELINE</th>\n",
              "      <th>LDLCholesterol_AT_BASELINE</th>\n",
              "      <th>Triglycerides_AT_BASELINE</th>\n",
              "      <th>2_years</th>\n",
              "      <th>5_years</th>\n",
              "      <th>10_years</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>122931</td>\n",
              "      <td>0</td>\n",
              "      <td>72.97</td>\n",
              "      <td>[60, 75)</td>\n",
              "      <td>HI</td>\n",
              "      <td>GENERAL</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>19.89</td>\n",
              "      <td>122.0</td>\n",
              "      <td>65.5</td>\n",
              "      <td>1.30</td>\n",
              "      <td>3.9</td>\n",
              "      <td>71.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9.55</td>\n",
              "      <td>3.87</td>\n",
              "      <td>11.70</td>\n",
              "      <td>34.0</td>\n",
              "      <td>22.2</td>\n",
              "      <td>138.5</td>\n",
              "      <td>4.60</td>\n",
              "      <td>9.25</td>\n",
              "      <td>31.80</td>\n",
              "      <td>69.0</td>\n",
              "      <td>271.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>98909</td>\n",
              "      <td>0</td>\n",
              "      <td>70.30</td>\n",
              "      <td>[60, 75)</td>\n",
              "      <td>MID</td>\n",
              "      <td>GENERAL</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>41.23</td>\n",
              "      <td>150.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>0.90</td>\n",
              "      <td>NaN</td>\n",
              "      <td>33.5</td>\n",
              "      <td>162.5</td>\n",
              "      <td>7.20</td>\n",
              "      <td>4.96</td>\n",
              "      <td>12.70</td>\n",
              "      <td>22.5</td>\n",
              "      <td>24.5</td>\n",
              "      <td>136.5</td>\n",
              "      <td>4.45</td>\n",
              "      <td>NaN</td>\n",
              "      <td>62.60</td>\n",
              "      <td>116.7</td>\n",
              "      <td>114.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>65611</td>\n",
              "      <td>0</td>\n",
              "      <td>53.46</td>\n",
              "      <td>[45, 60)</td>\n",
              "      <td>MID</td>\n",
              "      <td>HAREDI</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>137.0</td>\n",
              "      <td>7.85</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>54.00</td>\n",
              "      <td>136.8</td>\n",
              "      <td>81.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>95847</td>\n",
              "      <td>0</td>\n",
              "      <td>81.75</td>\n",
              "      <td>[75, 120)</td>\n",
              "      <td>MID</td>\n",
              "      <td>GENERAL</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>130.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>0.85</td>\n",
              "      <td>NaN</td>\n",
              "      <td>35.0</td>\n",
              "      <td>153.0</td>\n",
              "      <td>7.20</td>\n",
              "      <td>5.07</td>\n",
              "      <td>14.50</td>\n",
              "      <td>106.0</td>\n",
              "      <td>132.0</td>\n",
              "      <td>140.0</td>\n",
              "      <td>4.70</td>\n",
              "      <td>NaN</td>\n",
              "      <td>41.15</td>\n",
              "      <td>139.2</td>\n",
              "      <td>233.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>91914</td>\n",
              "      <td>1</td>\n",
              "      <td>85.35</td>\n",
              "      <td>[75, 120)</td>\n",
              "      <td>HI</td>\n",
              "      <td>GENERAL</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24.45</td>\n",
              "      <td>122.5</td>\n",
              "      <td>73.0</td>\n",
              "      <td>0.74</td>\n",
              "      <td>4.5</td>\n",
              "      <td>50.5</td>\n",
              "      <td>117.5</td>\n",
              "      <td>6.70</td>\n",
              "      <td>4.74</td>\n",
              "      <td>14.65</td>\n",
              "      <td>21.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>137.0</td>\n",
              "      <td>4.25</td>\n",
              "      <td>8.90</td>\n",
              "      <td>64.00</td>\n",
              "      <td>148.8</td>\n",
              "      <td>81.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      IDS  IS_MALE  AGE_AT_SDATE  ... 2_years 5_years 10_years\n",
              "0  122931        0         72.97  ...       1       1        1\n",
              "1   98909        0         70.30  ...       0       0        0\n",
              "2   65611        0         53.46  ...       0       0        0\n",
              "3   95847        0         81.75  ...       0       0        0\n",
              "4   91914        1         85.35  ...       0       0        0\n",
              "\n",
              "[5 rows x 34 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxOWB1xvrNng"
      },
      "source": [
        "Split between numerical data and non numerical one"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiTQ7gPxr_L1"
      },
      "source": [
        "cats = full_data.select_dtypes(include=[\"object\"])\n",
        "nums = full_data.select_dtypes(exclude=[\"object\"])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMZ0ClVGslez",
        "outputId": "c9afc7ec-36c2-483c-99fa-2f3d85df6f18"
      },
      "source": [
        "for a in cats.columns:\n",
        "  print(a)\n",
        "  print(full_data[a].nunique())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AGE_GROUP\n",
            "5\n",
            "SES_GROUP\n",
            "4\n",
            "MIGZAR\n",
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjPMkQ3irRq1"
      },
      "source": [
        "Create encoding for categorial data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhN-4veAz33V",
        "outputId": "a3a63865-6f9a-4bd6-940b-57191be5c5a9"
      },
      "source": [
        "datanew = full_data.copy()\n",
        "encoder = OrdinalEncoder()\n",
        "cat_cols = cats.columns\n",
        "num_cols = nums.columns\n",
        "#This function will encode non-null data and replace it in the original data\n",
        "def encode(data):\n",
        "    '''function to encode non-null data and replace it in the original data'''\n",
        "    #retains only non-null values\n",
        "    nonulls = np.array(data.dropna())\n",
        "    #reshapes the data for encoding\n",
        "    impute_reshape = nonulls.reshape(-1,1)\n",
        "    #encode date\n",
        "    impute_ordinal = encoder.fit_transform(impute_reshape)\n",
        "    #Assign back encoded values to non-null values\n",
        "    data.loc[data.notnull()] = np.squeeze(impute_ordinal)\n",
        "    return data\n",
        "\n",
        "#create a for loop to iterate through each column in the data\n",
        "for columns in cat_cols:\n",
        "    data = encode(datanew[columns])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  iloc._setitem_with_indexer(indexer, value)\n",
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  iloc._setitem_with_indexer(indexer, value)\n",
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  iloc._setitem_with_indexer(indexer, value)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "s1l7OsC30_px",
        "outputId": "7aeced62-53a2-4db7-bc52-4d0fe3389a59"
      },
      "source": [
        "datanew.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>IDS</th>\n",
              "      <th>IS_MALE</th>\n",
              "      <th>AGE_AT_SDATE</th>\n",
              "      <th>AGE_GROUP</th>\n",
              "      <th>SES_GROUP</th>\n",
              "      <th>MIGZAR</th>\n",
              "      <th>IS_HYPERTENSION</th>\n",
              "      <th>IS_ISCHEMIC_MI</th>\n",
              "      <th>IS_CVA_TIA</th>\n",
              "      <th>IS_DEMENTIA</th>\n",
              "      <th>IS_ART_SCLE_GEN</th>\n",
              "      <th>IS_TROMBOPHILIA</th>\n",
              "      <th>IS_IBD</th>\n",
              "      <th>BMI_AT_BASELINE</th>\n",
              "      <th>SYSTOLA_AT_BASELINE</th>\n",
              "      <th>DIASTOLA_AT_BASELINE</th>\n",
              "      <th>Creatinine_B_AT_BASELINE</th>\n",
              "      <th>Albumin_B_AT_BASELINE</th>\n",
              "      <th>Urea_B_AT_BASELINE</th>\n",
              "      <th>Glucose_B_AT_BASELINE</th>\n",
              "      <th>HbA1C_AT_BASELINE</th>\n",
              "      <th>RBCRed_Blood_Cells_AT_BASELINE</th>\n",
              "      <th>Hemoglobin_AT_BASELINE</th>\n",
              "      <th>AST_GOT_AT_BASELINE</th>\n",
              "      <th>ALT_GPT_AT_BASELINE</th>\n",
              "      <th>Na_Sodium_B_AT_BASELINE</th>\n",
              "      <th>K_Potassium_B_AT_BASELINE</th>\n",
              "      <th>CaCalcium_B_AT_BASELINE</th>\n",
              "      <th>HDLCholesterol_AT_BASELINE</th>\n",
              "      <th>LDLCholesterol_AT_BASELINE</th>\n",
              "      <th>Triglycerides_AT_BASELINE</th>\n",
              "      <th>2_years</th>\n",
              "      <th>5_years</th>\n",
              "      <th>10_years</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>122931</td>\n",
              "      <td>0</td>\n",
              "      <td>72.97</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>19.89</td>\n",
              "      <td>122.0</td>\n",
              "      <td>65.5</td>\n",
              "      <td>1.30</td>\n",
              "      <td>3.9</td>\n",
              "      <td>71.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9.55</td>\n",
              "      <td>3.87</td>\n",
              "      <td>11.70</td>\n",
              "      <td>34.0</td>\n",
              "      <td>22.2</td>\n",
              "      <td>138.5</td>\n",
              "      <td>4.60</td>\n",
              "      <td>9.25</td>\n",
              "      <td>31.80</td>\n",
              "      <td>69.0</td>\n",
              "      <td>271.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>98909</td>\n",
              "      <td>0</td>\n",
              "      <td>70.30</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>41.23</td>\n",
              "      <td>150.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>0.90</td>\n",
              "      <td>NaN</td>\n",
              "      <td>33.5</td>\n",
              "      <td>162.5</td>\n",
              "      <td>7.20</td>\n",
              "      <td>4.96</td>\n",
              "      <td>12.70</td>\n",
              "      <td>22.5</td>\n",
              "      <td>24.5</td>\n",
              "      <td>136.5</td>\n",
              "      <td>4.45</td>\n",
              "      <td>NaN</td>\n",
              "      <td>62.60</td>\n",
              "      <td>116.7</td>\n",
              "      <td>114.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>65611</td>\n",
              "      <td>0</td>\n",
              "      <td>53.46</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>137.0</td>\n",
              "      <td>7.85</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>54.00</td>\n",
              "      <td>136.8</td>\n",
              "      <td>81.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>95847</td>\n",
              "      <td>0</td>\n",
              "      <td>81.75</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>130.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>0.85</td>\n",
              "      <td>NaN</td>\n",
              "      <td>35.0</td>\n",
              "      <td>153.0</td>\n",
              "      <td>7.20</td>\n",
              "      <td>5.07</td>\n",
              "      <td>14.50</td>\n",
              "      <td>106.0</td>\n",
              "      <td>132.0</td>\n",
              "      <td>140.0</td>\n",
              "      <td>4.70</td>\n",
              "      <td>NaN</td>\n",
              "      <td>41.15</td>\n",
              "      <td>139.2</td>\n",
              "      <td>233.5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>91914</td>\n",
              "      <td>1</td>\n",
              "      <td>85.35</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>24.45</td>\n",
              "      <td>122.5</td>\n",
              "      <td>73.0</td>\n",
              "      <td>0.74</td>\n",
              "      <td>4.5</td>\n",
              "      <td>50.5</td>\n",
              "      <td>117.5</td>\n",
              "      <td>6.70</td>\n",
              "      <td>4.74</td>\n",
              "      <td>14.65</td>\n",
              "      <td>21.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>137.0</td>\n",
              "      <td>4.25</td>\n",
              "      <td>8.90</td>\n",
              "      <td>64.00</td>\n",
              "      <td>148.8</td>\n",
              "      <td>81.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      IDS  IS_MALE  AGE_AT_SDATE  ...  2_years  5_years  10_years\n",
              "0  122931        0         72.97  ...        1        1         1\n",
              "1   98909        0         70.30  ...        0        0         0\n",
              "2   65611        0         53.46  ...        0        0         0\n",
              "3   95847        0         81.75  ...        0        0         0\n",
              "4   91914        1         85.35  ...        0        0         0\n",
              "\n",
              "[5 rows x 34 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eqisq5DrUok"
      },
      "source": [
        "Impute missing numerical data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "ZtzvH-oi3hNS",
        "outputId": "e3282073-7e5d-4396-acfc-077769d42593"
      },
      "source": [
        "num_new = datanew[num_cols]\n",
        "dt_regressor = DecisionTreeRegressor(max_features='sqrt')\n",
        "impute = IterativeImputer(estimator=dt_regressor)\n",
        "datanew[num_cols] = impute.fit_transform(num_new)\n",
        "datanew.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/impute/_iterative.py:638: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
            "  \" reached.\", ConvergenceWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>IDS</th>\n",
              "      <th>IS_MALE</th>\n",
              "      <th>AGE_AT_SDATE</th>\n",
              "      <th>AGE_GROUP</th>\n",
              "      <th>SES_GROUP</th>\n",
              "      <th>MIGZAR</th>\n",
              "      <th>IS_HYPERTENSION</th>\n",
              "      <th>IS_ISCHEMIC_MI</th>\n",
              "      <th>IS_CVA_TIA</th>\n",
              "      <th>IS_DEMENTIA</th>\n",
              "      <th>IS_ART_SCLE_GEN</th>\n",
              "      <th>IS_TROMBOPHILIA</th>\n",
              "      <th>IS_IBD</th>\n",
              "      <th>BMI_AT_BASELINE</th>\n",
              "      <th>SYSTOLA_AT_BASELINE</th>\n",
              "      <th>DIASTOLA_AT_BASELINE</th>\n",
              "      <th>Creatinine_B_AT_BASELINE</th>\n",
              "      <th>Albumin_B_AT_BASELINE</th>\n",
              "      <th>Urea_B_AT_BASELINE</th>\n",
              "      <th>Glucose_B_AT_BASELINE</th>\n",
              "      <th>HbA1C_AT_BASELINE</th>\n",
              "      <th>RBCRed_Blood_Cells_AT_BASELINE</th>\n",
              "      <th>Hemoglobin_AT_BASELINE</th>\n",
              "      <th>AST_GOT_AT_BASELINE</th>\n",
              "      <th>ALT_GPT_AT_BASELINE</th>\n",
              "      <th>Na_Sodium_B_AT_BASELINE</th>\n",
              "      <th>K_Potassium_B_AT_BASELINE</th>\n",
              "      <th>CaCalcium_B_AT_BASELINE</th>\n",
              "      <th>HDLCholesterol_AT_BASELINE</th>\n",
              "      <th>LDLCholesterol_AT_BASELINE</th>\n",
              "      <th>Triglycerides_AT_BASELINE</th>\n",
              "      <th>2_years</th>\n",
              "      <th>5_years</th>\n",
              "      <th>10_years</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>122931.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>72.97</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19.89</td>\n",
              "      <td>122.0</td>\n",
              "      <td>65.5</td>\n",
              "      <td>1.30</td>\n",
              "      <td>3.9</td>\n",
              "      <td>71.0</td>\n",
              "      <td>185.5</td>\n",
              "      <td>9.55</td>\n",
              "      <td>3.870</td>\n",
              "      <td>11.70</td>\n",
              "      <td>34.0</td>\n",
              "      <td>22.2</td>\n",
              "      <td>138.5</td>\n",
              "      <td>4.60</td>\n",
              "      <td>9.25</td>\n",
              "      <td>31.80</td>\n",
              "      <td>69.0</td>\n",
              "      <td>271.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>98909.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>70.30</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>41.23</td>\n",
              "      <td>150.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>0.90</td>\n",
              "      <td>4.3</td>\n",
              "      <td>33.5</td>\n",
              "      <td>162.5</td>\n",
              "      <td>7.20</td>\n",
              "      <td>4.960</td>\n",
              "      <td>12.70</td>\n",
              "      <td>22.5</td>\n",
              "      <td>24.5</td>\n",
              "      <td>136.5</td>\n",
              "      <td>4.45</td>\n",
              "      <td>9.10</td>\n",
              "      <td>62.60</td>\n",
              "      <td>116.7</td>\n",
              "      <td>114.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>65611.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>53.46</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>29.07</td>\n",
              "      <td>140.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>0.80</td>\n",
              "      <td>4.3</td>\n",
              "      <td>36.5</td>\n",
              "      <td>137.0</td>\n",
              "      <td>7.85</td>\n",
              "      <td>4.525</td>\n",
              "      <td>14.05</td>\n",
              "      <td>34.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>140.0</td>\n",
              "      <td>4.50</td>\n",
              "      <td>9.70</td>\n",
              "      <td>54.00</td>\n",
              "      <td>136.8</td>\n",
              "      <td>81.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>95847.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>81.75</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>34.19</td>\n",
              "      <td>130.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>0.85</td>\n",
              "      <td>4.4</td>\n",
              "      <td>35.0</td>\n",
              "      <td>153.0</td>\n",
              "      <td>7.20</td>\n",
              "      <td>5.070</td>\n",
              "      <td>14.50</td>\n",
              "      <td>106.0</td>\n",
              "      <td>132.0</td>\n",
              "      <td>140.0</td>\n",
              "      <td>4.70</td>\n",
              "      <td>9.80</td>\n",
              "      <td>41.15</td>\n",
              "      <td>139.2</td>\n",
              "      <td>233.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>91914.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>85.35</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24.45</td>\n",
              "      <td>122.5</td>\n",
              "      <td>73.0</td>\n",
              "      <td>0.74</td>\n",
              "      <td>4.5</td>\n",
              "      <td>50.5</td>\n",
              "      <td>117.5</td>\n",
              "      <td>6.70</td>\n",
              "      <td>4.740</td>\n",
              "      <td>14.65</td>\n",
              "      <td>21.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>137.0</td>\n",
              "      <td>4.25</td>\n",
              "      <td>8.90</td>\n",
              "      <td>64.00</td>\n",
              "      <td>148.8</td>\n",
              "      <td>81.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        IDS  IS_MALE  AGE_AT_SDATE  ...  2_years  5_years  10_years\n",
              "0  122931.0      0.0         72.97  ...      1.0      1.0       1.0\n",
              "1   98909.0      0.0         70.30  ...      0.0      0.0       0.0\n",
              "2   65611.0      0.0         53.46  ...      0.0      0.0       0.0\n",
              "3   95847.0      0.0         81.75  ...      0.0      0.0       0.0\n",
              "4   91914.0      1.0         85.35  ...      0.0      0.0       0.0\n",
              "\n",
              "[5 rows x 34 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wL-L0JSMrZhw"
      },
      "source": [
        "Save the new data that we created for easier usage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2oZq5w9_P80"
      },
      "source": [
        "datanew.to_csv('readydata.csv')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOJD4I1eLN4X"
      },
      "source": [
        "#  You can start directly from here after you did cell 1 and 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76-WmATPLECr"
      },
      "source": [
        "datanew = pd.read_csv('readydata.csv')\n",
        "datanew = datanew.iloc[: , 1:]"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "7GMWrredNBkv",
        "outputId": "e58c6798-26a8-4038-c7f2-1e7d1242fb9f"
      },
      "source": [
        "datanew.head()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>IDS</th>\n",
              "      <th>IS_MALE</th>\n",
              "      <th>AGE_AT_SDATE</th>\n",
              "      <th>AGE_GROUP</th>\n",
              "      <th>SES_GROUP</th>\n",
              "      <th>MIGZAR</th>\n",
              "      <th>IS_HYPERTENSION</th>\n",
              "      <th>IS_ISCHEMIC_MI</th>\n",
              "      <th>IS_CVA_TIA</th>\n",
              "      <th>IS_DEMENTIA</th>\n",
              "      <th>IS_ART_SCLE_GEN</th>\n",
              "      <th>IS_TROMBOPHILIA</th>\n",
              "      <th>IS_IBD</th>\n",
              "      <th>BMI_AT_BASELINE</th>\n",
              "      <th>SYSTOLA_AT_BASELINE</th>\n",
              "      <th>DIASTOLA_AT_BASELINE</th>\n",
              "      <th>Creatinine_B_AT_BASELINE</th>\n",
              "      <th>Albumin_B_AT_BASELINE</th>\n",
              "      <th>Urea_B_AT_BASELINE</th>\n",
              "      <th>Glucose_B_AT_BASELINE</th>\n",
              "      <th>HbA1C_AT_BASELINE</th>\n",
              "      <th>RBCRed_Blood_Cells_AT_BASELINE</th>\n",
              "      <th>Hemoglobin_AT_BASELINE</th>\n",
              "      <th>AST_GOT_AT_BASELINE</th>\n",
              "      <th>ALT_GPT_AT_BASELINE</th>\n",
              "      <th>Na_Sodium_B_AT_BASELINE</th>\n",
              "      <th>K_Potassium_B_AT_BASELINE</th>\n",
              "      <th>CaCalcium_B_AT_BASELINE</th>\n",
              "      <th>HDLCholesterol_AT_BASELINE</th>\n",
              "      <th>LDLCholesterol_AT_BASELINE</th>\n",
              "      <th>Triglycerides_AT_BASELINE</th>\n",
              "      <th>2_years</th>\n",
              "      <th>5_years</th>\n",
              "      <th>10_years</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>122931.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>72.97</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>19.89</td>\n",
              "      <td>122.0</td>\n",
              "      <td>65.5</td>\n",
              "      <td>1.30</td>\n",
              "      <td>3.9</td>\n",
              "      <td>71.0</td>\n",
              "      <td>185.5</td>\n",
              "      <td>9.55</td>\n",
              "      <td>3.870</td>\n",
              "      <td>11.70</td>\n",
              "      <td>34.0</td>\n",
              "      <td>22.2</td>\n",
              "      <td>138.5</td>\n",
              "      <td>4.60</td>\n",
              "      <td>9.25</td>\n",
              "      <td>31.80</td>\n",
              "      <td>69.0</td>\n",
              "      <td>271.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>98909.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>70.30</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>41.23</td>\n",
              "      <td>150.0</td>\n",
              "      <td>85.0</td>\n",
              "      <td>0.90</td>\n",
              "      <td>4.3</td>\n",
              "      <td>33.5</td>\n",
              "      <td>162.5</td>\n",
              "      <td>7.20</td>\n",
              "      <td>4.960</td>\n",
              "      <td>12.70</td>\n",
              "      <td>22.5</td>\n",
              "      <td>24.5</td>\n",
              "      <td>136.5</td>\n",
              "      <td>4.45</td>\n",
              "      <td>9.10</td>\n",
              "      <td>62.60</td>\n",
              "      <td>116.7</td>\n",
              "      <td>114.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>65611.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>53.46</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>29.07</td>\n",
              "      <td>140.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>0.80</td>\n",
              "      <td>4.3</td>\n",
              "      <td>36.5</td>\n",
              "      <td>137.0</td>\n",
              "      <td>7.85</td>\n",
              "      <td>4.525</td>\n",
              "      <td>14.05</td>\n",
              "      <td>34.0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>140.0</td>\n",
              "      <td>4.50</td>\n",
              "      <td>9.70</td>\n",
              "      <td>54.00</td>\n",
              "      <td>136.8</td>\n",
              "      <td>81.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>95847.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>81.75</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>34.19</td>\n",
              "      <td>130.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>0.85</td>\n",
              "      <td>4.4</td>\n",
              "      <td>35.0</td>\n",
              "      <td>153.0</td>\n",
              "      <td>7.20</td>\n",
              "      <td>5.070</td>\n",
              "      <td>14.50</td>\n",
              "      <td>106.0</td>\n",
              "      <td>132.0</td>\n",
              "      <td>140.0</td>\n",
              "      <td>4.70</td>\n",
              "      <td>9.80</td>\n",
              "      <td>41.15</td>\n",
              "      <td>139.2</td>\n",
              "      <td>233.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>91914.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>85.35</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>24.45</td>\n",
              "      <td>122.5</td>\n",
              "      <td>73.0</td>\n",
              "      <td>0.74</td>\n",
              "      <td>4.5</td>\n",
              "      <td>50.5</td>\n",
              "      <td>117.5</td>\n",
              "      <td>6.70</td>\n",
              "      <td>4.740</td>\n",
              "      <td>14.65</td>\n",
              "      <td>21.0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>137.0</td>\n",
              "      <td>4.25</td>\n",
              "      <td>8.90</td>\n",
              "      <td>64.00</td>\n",
              "      <td>148.8</td>\n",
              "      <td>81.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        IDS  IS_MALE  AGE_AT_SDATE  ...  2_years  5_years  10_years\n",
              "0  122931.0      0.0         72.97  ...      1.0      1.0       1.0\n",
              "1   98909.0      0.0         70.30  ...      0.0      0.0       0.0\n",
              "2   65611.0      0.0         53.46  ...      0.0      0.0       0.0\n",
              "3   95847.0      0.0         81.75  ...      0.0      0.0       0.0\n",
              "4   91914.0      1.0         85.35  ...      0.0      0.0       0.0\n",
              "\n",
              "[5 rows x 34 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptm9DHYIrgW9"
      },
      "source": [
        "split data according to labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNBMq-74B675"
      },
      "source": [
        "df = datanew.copy()\n",
        "sample_size = df[df['10_years']==1].shape[0]\n",
        "grdf10 = df.groupby('10_years').apply(lambda x: x.sample(sample_size))\n",
        "\n",
        "sample_size = df[df['5_years']==1].shape[0]\n",
        "grdf5 = df.groupby('5_years').apply(lambda x: x.sample(sample_size))\n",
        "\n",
        "sample_size = df[df['2_years']==1].shape[0]\n",
        "grdf2 = df.groupby('2_years').apply(lambda x: x.sample(sample_size))"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8l_TZXEgrixE"
      },
      "source": [
        "Create train/test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6tOhCMG16Dl"
      },
      "source": [
        "def split_df_train_test_val(df,rs= 200):\n",
        "  train_inds, test_inds = next(GroupShuffleSplit(test_size=.20, n_splits=2, random_state = 7).split(df, groups=df['IDS']))\n",
        "  train = df.iloc[train_inds]\n",
        "  test = df.iloc[test_inds]\n",
        "  return train, test"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8FCCI2MgrlVs"
      },
      "source": [
        "Create Pytorch dataframe for the data for easier training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jVshloF6Xf9"
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class DataforSet(Dataset):\n",
        "    \"\"\"Face Landmarks dataset.\"\"\"\n",
        "\n",
        "    def __init__(self, datas, labels= '2_years'):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            csv_file (string): Path to the csv file with annotations.\n",
        "            root_dir (string): Directory with all the images.\n",
        "            transform (callable, optional): Optional transform to be applied\n",
        "                on a sample.\n",
        "        \"\"\"\n",
        "        self.data = datas\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \n",
        "        item = self.data.iloc[idx]\n",
        "        inp = item.drop(['2_years', '5_years', '10_years'])\n",
        "        cont = inp.drop(['AGE_GROUP', 'SES_GROUP', 'MIGZAR']).to_numpy()\n",
        "        cat0 = inp['AGE_GROUP']\n",
        "        cat1 = inp['SES_GROUP']\n",
        "        cat2 = inp['MIGZAR']\n",
        "        label = item['2_years']\n",
        "\n",
        "\n",
        "        return cont, cat0, cat1, cat2, label\n",
        "\n",
        "\n",
        "def create_dataloaders(label_type =10,scase = False):\n",
        "  if label_type == 10:\n",
        "    data = grdf10\n",
        "    labels = '10_years'\n",
        "  elif label_type == 5:\n",
        "    data = grdf5\n",
        "    labels = '5_years'\n",
        "  elif label_type == 2:\n",
        "    data = grdf2\n",
        "    labels = '2_years'\n",
        "\n",
        "  if scase:\n",
        "    data = datanew\n",
        "  \n",
        "\n",
        "\n",
        "  train, test = split_df_train_test_val(data)\n",
        "  train = train.drop(['IDS'],axis=1) #ID are not relevant\n",
        "  test = test.drop(['IDS'],axis=1) #ID are not relevant\n",
        "  dataTrain = DataforSet(train, labels)\n",
        "  dataTest = DataforSet(test, labels)\n",
        "\n",
        "  dataloaders =  {'train': DataLoader(dataTrain, batch_size=150, shuffle=True),\n",
        "                  'val': DataLoader(dataTest, batch_size=150, shuffle=True)}\n",
        "  return dataloaders\n",
        "\n",
        "dataset = datanew.drop(['IDS'],axis=1) #ID are not relevant\n",
        "dataset2 = DataforSet(dataset, 2)\n",
        "dataset5 = DataforSet(dataset, 5)\n",
        "dataset10 = DataforSet(dataset, 10)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xQjnUsJrsdR"
      },
      "source": [
        "Create a NN model using pytorch tow rok with it, we use embedding layers for some of the categorial data, we can improve the model by doing it for more categories which are in the numerical, but due to lack of time I will use only those"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6-YeLuE_GJV"
      },
      "source": [
        "class Model(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, inp_shape = 5, hidden_number= 50, num_labels = 2):\n",
        "      super(Model, self).__init__()\n",
        "      self.emb0 = nn.Embedding(5, 40)\n",
        "      self.emb1 = nn.Embedding(4, 50)\n",
        "      self.emb2 = nn.Embedding(3, 20)\n",
        "      self.emb_drop = nn.Dropout(0.6)\n",
        "      self.bn1 = nn.BatchNorm1d(27)\n",
        "      self.relu = nn.ReLU(True)\n",
        "\n",
        "      self.seq = nn.Sequential(\n",
        "      nn.Linear(137, hidden_number),\n",
        "      nn.BatchNorm1d(hidden_number),\n",
        "      nn.ReLU(True),\n",
        "      nn.Linear(hidden_number, int(hidden_number/2)),\n",
        "      nn.BatchNorm1d(int(hidden_number/2)),\n",
        "      nn.ReLU(True),\n",
        "      nn.Linear(int(hidden_number/2), 1),\n",
        "      nn.Sigmoid())\n",
        "\n",
        "    def forward(self, cont, cat0, cat1, cat2):\n",
        "      out0 = self.emb0(cat0.to(torch.int64))\n",
        "      out1 = self.emb1(cat1.to(torch.int64))\n",
        "      out2 = self.emb2(cat2.to(torch.int64))\n",
        "      x = torch.cat((out0,out1, out2), dim=1)\n",
        "      x = self.emb_drop(x)\n",
        "      x_cont = self.bn1(cont.float())\n",
        "      x = torch.cat([x, x_cont], dim=1)\n",
        "      x = self.relu(x)\n",
        "      x = self.seq(x)\n",
        "      return x\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crp3NwaLr48r"
      },
      "source": [
        "Creata a training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Asfh8Ajt_KD0"
      },
      "source": [
        "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
        "import torch.optim as optim\n",
        "import torch.optim.lr_scheduler as lr_scheduler\n",
        "import torch.nn.functional as F\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "\n",
        "\n",
        "\n",
        "def train_model(model, dataloaders, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    trg = []\n",
        "    oup = []\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "    best_f1 = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "        \n",
        "        \n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "            \n",
        "            count = 0\n",
        "            \n",
        "\n",
        "            # Iterate over data.\n",
        "            for cont, cat0, cat1, cat2, labels in dataloaders[phase]:\n",
        "                cont = cont.to(device)\n",
        "                cat0 = cat0.int().to(device)\n",
        "                cat1 = cat1.int().to(device)\n",
        "                cat2 = cat2.int().to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(cont, cat0, cat1, cat2)\n",
        "                    preds = torch.round(outputs)\n",
        "                    loss = criterion(outputs, labels.float().unsqueeze(1))\n",
        "                    count += len(cont)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * cont.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "                trg.append(labels.detach())\n",
        "                oup.append(preds.detach())\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "            \n",
        "\n",
        "\n",
        "\n",
        "            epoch_loss = running_loss / (len(dataloaders[phase])*150)\n",
        "            epoch_acc = running_corrects.double() / (len(dataloaders[phase])*150)\n",
        "            it = [item for sublist in trg for item in sublist]\n",
        "            tr = torch.tensor(it)\n",
        "            ot = [item for sublist in oup for item in sublist]\n",
        "            prd = torch.tensor(ot)\n",
        "\n",
        "            epoch_f1 = f1_score(tr, prd, average='macro')\n",
        "            epoch_precision = precision_score(tr, prd, average='macro')\n",
        "            epoch_recall = recall_score(tr, prd, average='macro')\n",
        "            epoch_accuracy = accuracy_score(tr, prd)\n",
        "\n",
        "            # epoch_f1 = 0\n",
        "            # epoch_precision = 0\n",
        "            # epoch_recall = 0\n",
        "\n",
        "\n",
        "            trg = []\n",
        "            oup = []\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f} F1 score: {:.4f} Precision: {:.4f} Recall: {:.4f} '.format(\n",
        "                phase, epoch_loss, epoch_accuracy, epoch_f1, epoch_precision, epoch_recall))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_f1 > best_f1:\n",
        "                best_f1 = epoch_f1\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "    print('Best val F1: {:4f}'.format(best_f1))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVUqsskYr8MO"
      },
      "source": [
        "Now we create folds for each timeframe and train with k=10 folds as requested"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgG-IVwnC9NY"
      },
      "source": [
        "# 10 Years"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Aor5sHy9VHr",
        "outputId": "d74fa115-c3f1-4fa0-a840-1da0b8056f4a"
      },
      "source": [
        "kfold = KFold(n_splits=10, shuffle=True)\n",
        "grdf10 = grdf10.drop(['IDS'],axis=1) #ID are not relevant\n",
        "# K-fold Cross Validation model evaluation\n",
        "for fold, (train_ids, test_ids) in enumerate(kfold.split(grdf10)):\n",
        "  print(f\"fold {fold}\")\n",
        "  model = Model()\n",
        "  model = model.to(device)\n",
        "  lr=0.005\n",
        "  optimizer = optim.Adam(model.parameters(),lr=lr)\n",
        "  criterion = nn.BCELoss()\n",
        "  scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "  train_subsampler = SubsetRandomSampler(train_ids)\n",
        "  test_subsampler = SubsetRandomSampler(test_ids)\n",
        "\n",
        "\n",
        "  dataf10 = DataforSet(grdf10, '10_years')\n",
        "\n",
        "  dataloaders =  {'train': DataLoader(dataf10, batch_size=150, sampler=train_subsampler),\n",
        "                  'val': DataLoader(dataf10, batch_size=150, sampler=test_subsampler)}\n",
        "\n",
        "  model = train_model(model, dataloaders, criterion, optimizer, scheduler, num_epochs=20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fold 0\n",
            "Epoch 0/19\n",
            "----------\n",
            "train Loss: 0.3426 Acc: 0.8684 F1 score: 0.6867 Precision: 0.7288 Recall: 0.6627 \n",
            "val Loss: 0.3297 Acc: 0.8695 F1 score: 0.7407 Precision: 0.7961 Recall: 0.7105 \n",
            "\n",
            "Epoch 1/19\n",
            "----------\n",
            "train Loss: 0.2843 Acc: 0.8908 F1 score: 0.7313 Precision: 0.8004 Recall: 0.6955 \n",
            "val Loss: 0.3230 Acc: 0.8679 F1 score: 0.7298 Precision: 0.7991 Recall: 0.6965 \n",
            "\n",
            "Epoch 2/19\n",
            "----------\n",
            "train Loss: 0.2806 Acc: 0.8919 F1 score: 0.7333 Precision: 0.8043 Recall: 0.6968 \n",
            "val Loss: 0.3303 Acc: 0.8658 F1 score: 0.7027 Precision: 0.8197 Recall: 0.6645 \n",
            "\n",
            "Epoch 3/19\n",
            "----------\n",
            "train Loss: 0.2770 Acc: 0.8941 F1 score: 0.7406 Precision: 0.8091 Recall: 0.7042 \n",
            "val Loss: 0.3186 Acc: 0.8690 F1 score: 0.7328 Precision: 0.8011 Recall: 0.6995 \n",
            "\n",
            "Epoch 4/19\n",
            "----------\n",
            "train Loss: 0.2757 Acc: 0.8948 F1 score: 0.7401 Precision: 0.8135 Recall: 0.7023 \n",
            "val Loss: 0.3246 Acc: 0.8727 F1 score: 0.7400 Precision: 0.8112 Recall: 0.7053 \n",
            "\n",
            "Epoch 5/19\n",
            "----------\n",
            "train Loss: 0.2736 Acc: 0.8949 F1 score: 0.7401 Precision: 0.8145 Recall: 0.7021 \n",
            "val Loss: 0.3251 Acc: 0.8701 F1 score: 0.7342 Precision: 0.8047 Recall: 0.7002 \n",
            "\n",
            "Epoch 6/19\n",
            "----------\n",
            "train Loss: 0.2716 Acc: 0.8957 F1 score: 0.7421 Precision: 0.8165 Recall: 0.7039 \n",
            "val Loss: 0.3285 Acc: 0.8642 F1 score: 0.7088 Precision: 0.8024 Recall: 0.6730 \n",
            "\n",
            "Epoch 7/19\n",
            "----------\n",
            "train Loss: 0.2670 Acc: 0.8961 F1 score: 0.7388 Precision: 0.8228 Recall: 0.6984 \n",
            "val Loss: 0.3267 Acc: 0.8647 F1 score: 0.7142 Precision: 0.7993 Recall: 0.6792 \n",
            "\n",
            "Epoch 8/19\n",
            "----------\n",
            "train Loss: 0.2653 Acc: 0.8974 F1 score: 0.7446 Precision: 0.8245 Recall: 0.7046 \n",
            "val Loss: 0.3238 Acc: 0.8711 F1 score: 0.7372 Precision: 0.8066 Recall: 0.7032 \n",
            "\n",
            "Epoch 9/19\n",
            "----------\n",
            "train Loss: 0.2667 Acc: 0.8979 F1 score: 0.7489 Precision: 0.8220 Recall: 0.7104 \n",
            "val Loss: 0.3259 Acc: 0.8636 F1 score: 0.7071 Precision: 0.8014 Recall: 0.6715 \n",
            "\n",
            "Epoch 10/19\n",
            "----------\n",
            "train Loss: 0.2659 Acc: 0.8966 F1 score: 0.7420 Precision: 0.8224 Recall: 0.7022 \n",
            "val Loss: 0.3247 Acc: 0.8668 F1 score: 0.7196 Precision: 0.8044 Recall: 0.6840 \n",
            "\n",
            "Epoch 11/19\n",
            "----------\n",
            "train Loss: 0.2666 Acc: 0.8970 F1 score: 0.7449 Precision: 0.8216 Recall: 0.7057 \n",
            "val Loss: 0.3253 Acc: 0.8642 F1 score: 0.7097 Precision: 0.8013 Recall: 0.6742 \n",
            "\n",
            "Epoch 12/19\n",
            "----------\n",
            "train Loss: 0.2663 Acc: 0.8970 F1 score: 0.7452 Precision: 0.8212 Recall: 0.7062 \n",
            "val Loss: 0.3235 Acc: 0.8663 F1 score: 0.7153 Precision: 0.8066 Recall: 0.6790 \n",
            "\n",
            "Epoch 13/19\n",
            "----------\n",
            "train Loss: 0.2640 Acc: 0.8964 F1 score: 0.7441 Precision: 0.8186 Recall: 0.7057 \n",
            "val Loss: 0.3224 Acc: 0.8695 F1 score: 0.7310 Precision: 0.8055 Recall: 0.6963 \n",
            "\n",
            "Epoch 14/19\n",
            "----------\n",
            "train Loss: 0.2651 Acc: 0.8973 F1 score: 0.7486 Precision: 0.8189 Recall: 0.7109 \n",
            "val Loss: 0.3251 Acc: 0.8695 F1 score: 0.7284 Precision: 0.8083 Recall: 0.6928 \n",
            "\n",
            "Epoch 15/19\n",
            "----------\n",
            "train Loss: 0.2651 Acc: 0.8958 F1 score: 0.7429 Precision: 0.8168 Recall: 0.7047 \n",
            "val Loss: 0.3259 Acc: 0.8652 F1 score: 0.7120 Precision: 0.8045 Recall: 0.6760 \n",
            "\n",
            "Epoch 16/19\n",
            "----------\n",
            "train Loss: 0.2642 Acc: 0.8978 F1 score: 0.7483 Precision: 0.8223 Recall: 0.7096 \n",
            "val Loss: 0.3258 Acc: 0.8647 F1 score: 0.7075 Precision: 0.8069 Recall: 0.6709 \n",
            "\n",
            "Epoch 17/19\n",
            "----------\n",
            "train Loss: 0.2649 Acc: 0.8958 F1 score: 0.7436 Precision: 0.8157 Recall: 0.7059 \n",
            "val Loss: 0.3230 Acc: 0.8668 F1 score: 0.7196 Precision: 0.8044 Recall: 0.6840 \n",
            "\n",
            "Epoch 18/19\n",
            "----------\n",
            "train Loss: 0.2643 Acc: 0.8975 F1 score: 0.7469 Precision: 0.8222 Recall: 0.7079 \n",
            "val Loss: 0.3250 Acc: 0.8647 F1 score: 0.7123 Precision: 0.8013 Recall: 0.6768 \n",
            "\n",
            "Epoch 19/19\n",
            "----------\n",
            "train Loss: 0.2640 Acc: 0.8964 F1 score: 0.7457 Precision: 0.8168 Recall: 0.7081 \n",
            "val Loss: 0.3252 Acc: 0.8636 F1 score: 0.7021 Precision: 0.8072 Recall: 0.6656 \n",
            "\n",
            "Training complete in 4m 55s\n",
            "Best val F1: 0.740717\n",
            "fold 1\n",
            "Epoch 0/19\n",
            "----------\n",
            "train Loss: 0.3352 Acc: 0.8768 F1 score: 0.6972 Precision: 0.7671 Recall: 0.6648 \n",
            "val Loss: 0.2677 Acc: 0.8882 F1 score: 0.7434 Precision: 0.7901 Recall: 0.7144 \n",
            "\n",
            "Epoch 1/19\n",
            "----------\n",
            "train Loss: 0.2915 Acc: 0.8897 F1 score: 0.7362 Precision: 0.8019 Recall: 0.7012 \n",
            "val Loss: 0.2671 Acc: 0.8936 F1 score: 0.7529 Precision: 0.8070 Recall: 0.7206 \n",
            "\n",
            "Epoch 2/19\n",
            "----------\n",
            "train Loss: 0.2864 Acc: 0.8918 F1 score: 0.7405 Precision: 0.8091 Recall: 0.7043 \n",
            "val Loss: 0.2646 Acc: 0.8936 F1 score: 0.7391 Precision: 0.8212 Recall: 0.6993 \n",
            "\n",
            "Epoch 3/19\n",
            "----------\n",
            "train Loss: 0.2848 Acc: 0.8911 F1 score: 0.7377 Precision: 0.8082 Recall: 0.7012 \n",
            "val Loss: 0.2673 Acc: 0.8936 F1 score: 0.7348 Precision: 0.8265 Recall: 0.6932 \n",
            "\n",
            "Epoch 4/19\n",
            "----------\n",
            "train Loss: 0.2831 Acc: 0.8912 F1 score: 0.7410 Precision: 0.8055 Recall: 0.7060 \n",
            "val Loss: 0.2616 Acc: 0.8936 F1 score: 0.7452 Precision: 0.8144 Recall: 0.7084 \n",
            "\n",
            "Epoch 5/19\n",
            "----------\n",
            "train Loss: 0.2808 Acc: 0.8929 F1 score: 0.7409 Precision: 0.8145 Recall: 0.7032 \n",
            "val Loss: 0.2646 Acc: 0.8963 F1 score: 0.7387 Precision: 0.8395 Recall: 0.6948 \n",
            "\n",
            "Epoch 6/19\n",
            "----------\n",
            "train Loss: 0.2798 Acc: 0.8919 F1 score: 0.7391 Precision: 0.8108 Recall: 0.7021 \n",
            "val Loss: 0.2624 Acc: 0.8930 F1 score: 0.7329 Precision: 0.8254 Recall: 0.6914 \n",
            "\n",
            "Epoch 7/19\n",
            "----------\n",
            "train Loss: 0.2769 Acc: 0.8914 F1 score: 0.7339 Precision: 0.8135 Recall: 0.6953 \n",
            "val Loss: 0.2611 Acc: 0.8936 F1 score: 0.7348 Precision: 0.8265 Recall: 0.6932 \n",
            "\n",
            "Epoch 8/19\n",
            "----------\n",
            "train Loss: 0.2753 Acc: 0.8936 F1 score: 0.7423 Precision: 0.8175 Recall: 0.7040 \n",
            "val Loss: 0.2608 Acc: 0.8930 F1 score: 0.7362 Precision: 0.8214 Recall: 0.6960 \n",
            "\n",
            "Epoch 9/19\n",
            "----------\n",
            "train Loss: 0.2743 Acc: 0.8929 F1 score: 0.7423 Precision: 0.8131 Recall: 0.7052 \n",
            "val Loss: 0.2610 Acc: 0.8947 F1 score: 0.7468 Precision: 0.8187 Recall: 0.7090 \n",
            "\n",
            "Epoch 10/19\n",
            "----------\n",
            "train Loss: 0.2735 Acc: 0.8926 F1 score: 0.7403 Precision: 0.8135 Recall: 0.7027 \n",
            "val Loss: 0.2620 Acc: 0.8952 F1 score: 0.7446 Precision: 0.8245 Recall: 0.7048 \n",
            "\n",
            "Epoch 11/19\n",
            "----------\n",
            "train Loss: 0.2749 Acc: 0.8917 F1 score: 0.7400 Precision: 0.8093 Recall: 0.7036 \n",
            "val Loss: 0.2614 Acc: 0.8947 F1 score: 0.7468 Precision: 0.8187 Recall: 0.7090 \n",
            "\n",
            "Epoch 12/19\n",
            "----------\n",
            "train Loss: 0.2745 Acc: 0.8925 F1 score: 0.7396 Precision: 0.8139 Recall: 0.7018 \n",
            "val Loss: 0.2643 Acc: 0.8930 F1 score: 0.7261 Precision: 0.8347 Recall: 0.6823 \n",
            "\n",
            "Epoch 13/19\n",
            "----------\n",
            "train Loss: 0.2738 Acc: 0.8926 F1 score: 0.7424 Precision: 0.8117 Recall: 0.7058 \n",
            "val Loss: 0.2630 Acc: 0.8936 F1 score: 0.7326 Precision: 0.8294 Recall: 0.6902 \n",
            "\n",
            "Epoch 14/19\n",
            "----------\n",
            "train Loss: 0.2723 Acc: 0.8926 F1 score: 0.7408 Precision: 0.8133 Recall: 0.7034 \n",
            "val Loss: 0.2610 Acc: 0.8930 F1 score: 0.7393 Precision: 0.8177 Recall: 0.7005 \n",
            "\n",
            "Epoch 15/19\n",
            "----------\n",
            "train Loss: 0.2731 Acc: 0.8929 F1 score: 0.7415 Precision: 0.8143 Recall: 0.7039 \n",
            "val Loss: 0.2608 Acc: 0.8941 F1 score: 0.7450 Precision: 0.8176 Recall: 0.7072 \n",
            "\n",
            "Epoch 16/19\n",
            "----------\n",
            "train Loss: 0.2724 Acc: 0.8939 F1 score: 0.7456 Precision: 0.8155 Recall: 0.7086 \n",
            "val Loss: 0.2614 Acc: 0.8941 F1 score: 0.7419 Precision: 0.8211 Recall: 0.7027 \n",
            "\n",
            "Epoch 17/19\n",
            "----------\n",
            "train Loss: 0.2727 Acc: 0.8938 F1 score: 0.7450 Precision: 0.8152 Recall: 0.7080 \n",
            "val Loss: 0.2613 Acc: 0.8936 F1 score: 0.7401 Precision: 0.8200 Recall: 0.7008 \n",
            "\n",
            "Epoch 18/19\n",
            "----------\n",
            "train Loss: 0.2729 Acc: 0.8940 F1 score: 0.7448 Precision: 0.8167 Recall: 0.7073 \n",
            "val Loss: 0.2622 Acc: 0.8957 F1 score: 0.7401 Precision: 0.8338 Recall: 0.6975 \n",
            "\n",
            "Epoch 19/19\n",
            "----------\n",
            "train Loss: 0.2721 Acc: 0.8919 F1 score: 0.7384 Precision: 0.8114 Recall: 0.7011 \n",
            "val Loss: 0.2612 Acc: 0.8947 F1 score: 0.7427 Precision: 0.8234 Recall: 0.7030 \n",
            "\n",
            "Training complete in 4m 56s\n",
            "Best val F1: 0.752898\n",
            "fold 2\n",
            "Epoch 0/19\n",
            "----------\n",
            "train Loss: 0.3385 Acc: 0.8773 F1 score: 0.6973 Precision: 0.7746 Recall: 0.6633 \n",
            "val Loss: 0.2571 Acc: 0.9000 F1 score: 0.7568 Precision: 0.7932 Recall: 0.7313 \n",
            "\n",
            "Epoch 1/19\n",
            "----------\n",
            "train Loss: 0.2921 Acc: 0.8887 F1 score: 0.7385 Precision: 0.8001 Recall: 0.7047 \n",
            "val Loss: 0.2528 Acc: 0.9011 F1 score: 0.7439 Precision: 0.8081 Recall: 0.7079 \n",
            "\n",
            "Epoch 2/19\n",
            "----------\n",
            "train Loss: 0.2899 Acc: 0.8881 F1 score: 0.7360 Precision: 0.7993 Recall: 0.7019 \n",
            "val Loss: 0.2485 Acc: 0.9037 F1 score: 0.7555 Precision: 0.8121 Recall: 0.7214 \n",
            "\n",
            "Epoch 3/19\n",
            "----------\n",
            "train Loss: 0.2859 Acc: 0.8911 F1 score: 0.7421 Precision: 0.8092 Recall: 0.7063 \n",
            "val Loss: 0.2490 Acc: 0.9043 F1 score: 0.7478 Precision: 0.8232 Recall: 0.7080 \n",
            "\n",
            "Epoch 4/19\n",
            "----------\n",
            "train Loss: 0.2823 Acc: 0.8923 F1 score: 0.7407 Precision: 0.8173 Recall: 0.7023 \n",
            "val Loss: 0.2484 Acc: 0.9048 F1 score: 0.7509 Precision: 0.8231 Recall: 0.7118 \n",
            "\n",
            "Epoch 5/19\n",
            "----------\n",
            "train Loss: 0.2811 Acc: 0.8898 F1 score: 0.7386 Precision: 0.8054 Recall: 0.7032 \n",
            "val Loss: 0.2489 Acc: 0.9021 F1 score: 0.7477 Precision: 0.8105 Recall: 0.7119 \n",
            "\n",
            "Epoch 6/19\n",
            "----------\n",
            "train Loss: 0.2801 Acc: 0.8910 F1 score: 0.7399 Precision: 0.8105 Recall: 0.7032 \n",
            "val Loss: 0.2489 Acc: 0.9027 F1 score: 0.7549 Precision: 0.8071 Recall: 0.7225 \n",
            "\n",
            "Epoch 7/19\n",
            "----------\n",
            "train Loss: 0.2757 Acc: 0.8914 F1 score: 0.7462 Precision: 0.8066 Recall: 0.7121 \n",
            "val Loss: 0.2503 Acc: 0.9021 F1 score: 0.7541 Precision: 0.8050 Recall: 0.7222 \n",
            "\n",
            "Epoch 8/19\n",
            "----------\n",
            "train Loss: 0.2744 Acc: 0.8932 F1 score: 0.7470 Precision: 0.8151 Recall: 0.7105 \n",
            "val Loss: 0.2482 Acc: 0.9075 F1 score: 0.7529 Precision: 0.8385 Recall: 0.7099 \n",
            "\n",
            "Epoch 9/19\n",
            "----------\n",
            "train Loss: 0.2756 Acc: 0.8918 F1 score: 0.7441 Precision: 0.8108 Recall: 0.7082 \n",
            "val Loss: 0.2503 Acc: 0.8995 F1 score: 0.7479 Precision: 0.7967 Recall: 0.7173 \n",
            "\n",
            "Epoch 10/19\n",
            "----------\n",
            "train Loss: 0.2736 Acc: 0.8926 F1 score: 0.7422 Precision: 0.8174 Recall: 0.7040 \n",
            "val Loss: 0.2494 Acc: 0.9005 F1 score: 0.7506 Precision: 0.7998 Recall: 0.7196 \n",
            "\n",
            "Epoch 11/19\n",
            "----------\n",
            "train Loss: 0.2747 Acc: 0.8919 F1 score: 0.7401 Precision: 0.8152 Recall: 0.7022 \n",
            "val Loss: 0.2491 Acc: 0.9032 F1 score: 0.7505 Precision: 0.8139 Recall: 0.7143 \n",
            "\n",
            "Epoch 12/19\n",
            "----------\n",
            "train Loss: 0.2738 Acc: 0.8930 F1 score: 0.7425 Precision: 0.8194 Recall: 0.7039 \n",
            "val Loss: 0.2490 Acc: 0.9075 F1 score: 0.7518 Precision: 0.8401 Recall: 0.7081 \n",
            "\n",
            "Epoch 13/19\n",
            "----------\n",
            "train Loss: 0.2741 Acc: 0.8938 F1 score: 0.7472 Precision: 0.8182 Recall: 0.7098 \n",
            "val Loss: 0.2482 Acc: 0.9048 F1 score: 0.7530 Precision: 0.8208 Recall: 0.7152 \n",
            "\n",
            "Epoch 14/19\n",
            "----------\n",
            "train Loss: 0.2708 Acc: 0.8946 F1 score: 0.7478 Precision: 0.8223 Recall: 0.7093 \n",
            "val Loss: 0.2497 Acc: 0.9037 F1 score: 0.7535 Precision: 0.8141 Recall: 0.7180 \n",
            "\n",
            "Epoch 15/19\n",
            "----------\n",
            "train Loss: 0.2736 Acc: 0.8926 F1 score: 0.7438 Precision: 0.8155 Recall: 0.7065 \n",
            "val Loss: 0.2481 Acc: 0.9053 F1 score: 0.7549 Precision: 0.8219 Recall: 0.7172 \n",
            "\n",
            "Epoch 16/19\n",
            "----------\n",
            "train Loss: 0.2720 Acc: 0.8936 F1 score: 0.7463 Precision: 0.8185 Recall: 0.7086 \n",
            "val Loss: 0.2495 Acc: 0.9053 F1 score: 0.7472 Precision: 0.8310 Recall: 0.7052 \n",
            "\n",
            "Epoch 17/19\n",
            "----------\n",
            "train Loss: 0.2707 Acc: 0.8942 F1 score: 0.7463 Precision: 0.8216 Recall: 0.7077 \n",
            "val Loss: 0.2479 Acc: 0.9064 F1 score: 0.7512 Precision: 0.8333 Recall: 0.7092 \n",
            "\n",
            "Epoch 18/19\n",
            "----------\n",
            "train Loss: 0.2720 Acc: 0.8938 F1 score: 0.7459 Precision: 0.8196 Recall: 0.7078 \n",
            "val Loss: 0.2491 Acc: 0.9037 F1 score: 0.7535 Precision: 0.8141 Recall: 0.7180 \n",
            "\n",
            "Epoch 19/19\n",
            "----------\n",
            "train Loss: 0.2729 Acc: 0.8942 F1 score: 0.7481 Precision: 0.8196 Recall: 0.7104 \n",
            "val Loss: 0.2490 Acc: 0.9059 F1 score: 0.7515 Precision: 0.8293 Recall: 0.7107 \n",
            "\n",
            "Training complete in 4m 56s\n",
            "Best val F1: 0.756767\n",
            "fold 3\n",
            "Epoch 0/19\n",
            "----------\n",
            "train Loss: 0.3452 Acc: 0.8712 F1 score: 0.6901 Precision: 0.7493 Recall: 0.6611 \n",
            "val Loss: 0.2814 Acc: 0.8882 F1 score: 0.7324 Precision: 0.7758 Recall: 0.7051 \n",
            "\n",
            "Epoch 1/19\n",
            "----------\n",
            "train Loss: 0.2885 Acc: 0.8898 F1 score: 0.7378 Precision: 0.8041 Recall: 0.7025 \n",
            "val Loss: 0.2767 Acc: 0.8936 F1 score: 0.7314 Precision: 0.8011 Recall: 0.6952 \n",
            "\n",
            "Epoch 2/19\n",
            "----------\n",
            "train Loss: 0.2835 Acc: 0.8903 F1 score: 0.7419 Precision: 0.8025 Recall: 0.7081 \n",
            "val Loss: 0.2729 Acc: 0.8957 F1 score: 0.7346 Precision: 0.8102 Recall: 0.6965 \n",
            "\n",
            "Epoch 3/19\n",
            "----------\n",
            "train Loss: 0.2843 Acc: 0.8886 F1 score: 0.7310 Precision: 0.8037 Recall: 0.6946 \n",
            "val Loss: 0.2732 Acc: 0.8947 F1 score: 0.7330 Precision: 0.8056 Recall: 0.6958 \n",
            "\n",
            "Epoch 4/19\n",
            "----------\n",
            "train Loss: 0.2799 Acc: 0.8913 F1 score: 0.7394 Precision: 0.8105 Recall: 0.7026 \n",
            "val Loss: 0.2713 Acc: 0.8968 F1 score: 0.7305 Precision: 0.8213 Recall: 0.6890 \n",
            "\n",
            "Epoch 5/19\n",
            "----------\n",
            "train Loss: 0.2785 Acc: 0.8925 F1 score: 0.7437 Precision: 0.8126 Recall: 0.7071 \n",
            "val Loss: 0.2747 Acc: 0.8947 F1 score: 0.7261 Precision: 0.8124 Recall: 0.6861 \n",
            "\n",
            "Epoch 6/19\n",
            "----------\n",
            "train Loss: 0.2753 Acc: 0.8925 F1 score: 0.7423 Precision: 0.8136 Recall: 0.7052 \n",
            "val Loss: 0.2730 Acc: 0.8936 F1 score: 0.7196 Precision: 0.8125 Recall: 0.6790 \n",
            "\n",
            "Epoch 7/19\n",
            "----------\n",
            "train Loss: 0.2717 Acc: 0.8951 F1 score: 0.7512 Precision: 0.8190 Recall: 0.7143 \n",
            "val Loss: 0.2720 Acc: 0.8963 F1 score: 0.7409 Precision: 0.8072 Recall: 0.7049 \n",
            "\n",
            "Epoch 8/19\n",
            "----------\n",
            "train Loss: 0.2713 Acc: 0.8941 F1 score: 0.7482 Precision: 0.8167 Recall: 0.7114 \n",
            "val Loss: 0.2725 Acc: 0.8952 F1 score: 0.7382 Precision: 0.8039 Recall: 0.7026 \n",
            "\n",
            "Epoch 9/19\n",
            "----------\n",
            "train Loss: 0.2724 Acc: 0.8951 F1 score: 0.7506 Precision: 0.8194 Recall: 0.7135 \n",
            "val Loss: 0.2723 Acc: 0.8968 F1 score: 0.7417 Precision: 0.8094 Recall: 0.7052 \n",
            "\n",
            "Epoch 10/19\n",
            "----------\n",
            "train Loss: 0.2720 Acc: 0.8945 F1 score: 0.7487 Precision: 0.8185 Recall: 0.7115 \n",
            "val Loss: 0.2725 Acc: 0.8947 F1 score: 0.7374 Precision: 0.8017 Recall: 0.7023 \n",
            "\n",
            "Epoch 11/19\n",
            "----------\n",
            "train Loss: 0.2706 Acc: 0.8932 F1 score: 0.7444 Precision: 0.8154 Recall: 0.7072 \n",
            "val Loss: 0.2717 Acc: 0.8952 F1 score: 0.7349 Precision: 0.8068 Recall: 0.6978 \n",
            "\n",
            "Epoch 12/19\n",
            "----------\n",
            "train Loss: 0.2692 Acc: 0.8948 F1 score: 0.7473 Precision: 0.8214 Recall: 0.7089 \n",
            "val Loss: 0.2715 Acc: 0.8973 F1 score: 0.7324 Precision: 0.8225 Recall: 0.6909 \n",
            "\n",
            "Epoch 13/19\n",
            "----------\n",
            "train Loss: 0.2682 Acc: 0.8969 F1 score: 0.7542 Precision: 0.8257 Recall: 0.7161 \n",
            "val Loss: 0.2727 Acc: 0.8930 F1 score: 0.7318 Precision: 0.7980 Recall: 0.6965 \n",
            "\n",
            "Epoch 14/19\n",
            "----------\n",
            "train Loss: 0.2689 Acc: 0.8953 F1 score: 0.7497 Precision: 0.8217 Recall: 0.7118 \n",
            "val Loss: 0.2721 Acc: 0.8952 F1 score: 0.7327 Precision: 0.8090 Recall: 0.6945 \n",
            "\n",
            "Epoch 15/19\n",
            "----------\n",
            "train Loss: 0.2680 Acc: 0.8953 F1 score: 0.7505 Precision: 0.8208 Recall: 0.7129 \n",
            "val Loss: 0.2742 Acc: 0.8941 F1 score: 0.7419 Precision: 0.7955 Recall: 0.7101 \n",
            "\n",
            "Epoch 16/19\n",
            "----------\n",
            "train Loss: 0.2687 Acc: 0.8945 F1 score: 0.7496 Precision: 0.8172 Recall: 0.7130 \n",
            "val Loss: 0.2725 Acc: 0.8941 F1 score: 0.7345 Precision: 0.8014 Recall: 0.6988 \n",
            "\n",
            "Epoch 17/19\n",
            "----------\n",
            "train Loss: 0.2676 Acc: 0.8945 F1 score: 0.7457 Precision: 0.8214 Recall: 0.7071 \n",
            "val Loss: 0.2724 Acc: 0.8968 F1 score: 0.7339 Precision: 0.8174 Recall: 0.6938 \n",
            "\n",
            "Epoch 18/19\n",
            "----------\n",
            "train Loss: 0.2686 Acc: 0.8955 F1 score: 0.7502 Precision: 0.8225 Recall: 0.7121 \n",
            "val Loss: 0.2717 Acc: 0.8973 F1 score: 0.7324 Precision: 0.8225 Recall: 0.6909 \n",
            "\n",
            "Epoch 19/19\n",
            "----------\n",
            "train Loss: 0.2680 Acc: 0.8951 F1 score: 0.7485 Precision: 0.8221 Recall: 0.7101 \n",
            "val Loss: 0.2728 Acc: 0.8952 F1 score: 0.7338 Precision: 0.8079 Recall: 0.6961 \n",
            "\n",
            "Training complete in 4m 56s\n",
            "Best val F1: 0.741944\n",
            "fold 4\n",
            "Epoch 0/19\n",
            "----------\n",
            "train Loss: 0.3277 Acc: 0.8813 F1 score: 0.6944 Precision: 0.7949 Recall: 0.6566 \n",
            "val Loss: 0.2802 Acc: 0.8797 F1 score: 0.7073 Precision: 0.7602 Recall: 0.6783 \n",
            "\n",
            "Epoch 1/19\n",
            "----------\n",
            "train Loss: 0.2909 Acc: 0.8900 F1 score: 0.7383 Precision: 0.8036 Recall: 0.7032 \n",
            "val Loss: 0.2836 Acc: 0.8818 F1 score: 0.6913 Precision: 0.7783 Recall: 0.6558 \n",
            "\n",
            "Epoch 2/19\n",
            "----------\n",
            "train Loss: 0.2857 Acc: 0.8928 F1 score: 0.7420 Precision: 0.8150 Recall: 0.7044 \n",
            "val Loss: 0.2798 Acc: 0.8813 F1 score: 0.6972 Precision: 0.7719 Recall: 0.6634 \n",
            "\n",
            "Epoch 3/19\n",
            "----------\n",
            "train Loss: 0.2817 Acc: 0.8929 F1 score: 0.7454 Precision: 0.8118 Recall: 0.7094 \n",
            "val Loss: 0.2799 Acc: 0.8807 F1 score: 0.7134 Precision: 0.7621 Recall: 0.6853 \n",
            "\n",
            "Epoch 4/19\n",
            "----------\n",
            "train Loss: 0.2807 Acc: 0.8937 F1 score: 0.7426 Precision: 0.8194 Recall: 0.7039 \n",
            "val Loss: 0.2761 Acc: 0.8840 F1 score: 0.7177 Precision: 0.7731 Recall: 0.6871 \n",
            "\n",
            "Epoch 5/19\n",
            "----------\n",
            "train Loss: 0.2782 Acc: 0.8942 F1 score: 0.7471 Precision: 0.8172 Recall: 0.7099 \n",
            "val Loss: 0.2786 Acc: 0.8791 F1 score: 0.6982 Precision: 0.7616 Recall: 0.6669 \n",
            "\n",
            "Epoch 6/19\n",
            "----------\n",
            "train Loss: 0.2776 Acc: 0.8942 F1 score: 0.7462 Precision: 0.8181 Recall: 0.7085 \n",
            "val Loss: 0.2772 Acc: 0.8791 F1 score: 0.6918 Precision: 0.7645 Recall: 0.6590 \n",
            "\n",
            "Epoch 7/19\n",
            "----------\n",
            "train Loss: 0.2734 Acc: 0.8955 F1 score: 0.7446 Precision: 0.8282 Recall: 0.7040 \n",
            "val Loss: 0.2782 Acc: 0.8818 F1 score: 0.6786 Precision: 0.7881 Recall: 0.6416 \n",
            "\n",
            "Epoch 8/19\n",
            "----------\n",
            "train Loss: 0.2721 Acc: 0.8945 F1 score: 0.7472 Precision: 0.8191 Recall: 0.7094 \n",
            "val Loss: 0.2766 Acc: 0.8824 F1 score: 0.7098 Precision: 0.7702 Recall: 0.6783 \n",
            "\n",
            "Epoch 9/19\n",
            "----------\n",
            "train Loss: 0.2717 Acc: 0.8956 F1 score: 0.7485 Precision: 0.8238 Recall: 0.7097 \n",
            "val Loss: 0.2767 Acc: 0.8813 F1 score: 0.6946 Precision: 0.7734 Recall: 0.6603 \n",
            "\n",
            "Epoch 10/19\n",
            "----------\n",
            "train Loss: 0.2698 Acc: 0.8958 F1 score: 0.7479 Precision: 0.8256 Recall: 0.7085 \n",
            "val Loss: 0.2770 Acc: 0.8797 F1 score: 0.6938 Precision: 0.7660 Recall: 0.6609 \n",
            "\n",
            "Epoch 11/19\n",
            "----------\n",
            "train Loss: 0.2722 Acc: 0.8948 F1 score: 0.7479 Precision: 0.8200 Recall: 0.7101 \n",
            "val Loss: 0.2774 Acc: 0.8807 F1 score: 0.6844 Precision: 0.7771 Recall: 0.6489 \n",
            "\n",
            "Epoch 12/19\n",
            "----------\n",
            "train Loss: 0.2706 Acc: 0.8958 F1 score: 0.7499 Precision: 0.8232 Recall: 0.7115 \n",
            "val Loss: 0.2777 Acc: 0.8824 F1 score: 0.7121 Precision: 0.7691 Recall: 0.6815 \n",
            "\n",
            "Epoch 13/19\n",
            "----------\n",
            "train Loss: 0.2711 Acc: 0.8947 F1 score: 0.7472 Precision: 0.8201 Recall: 0.7092 \n",
            "val Loss: 0.2776 Acc: 0.8807 F1 score: 0.7052 Precision: 0.7654 Recall: 0.6742 \n",
            "\n",
            "Epoch 14/19\n",
            "----------\n",
            "train Loss: 0.2693 Acc: 0.8942 F1 score: 0.7469 Precision: 0.8174 Recall: 0.7095 \n",
            "val Loss: 0.2786 Acc: 0.8840 F1 score: 0.7189 Precision: 0.7725 Recall: 0.6887 \n",
            "\n",
            "Epoch 15/19\n",
            "----------\n",
            "train Loss: 0.2688 Acc: 0.8958 F1 score: 0.7502 Precision: 0.8228 Recall: 0.7120 \n",
            "val Loss: 0.2778 Acc: 0.8807 F1 score: 0.6939 Precision: 0.7711 Recall: 0.6599 \n",
            "\n",
            "Epoch 16/19\n",
            "----------\n",
            "train Loss: 0.2698 Acc: 0.8965 F1 score: 0.7511 Precision: 0.8261 Recall: 0.7121 \n",
            "val Loss: 0.2773 Acc: 0.8791 F1 score: 0.6944 Precision: 0.7633 Recall: 0.6622 \n",
            "\n",
            "Epoch 17/19\n",
            "----------\n",
            "train Loss: 0.2686 Acc: 0.8957 F1 score: 0.7499 Precision: 0.8229 Recall: 0.7116 \n",
            "val Loss: 0.2778 Acc: 0.8813 F1 score: 0.7059 Precision: 0.7674 Recall: 0.6745 \n",
            "\n",
            "Epoch 18/19\n",
            "----------\n",
            "train Loss: 0.2691 Acc: 0.8940 F1 score: 0.7447 Precision: 0.8188 Recall: 0.7066 \n",
            "val Loss: 0.2772 Acc: 0.8791 F1 score: 0.7043 Precision: 0.7593 Recall: 0.6748 \n",
            "\n",
            "Epoch 19/19\n",
            "----------\n",
            "train Loss: 0.2691 Acc: 0.8967 F1 score: 0.7525 Precision: 0.8254 Recall: 0.7140 \n",
            "val Loss: 0.2787 Acc: 0.8797 F1 score: 0.6830 Precision: 0.7721 Recall: 0.6482 \n",
            "\n",
            "Training complete in 4m 56s\n",
            "Best val F1: 0.718867\n",
            "fold 5\n",
            "Epoch 0/19\n",
            "----------\n",
            "train Loss: 0.3596 Acc: 0.8620 F1 score: 0.6784 Precision: 0.7174 Recall: 0.6562 \n",
            "val Loss: 0.2550 Acc: 0.8989 F1 score: 0.7512 Precision: 0.8587 Recall: 0.7047 \n",
            "\n",
            "Epoch 1/19\n",
            "----------\n",
            "train Loss: 0.2928 Acc: 0.8872 F1 score: 0.7257 Precision: 0.7964 Recall: 0.6901 \n",
            "val Loss: 0.2526 Acc: 0.8984 F1 score: 0.7582 Precision: 0.8430 Recall: 0.7161 \n",
            "\n",
            "Epoch 2/19\n",
            "----------\n",
            "train Loss: 0.2898 Acc: 0.8886 F1 score: 0.7276 Precision: 0.8023 Recall: 0.6908 \n",
            "val Loss: 0.2536 Acc: 0.9005 F1 score: 0.7651 Precision: 0.8467 Recall: 0.7232 \n",
            "\n",
            "Epoch 3/19\n",
            "----------\n",
            "train Loss: 0.2862 Acc: 0.8884 F1 score: 0.7263 Precision: 0.8022 Recall: 0.6893 \n",
            "val Loss: 0.2494 Acc: 0.9027 F1 score: 0.7753 Precision: 0.8450 Recall: 0.7362 \n",
            "\n",
            "Epoch 4/19\n",
            "----------\n",
            "train Loss: 0.2833 Acc: 0.8899 F1 score: 0.7337 Precision: 0.8037 Recall: 0.6977 \n",
            "val Loss: 0.2489 Acc: 0.9021 F1 score: 0.7666 Precision: 0.8554 Recall: 0.7227 \n",
            "\n",
            "Epoch 5/19\n",
            "----------\n",
            "train Loss: 0.2809 Acc: 0.8914 F1 score: 0.7365 Precision: 0.8093 Recall: 0.6994 \n",
            "val Loss: 0.2528 Acc: 0.8995 F1 score: 0.7510 Precision: 0.8634 Recall: 0.7036 \n",
            "\n",
            "Epoch 6/19\n",
            "----------\n",
            "train Loss: 0.2797 Acc: 0.8908 F1 score: 0.7331 Precision: 0.8095 Recall: 0.6954 \n",
            "val Loss: 0.2491 Acc: 0.9027 F1 score: 0.7656 Precision: 0.8612 Recall: 0.7201 \n",
            "\n",
            "Epoch 7/19\n",
            "----------\n",
            "train Loss: 0.2772 Acc: 0.8913 F1 score: 0.7407 Precision: 0.8044 Recall: 0.7059 \n",
            "val Loss: 0.2462 Acc: 0.9021 F1 score: 0.7736 Precision: 0.8441 Recall: 0.7344 \n",
            "\n",
            "Epoch 8/19\n",
            "----------\n",
            "train Loss: 0.2766 Acc: 0.8909 F1 score: 0.7385 Precision: 0.8046 Recall: 0.7032 \n",
            "val Loss: 0.2481 Acc: 0.9005 F1 score: 0.7677 Precision: 0.8426 Recall: 0.7276 \n",
            "\n",
            "Epoch 9/19\n",
            "----------\n",
            "train Loss: 0.2737 Acc: 0.8924 F1 score: 0.7399 Precision: 0.8113 Recall: 0.7029 \n",
            "val Loss: 0.2474 Acc: 0.9011 F1 score: 0.7659 Precision: 0.8491 Recall: 0.7235 \n",
            "\n",
            "Epoch 10/19\n",
            "----------\n",
            "train Loss: 0.2730 Acc: 0.8923 F1 score: 0.7374 Precision: 0.8131 Recall: 0.6994 \n",
            "val Loss: 0.2501 Acc: 0.9021 F1 score: 0.7648 Precision: 0.8587 Recall: 0.7198 \n",
            "\n",
            "Epoch 11/19\n",
            "----------\n",
            "train Loss: 0.2739 Acc: 0.8935 F1 score: 0.7446 Precision: 0.8127 Recall: 0.7081 \n",
            "val Loss: 0.2477 Acc: 0.9011 F1 score: 0.7703 Precision: 0.8423 Recall: 0.7309 \n",
            "\n",
            "Epoch 12/19\n",
            "----------\n",
            "train Loss: 0.2740 Acc: 0.8933 F1 score: 0.7395 Precision: 0.8168 Recall: 0.7008 \n",
            "val Loss: 0.2474 Acc: 0.9000 F1 score: 0.7624 Precision: 0.8473 Recall: 0.7200 \n",
            "\n",
            "Epoch 13/19\n",
            "----------\n",
            "train Loss: 0.2734 Acc: 0.8930 F1 score: 0.7398 Precision: 0.8150 Recall: 0.7017 \n",
            "val Loss: 0.2474 Acc: 0.9011 F1 score: 0.7650 Precision: 0.8506 Recall: 0.7221 \n",
            "\n",
            "Epoch 14/19\n",
            "----------\n",
            "train Loss: 0.2726 Acc: 0.8930 F1 score: 0.7404 Precision: 0.8144 Recall: 0.7026 \n",
            "val Loss: 0.2463 Acc: 0.9021 F1 score: 0.7702 Precision: 0.8495 Recall: 0.7286 \n",
            "\n",
            "Epoch 15/19\n",
            "----------\n",
            "train Loss: 0.2728 Acc: 0.8944 F1 score: 0.7435 Precision: 0.8189 Recall: 0.7051 \n",
            "val Loss: 0.2462 Acc: 0.9011 F1 score: 0.7703 Precision: 0.8423 Recall: 0.7309 \n",
            "\n",
            "Epoch 16/19\n",
            "----------\n",
            "train Loss: 0.2741 Acc: 0.8933 F1 score: 0.7416 Precision: 0.8148 Recall: 0.7039 \n",
            "val Loss: 0.2465 Acc: 0.9005 F1 score: 0.7677 Precision: 0.8426 Recall: 0.7276 \n",
            "\n",
            "Epoch 17/19\n",
            "----------\n",
            "train Loss: 0.2714 Acc: 0.8944 F1 score: 0.7430 Precision: 0.8191 Recall: 0.7044 \n",
            "val Loss: 0.2461 Acc: 0.9011 F1 score: 0.7737 Precision: 0.8375 Recall: 0.7367 \n",
            "\n",
            "Epoch 18/19\n",
            "----------\n",
            "train Loss: 0.2730 Acc: 0.8920 F1 score: 0.7372 Precision: 0.8120 Recall: 0.6994 \n",
            "val Loss: 0.2468 Acc: 0.9005 F1 score: 0.7695 Precision: 0.8401 Recall: 0.7306 \n",
            "\n",
            "Epoch 19/19\n",
            "----------\n",
            "train Loss: 0.2727 Acc: 0.8929 F1 score: 0.7388 Precision: 0.8150 Recall: 0.7006 \n",
            "val Loss: 0.2484 Acc: 0.9011 F1 score: 0.7641 Precision: 0.8521 Recall: 0.7206 \n",
            "\n",
            "Training complete in 4m 55s\n",
            "Best val F1: 0.775269\n",
            "fold 6\n",
            "Epoch 0/19\n",
            "----------\n",
            "train Loss: 0.3286 Acc: 0.8784 F1 score: 0.7050 Precision: 0.7689 Recall: 0.6733 \n",
            "val Loss: 0.2754 Acc: 0.8936 F1 score: 0.7529 Precision: 0.8188 Recall: 0.7167 \n",
            "\n",
            "Epoch 1/19\n",
            "----------\n",
            "train Loss: 0.2896 Acc: 0.8897 F1 score: 0.7329 Precision: 0.8037 Recall: 0.6967 \n",
            "val Loss: 0.2766 Acc: 0.8957 F1 score: 0.7401 Precision: 0.8505 Recall: 0.6945 \n",
            "\n",
            "Epoch 2/19\n",
            "----------\n",
            "train Loss: 0.2846 Acc: 0.8923 F1 score: 0.7426 Precision: 0.8085 Recall: 0.7070 \n",
            "val Loss: 0.2726 Acc: 0.8914 F1 score: 0.7360 Precision: 0.8264 Recall: 0.6949 \n",
            "\n",
            "Epoch 3/19\n",
            "----------\n",
            "train Loss: 0.2813 Acc: 0.8910 F1 score: 0.7354 Precision: 0.8081 Recall: 0.6984 \n",
            "val Loss: 0.2740 Acc: 0.8936 F1 score: 0.7432 Precision: 0.8306 Recall: 0.7020 \n",
            "\n",
            "Epoch 4/19\n",
            "----------\n",
            "train Loss: 0.2795 Acc: 0.8917 F1 score: 0.7431 Precision: 0.8050 Recall: 0.7087 \n",
            "val Loss: 0.2684 Acc: 0.8947 F1 score: 0.7458 Precision: 0.8340 Recall: 0.7041 \n",
            "\n",
            "Epoch 5/19\n",
            "----------\n",
            "train Loss: 0.2789 Acc: 0.8932 F1 score: 0.7427 Precision: 0.8132 Recall: 0.7057 \n",
            "val Loss: 0.2682 Acc: 0.8963 F1 score: 0.7540 Precision: 0.8330 Recall: 0.7139 \n",
            "\n",
            "Epoch 6/19\n",
            "----------\n",
            "train Loss: 0.2766 Acc: 0.8919 F1 score: 0.7429 Precision: 0.8057 Recall: 0.7083 \n",
            "val Loss: 0.2686 Acc: 0.8947 F1 score: 0.7448 Precision: 0.8355 Recall: 0.7027 \n",
            "\n",
            "Epoch 7/19\n",
            "----------\n",
            "train Loss: 0.2721 Acc: 0.8936 F1 score: 0.7457 Precision: 0.8121 Recall: 0.7096 \n",
            "val Loss: 0.2717 Acc: 0.8914 F1 score: 0.7214 Precision: 0.8484 Recall: 0.6758 \n",
            "\n",
            "Epoch 8/19\n",
            "----------\n",
            "train Loss: 0.2737 Acc: 0.8946 F1 score: 0.7508 Precision: 0.8124 Recall: 0.7160 \n",
            "val Loss: 0.2684 Acc: 0.8963 F1 score: 0.7502 Precision: 0.8385 Recall: 0.7080 \n",
            "\n",
            "Epoch 9/19\n",
            "----------\n",
            "train Loss: 0.2713 Acc: 0.8948 F1 score: 0.7480 Precision: 0.8163 Recall: 0.7112 \n",
            "val Loss: 0.2687 Acc: 0.8947 F1 score: 0.7427 Precision: 0.8384 Recall: 0.6997 \n",
            "\n",
            "Epoch 10/19\n",
            "----------\n",
            "train Loss: 0.2710 Acc: 0.8939 F1 score: 0.7442 Precision: 0.8156 Recall: 0.7068 \n",
            "val Loss: 0.2700 Acc: 0.8925 F1 score: 0.7364 Precision: 0.8328 Recall: 0.6940 \n",
            "\n",
            "Epoch 11/19\n",
            "----------\n",
            "train Loss: 0.2714 Acc: 0.8936 F1 score: 0.7461 Precision: 0.8120 Recall: 0.7102 \n",
            "val Loss: 0.2675 Acc: 0.8952 F1 score: 0.7571 Precision: 0.8229 Recall: 0.7206 \n",
            "\n",
            "Epoch 12/19\n",
            "----------\n",
            "train Loss: 0.2710 Acc: 0.8952 F1 score: 0.7480 Precision: 0.8189 Recall: 0.7104 \n",
            "val Loss: 0.2671 Acc: 0.8957 F1 score: 0.7542 Precision: 0.8295 Recall: 0.7150 \n",
            "\n",
            "Epoch 13/19\n",
            "----------\n",
            "train Loss: 0.2705 Acc: 0.8955 F1 score: 0.7504 Precision: 0.8176 Recall: 0.7138 \n",
            "val Loss: 0.2675 Acc: 0.8952 F1 score: 0.7486 Precision: 0.8337 Recall: 0.7074 \n",
            "\n",
            "Epoch 14/19\n",
            "----------\n",
            "train Loss: 0.2696 Acc: 0.8941 F1 score: 0.7472 Precision: 0.8135 Recall: 0.7111 \n",
            "val Loss: 0.2677 Acc: 0.8947 F1 score: 0.7478 Precision: 0.8313 Recall: 0.7071 \n",
            "\n",
            "Epoch 15/19\n",
            "----------\n",
            "train Loss: 0.2704 Acc: 0.8949 F1 score: 0.7488 Precision: 0.8161 Recall: 0.7122 \n",
            "val Loss: 0.2699 Acc: 0.8925 F1 score: 0.7299 Precision: 0.8427 Recall: 0.6852 \n",
            "\n",
            "Epoch 16/19\n",
            "----------\n",
            "train Loss: 0.2687 Acc: 0.8967 F1 score: 0.7529 Precision: 0.8219 Recall: 0.7155 \n",
            "val Loss: 0.2681 Acc: 0.8936 F1 score: 0.7412 Precision: 0.8334 Recall: 0.6991 \n",
            "\n",
            "Epoch 17/19\n",
            "----------\n",
            "train Loss: 0.2697 Acc: 0.8960 F1 score: 0.7499 Precision: 0.8208 Recall: 0.7122 \n",
            "val Loss: 0.2688 Acc: 0.8941 F1 score: 0.7450 Precision: 0.8316 Recall: 0.7038 \n",
            "\n",
            "Epoch 18/19\n",
            "----------\n",
            "train Loss: 0.2680 Acc: 0.8966 F1 score: 0.7521 Precision: 0.8218 Recall: 0.7146 \n",
            "val Loss: 0.2709 Acc: 0.8930 F1 score: 0.7295 Precision: 0.8475 Recall: 0.6841 \n",
            "\n",
            "Epoch 19/19\n",
            "----------\n",
            "train Loss: 0.2697 Acc: 0.8956 F1 score: 0.7503 Precision: 0.8184 Recall: 0.7133 \n",
            "val Loss: 0.2676 Acc: 0.8936 F1 score: 0.7422 Precision: 0.8320 Recall: 0.7006 \n",
            "\n",
            "Training complete in 4m 55s\n",
            "Best val F1: 0.757078\n",
            "fold 7\n",
            "Epoch 0/19\n",
            "----------\n",
            "train Loss: 0.3580 Acc: 0.8601 F1 score: 0.6832 Precision: 0.7131 Recall: 0.6642 \n",
            "val Loss: 0.2599 Acc: 0.8936 F1 score: 0.7659 Precision: 0.8049 Recall: 0.7394 \n",
            "\n",
            "Epoch 1/19\n",
            "----------\n",
            "train Loss: 0.2929 Acc: 0.8889 F1 score: 0.7330 Precision: 0.7995 Recall: 0.6980 \n",
            "val Loss: 0.2627 Acc: 0.8973 F1 score: 0.7664 Precision: 0.8222 Recall: 0.7328 \n",
            "\n",
            "Epoch 2/19\n",
            "----------\n",
            "train Loss: 0.2864 Acc: 0.8912 F1 score: 0.7402 Precision: 0.8050 Recall: 0.7051 \n",
            "val Loss: 0.2558 Acc: 0.8947 F1 score: 0.7642 Precision: 0.8112 Recall: 0.7341 \n",
            "\n",
            "Epoch 3/19\n",
            "----------\n",
            "train Loss: 0.2834 Acc: 0.8904 F1 score: 0.7357 Precision: 0.8051 Recall: 0.6996 \n",
            "val Loss: 0.2588 Acc: 0.8941 F1 score: 0.7591 Precision: 0.8134 Recall: 0.7264 \n",
            "\n",
            "Epoch 4/19\n",
            "----------\n",
            "train Loss: 0.2794 Acc: 0.8906 F1 score: 0.7378 Precision: 0.8041 Recall: 0.7024 \n",
            "val Loss: 0.2586 Acc: 0.8930 F1 score: 0.7635 Precision: 0.8045 Recall: 0.7362 \n",
            "\n",
            "Epoch 5/19\n",
            "----------\n",
            "train Loss: 0.2790 Acc: 0.8904 F1 score: 0.7346 Precision: 0.8061 Recall: 0.6981 \n",
            "val Loss: 0.2554 Acc: 0.8963 F1 score: 0.7730 Precision: 0.8105 Recall: 0.7469 \n",
            "\n",
            "Epoch 6/19\n",
            "----------\n",
            "train Loss: 0.2797 Acc: 0.8917 F1 score: 0.7394 Precision: 0.8086 Recall: 0.7031 \n",
            "val Loss: 0.2575 Acc: 0.8963 F1 score: 0.7596 Precision: 0.8242 Recall: 0.7233 \n",
            "\n",
            "Epoch 7/19\n",
            "----------\n",
            "train Loss: 0.2735 Acc: 0.8948 F1 score: 0.7447 Precision: 0.8204 Recall: 0.7060 \n",
            "val Loss: 0.2559 Acc: 0.8973 F1 score: 0.7745 Precision: 0.8139 Recall: 0.7475 \n",
            "\n",
            "Epoch 8/19\n",
            "----------\n",
            "train Loss: 0.2721 Acc: 0.8931 F1 score: 0.7434 Precision: 0.8120 Recall: 0.7069 \n",
            "val Loss: 0.2562 Acc: 0.8973 F1 score: 0.7753 Precision: 0.8132 Recall: 0.7490 \n",
            "\n",
            "Epoch 9/19\n",
            "----------\n",
            "train Loss: 0.2743 Acc: 0.8930 F1 score: 0.7421 Precision: 0.8130 Recall: 0.7050 \n",
            "val Loss: 0.2564 Acc: 0.8963 F1 score: 0.7714 Precision: 0.8119 Recall: 0.7440 \n",
            "\n",
            "Epoch 10/19\n",
            "----------\n",
            "train Loss: 0.2722 Acc: 0.8936 F1 score: 0.7426 Precision: 0.8155 Recall: 0.7050 \n",
            "val Loss: 0.2563 Acc: 0.8963 F1 score: 0.7714 Precision: 0.8119 Recall: 0.7440 \n",
            "\n",
            "Epoch 11/19\n",
            "----------\n",
            "train Loss: 0.2705 Acc: 0.8960 F1 score: 0.7497 Precision: 0.8217 Recall: 0.7117 \n",
            "val Loss: 0.2570 Acc: 0.8968 F1 score: 0.7664 Precision: 0.8194 Recall: 0.7339 \n",
            "\n",
            "Epoch 12/19\n",
            "----------\n",
            "train Loss: 0.2716 Acc: 0.8944 F1 score: 0.7457 Precision: 0.8166 Recall: 0.7083 \n",
            "val Loss: 0.2572 Acc: 0.8984 F1 score: 0.7761 Precision: 0.8173 Recall: 0.7482 \n",
            "\n",
            "Epoch 13/19\n",
            "----------\n",
            "train Loss: 0.2711 Acc: 0.8944 F1 score: 0.7435 Precision: 0.8193 Recall: 0.7050 \n",
            "val Loss: 0.2565 Acc: 0.8973 F1 score: 0.7706 Precision: 0.8178 Recall: 0.7402 \n",
            "\n",
            "Epoch 14/19\n",
            "----------\n",
            "train Loss: 0.2698 Acc: 0.8952 F1 score: 0.7478 Precision: 0.8190 Recall: 0.7102 \n",
            "val Loss: 0.2567 Acc: 0.8968 F1 score: 0.7664 Precision: 0.8194 Recall: 0.7339 \n",
            "\n",
            "Epoch 15/19\n",
            "----------\n",
            "train Loss: 0.2696 Acc: 0.8964 F1 score: 0.7522 Precision: 0.8212 Recall: 0.7148 \n",
            "val Loss: 0.2569 Acc: 0.8989 F1 score: 0.7761 Precision: 0.8199 Recall: 0.7470 \n",
            "\n",
            "Epoch 16/19\n",
            "----------\n",
            "train Loss: 0.2697 Acc: 0.8941 F1 score: 0.7449 Precision: 0.8161 Recall: 0.7075 \n",
            "val Loss: 0.2571 Acc: 0.8957 F1 score: 0.7722 Precision: 0.8089 Recall: 0.7466 \n",
            "\n",
            "Epoch 17/19\n",
            "----------\n",
            "train Loss: 0.2707 Acc: 0.8935 F1 score: 0.7435 Precision: 0.8139 Recall: 0.7064 \n",
            "val Loss: 0.2569 Acc: 0.8973 F1 score: 0.7738 Precision: 0.8146 Recall: 0.7461 \n",
            "\n",
            "Epoch 18/19\n",
            "----------\n",
            "train Loss: 0.2706 Acc: 0.8946 F1 score: 0.7457 Precision: 0.8179 Recall: 0.7079 \n",
            "val Loss: 0.2586 Acc: 0.8963 F1 score: 0.7568 Precision: 0.8275 Recall: 0.7188 \n",
            "\n",
            "Epoch 19/19\n",
            "----------\n",
            "train Loss: 0.2704 Acc: 0.8951 F1 score: 0.7487 Precision: 0.8177 Recall: 0.7116 \n",
            "val Loss: 0.2569 Acc: 0.8984 F1 score: 0.7705 Precision: 0.8232 Recall: 0.7378 \n",
            "\n",
            "Training complete in 4m 55s\n",
            "Best val F1: 0.776122\n",
            "fold 8\n",
            "Epoch 0/19\n",
            "----------\n",
            "train Loss: 0.3723 Acc: 0.8425 F1 score: 0.6723 Precision: 0.6804 Recall: 0.6653 \n",
            "val Loss: 0.2705 Acc: 0.8995 F1 score: 0.7333 Precision: 0.8266 Recall: 0.6908 \n",
            "\n",
            "Epoch 1/19\n",
            "----------\n",
            "train Loss: 0.2900 Acc: 0.8879 F1 score: 0.7374 Precision: 0.7958 Recall: 0.7047 \n",
            "val Loss: 0.2674 Acc: 0.8947 F1 score: 0.7296 Precision: 0.8007 Recall: 0.6930 \n",
            "\n",
            "Epoch 2/19\n",
            "----------\n",
            "train Loss: 0.2851 Acc: 0.8903 F1 score: 0.7386 Precision: 0.8063 Recall: 0.7029 \n",
            "val Loss: 0.2639 Acc: 0.9037 F1 score: 0.7502 Precision: 0.8343 Recall: 0.7082 \n",
            "\n",
            "Epoch 3/19\n",
            "----------\n",
            "train Loss: 0.2833 Acc: 0.8910 F1 score: 0.7408 Precision: 0.8080 Recall: 0.7050 \n",
            "val Loss: 0.2655 Acc: 0.9032 F1 score: 0.7438 Precision: 0.8394 Recall: 0.6996 \n",
            "\n",
            "Epoch 4/19\n",
            "----------\n",
            "train Loss: 0.2804 Acc: 0.8907 F1 score: 0.7386 Precision: 0.8084 Recall: 0.7023 \n",
            "val Loss: 0.2665 Acc: 0.9011 F1 score: 0.7370 Precision: 0.8332 Recall: 0.6934 \n",
            "\n",
            "Epoch 5/19\n",
            "----------\n",
            "train Loss: 0.2791 Acc: 0.8919 F1 score: 0.7439 Precision: 0.8100 Recall: 0.7082 \n",
            "val Loss: 0.2690 Acc: 0.9021 F1 score: 0.7477 Precision: 0.8268 Recall: 0.7072 \n",
            "\n",
            "Epoch 6/19\n",
            "----------\n",
            "train Loss: 0.2763 Acc: 0.8932 F1 score: 0.7481 Precision: 0.8128 Recall: 0.7125 \n",
            "val Loss: 0.2665 Acc: 0.9000 F1 score: 0.7133 Precision: 0.8628 Recall: 0.6647 \n",
            "\n",
            "Epoch 7/19\n",
            "----------\n",
            "train Loss: 0.2763 Acc: 0.8925 F1 score: 0.7344 Precision: 0.8239 Recall: 0.6935 \n",
            "val Loss: 0.2654 Acc: 0.9000 F1 score: 0.7175 Precision: 0.8549 Recall: 0.6697 \n",
            "\n",
            "Epoch 8/19\n",
            "----------\n",
            "train Loss: 0.2739 Acc: 0.8927 F1 score: 0.7424 Precision: 0.8158 Recall: 0.7046 \n",
            "val Loss: 0.2648 Acc: 0.9000 F1 score: 0.7365 Precision: 0.8263 Recall: 0.6944 \n",
            "\n",
            "Epoch 9/19\n",
            "----------\n",
            "train Loss: 0.2732 Acc: 0.8921 F1 score: 0.7399 Precision: 0.8150 Recall: 0.7020 \n",
            "val Loss: 0.2667 Acc: 0.9000 F1 score: 0.7189 Precision: 0.8524 Recall: 0.6713 \n",
            "\n",
            "Epoch 10/19\n",
            "----------\n",
            "train Loss: 0.2733 Acc: 0.8919 F1 score: 0.7411 Precision: 0.8128 Recall: 0.7040 \n",
            "val Loss: 0.2659 Acc: 0.9005 F1 score: 0.7288 Precision: 0.8408 Recall: 0.6832 \n",
            "\n",
            "Epoch 11/19\n",
            "----------\n",
            "train Loss: 0.2726 Acc: 0.8923 F1 score: 0.7416 Precision: 0.8142 Recall: 0.7042 \n",
            "val Loss: 0.2673 Acc: 0.9005 F1 score: 0.7197 Precision: 0.8560 Recall: 0.6716 \n",
            "\n",
            "Epoch 12/19\n",
            "----------\n",
            "train Loss: 0.2694 Acc: 0.8933 F1 score: 0.7448 Precision: 0.8165 Recall: 0.7073 \n",
            "val Loss: 0.2665 Acc: 0.9005 F1 score: 0.7350 Precision: 0.8321 Recall: 0.6914 \n",
            "\n",
            "Epoch 13/19\n",
            "----------\n",
            "train Loss: 0.2723 Acc: 0.8937 F1 score: 0.7456 Precision: 0.8180 Recall: 0.7079 \n",
            "val Loss: 0.2673 Acc: 0.9016 F1 score: 0.7425 Precision: 0.8298 Recall: 0.7003 \n",
            "\n",
            "Epoch 14/19\n",
            "----------\n",
            "train Loss: 0.2703 Acc: 0.8933 F1 score: 0.7443 Precision: 0.8170 Recall: 0.7067 \n",
            "val Loss: 0.2668 Acc: 0.9016 F1 score: 0.7402 Precision: 0.8328 Recall: 0.6970 \n",
            "\n",
            "Epoch 15/19\n",
            "----------\n",
            "train Loss: 0.2706 Acc: 0.8934 F1 score: 0.7447 Precision: 0.8172 Recall: 0.7071 \n",
            "val Loss: 0.2665 Acc: 0.9016 F1 score: 0.7413 Precision: 0.8313 Recall: 0.6987 \n",
            "\n",
            "Epoch 16/19\n",
            "----------\n",
            "train Loss: 0.2705 Acc: 0.8943 F1 score: 0.7455 Precision: 0.8216 Recall: 0.7068 \n",
            "val Loss: 0.2668 Acc: 0.9021 F1 score: 0.7444 Precision: 0.8309 Recall: 0.7023 \n",
            "\n",
            "Epoch 17/19\n",
            "----------\n",
            "train Loss: 0.2700 Acc: 0.8932 F1 score: 0.7431 Precision: 0.8180 Recall: 0.7050 \n",
            "val Loss: 0.2669 Acc: 0.9011 F1 score: 0.7382 Precision: 0.8316 Recall: 0.6950 \n",
            "\n",
            "Epoch 18/19\n",
            "----------\n",
            "train Loss: 0.2702 Acc: 0.8929 F1 score: 0.7418 Precision: 0.8174 Recall: 0.7036 \n",
            "val Loss: 0.2669 Acc: 0.9000 F1 score: 0.7255 Precision: 0.8416 Recall: 0.6796 \n",
            "\n",
            "Epoch 19/19\n",
            "----------\n",
            "train Loss: 0.2719 Acc: 0.8933 F1 score: 0.7440 Precision: 0.8177 Recall: 0.7060 \n",
            "val Loss: 0.2665 Acc: 0.9027 F1 score: 0.7441 Precision: 0.8351 Recall: 0.7009 \n",
            "\n",
            "Training complete in 4m 56s\n",
            "Best val F1: 0.750249\n",
            "fold 9\n",
            "Epoch 0/19\n",
            "----------\n",
            "train Loss: 0.3296 Acc: 0.8794 F1 score: 0.6895 Precision: 0.7893 Recall: 0.6526 \n",
            "val Loss: 0.2844 Acc: 0.8861 F1 score: 0.6930 Precision: 0.7881 Recall: 0.6556 \n",
            "\n",
            "Epoch 1/19\n",
            "----------\n",
            "train Loss: 0.2878 Acc: 0.8898 F1 score: 0.7362 Precision: 0.8057 Recall: 0.7001 \n",
            "val Loss: 0.2771 Acc: 0.8888 F1 score: 0.7211 Precision: 0.7827 Recall: 0.6881 \n",
            "\n",
            "Epoch 2/19\n",
            "----------\n",
            "train Loss: 0.2862 Acc: 0.8904 F1 score: 0.7368 Precision: 0.8080 Recall: 0.7003 \n",
            "val Loss: 0.2798 Acc: 0.8888 F1 score: 0.7114 Precision: 0.7892 Recall: 0.6750 \n",
            "\n",
            "Epoch 3/19\n",
            "----------\n",
            "train Loss: 0.2841 Acc: 0.8925 F1 score: 0.7440 Precision: 0.8125 Recall: 0.7076 \n",
            "val Loss: 0.2765 Acc: 0.8930 F1 score: 0.7071 Precision: 0.8208 Recall: 0.6645 \n",
            "\n",
            "Epoch 4/19\n",
            "----------\n",
            "train Loss: 0.2810 Acc: 0.8930 F1 score: 0.7445 Precision: 0.8148 Recall: 0.7075 \n",
            "val Loss: 0.2739 Acc: 0.8898 F1 score: 0.6802 Precision: 0.8310 Recall: 0.6382 \n",
            "\n",
            "Epoch 5/19\n",
            "----------\n",
            "train Loss: 0.2798 Acc: 0.8911 F1 score: 0.7371 Precision: 0.8117 Recall: 0.6995 \n",
            "val Loss: 0.2731 Acc: 0.8898 F1 score: 0.7065 Precision: 0.7995 Recall: 0.6675 \n",
            "\n",
            "Epoch 6/19\n",
            "----------\n",
            "train Loss: 0.2781 Acc: 0.8924 F1 score: 0.7429 Precision: 0.8129 Recall: 0.7061 \n",
            "val Loss: 0.2731 Acc: 0.8914 F1 score: 0.7189 Precision: 0.7980 Recall: 0.6815 \n",
            "\n",
            "Epoch 7/19\n",
            "----------\n",
            "train Loss: 0.2753 Acc: 0.8942 F1 score: 0.7505 Precision: 0.8147 Recall: 0.7149 \n",
            "val Loss: 0.2721 Acc: 0.8925 F1 score: 0.7168 Precision: 0.8063 Recall: 0.6772 \n",
            "\n",
            "Epoch 8/19\n",
            "----------\n",
            "train Loss: 0.2725 Acc: 0.8938 F1 score: 0.7458 Precision: 0.8175 Recall: 0.7083 \n",
            "val Loss: 0.2717 Acc: 0.8904 F1 score: 0.7210 Precision: 0.7906 Recall: 0.6857 \n",
            "\n",
            "Epoch 9/19\n",
            "----------\n",
            "train Loss: 0.2726 Acc: 0.8949 F1 score: 0.7476 Precision: 0.8220 Recall: 0.7091 \n",
            "val Loss: 0.2720 Acc: 0.8930 F1 score: 0.7201 Precision: 0.8064 Recall: 0.6808 \n",
            "\n",
            "Epoch 10/19\n",
            "----------\n",
            "train Loss: 0.2731 Acc: 0.8926 F1 score: 0.7437 Precision: 0.8130 Recall: 0.7071 \n",
            "val Loss: 0.2714 Acc: 0.8925 F1 score: 0.7287 Precision: 0.7958 Recall: 0.6935 \n",
            "\n",
            "Epoch 11/19\n",
            "----------\n",
            "train Loss: 0.2708 Acc: 0.8949 F1 score: 0.7481 Precision: 0.8213 Recall: 0.7100 \n",
            "val Loss: 0.2720 Acc: 0.8930 F1 score: 0.7137 Precision: 0.8130 Recall: 0.6726 \n",
            "\n",
            "Epoch 12/19\n",
            "----------\n",
            "train Loss: 0.2715 Acc: 0.8950 F1 score: 0.7494 Precision: 0.8206 Recall: 0.7117 \n",
            "val Loss: 0.2719 Acc: 0.8936 F1 score: 0.7292 Precision: 0.8011 Recall: 0.6925 \n",
            "\n",
            "Epoch 13/19\n",
            "----------\n",
            "train Loss: 0.2714 Acc: 0.8919 F1 score: 0.7437 Precision: 0.8096 Recall: 0.7080 \n",
            "val Loss: 0.2718 Acc: 0.8930 F1 score: 0.7284 Precision: 0.7989 Recall: 0.6922 \n",
            "\n",
            "Epoch 14/19\n",
            "----------\n",
            "train Loss: 0.2709 Acc: 0.8931 F1 score: 0.7445 Precision: 0.8152 Recall: 0.7074 \n",
            "val Loss: 0.2716 Acc: 0.8930 F1 score: 0.7318 Precision: 0.7962 Recall: 0.6970 \n",
            "\n",
            "Epoch 15/19\n",
            "----------\n",
            "train Loss: 0.2699 Acc: 0.8932 F1 score: 0.7447 Precision: 0.8157 Recall: 0.7075 \n",
            "val Loss: 0.2715 Acc: 0.8925 F1 score: 0.7310 Precision: 0.7941 Recall: 0.6967 \n",
            "\n",
            "Epoch 16/19\n",
            "----------\n",
            "train Loss: 0.2708 Acc: 0.8928 F1 score: 0.7420 Precision: 0.8159 Recall: 0.7042 \n",
            "val Loss: 0.2720 Acc: 0.8947 F1 score: 0.7296 Precision: 0.8068 Recall: 0.6915 \n",
            "\n",
            "Epoch 17/19\n",
            "----------\n",
            "train Loss: 0.2703 Acc: 0.8936 F1 score: 0.7458 Precision: 0.8165 Recall: 0.7085 \n",
            "val Loss: 0.2725 Acc: 0.8952 F1 score: 0.7207 Precision: 0.8196 Recall: 0.6788 \n",
            "\n",
            "Epoch 18/19\n",
            "----------\n",
            "train Loss: 0.2707 Acc: 0.8933 F1 score: 0.7458 Precision: 0.8148 Recall: 0.7090 \n",
            "val Loss: 0.2738 Acc: 0.8952 F1 score: 0.7075 Precision: 0.8376 Recall: 0.6625 \n",
            "\n",
            "Epoch 19/19\n",
            "----------\n",
            "train Loss: 0.2706 Acc: 0.8932 F1 score: 0.7460 Precision: 0.8143 Recall: 0.7095 \n",
            "val Loss: 0.2719 Acc: 0.8925 F1 score: 0.7287 Precision: 0.7958 Recall: 0.6935 \n",
            "\n",
            "Training complete in 4m 55s\n",
            "Best val F1: 0.731784\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56mXTj33qQbZ"
      },
      "source": [
        "Across all folds we get around 0.7496 F1-score for 10 years prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_w_I2JhacrvU"
      },
      "source": [
        "#5 years"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFVglNN8_0sN",
        "outputId": "500d8f2d-ce91-474a-8e0d-2b0a7e59ac9b"
      },
      "source": [
        "kfold = KFold(n_splits=10, shuffle=True)\n",
        "grdf5 = grdf5.drop(['IDS'],axis=1) #ID are not relevant\n",
        "# K-fold Cross Validation model evaluation\n",
        "for fold, (train_ids, test_ids) in enumerate(kfold.split(grdf5)):\n",
        "  print(f\"fold {fold}\")\n",
        "  model = Model()\n",
        "  model = model.to(device)\n",
        "  lr=0.005\n",
        "  optimizer = optim.Adam(model.parameters(),lr=lr)\n",
        "  criterion = nn.BCELoss()\n",
        "  scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "  train_subsampler = SubsetRandomSampler(train_ids)\n",
        "  test_subsampler = SubsetRandomSampler(test_ids)\n",
        "\n",
        "\n",
        "  dataf5 = DataforSet(grdf5, '5_years')\n",
        "\n",
        "  dataloaders =  {'train': DataLoader(dataf5, batch_size=150, sampler=train_subsampler),\n",
        "                  'val': DataLoader(dataf5, batch_size=150, sampler=test_subsampler)}\n",
        "\n",
        "  model = train_model(model, dataloaders, criterion, optimizer, scheduler, num_epochs=20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fold 0\n",
            "Epoch 0/19\n",
            "----------\n",
            "train Loss: 0.4558 Acc: 0.7951 F1 score: 0.6823 Precision: 0.7362 Recall: 0.6627 \n",
            "val Loss: 0.4048 Acc: 0.8155 F1 score: 0.7068 Precision: 0.7929 Recall: 0.6805 \n",
            "\n",
            "Epoch 1/19\n",
            "----------\n",
            "train Loss: 0.3937 Acc: 0.8279 F1 score: 0.7444 Precision: 0.7868 Recall: 0.7224 \n",
            "val Loss: 0.3837 Acc: 0.8192 F1 score: 0.7287 Precision: 0.7810 Recall: 0.7055 \n",
            "\n",
            "Epoch 2/19\n",
            "----------\n",
            "train Loss: 0.3908 Acc: 0.8350 F1 score: 0.7547 Precision: 0.7996 Recall: 0.7313 \n",
            "val Loss: 0.3850 Acc: 0.8183 F1 score: 0.7138 Precision: 0.7952 Recall: 0.6871 \n",
            "\n",
            "Epoch 3/19\n",
            "----------\n",
            "train Loss: 0.3826 Acc: 0.8341 F1 score: 0.7591 Precision: 0.7920 Recall: 0.7395 \n",
            "val Loss: 0.3714 Acc: 0.8183 F1 score: 0.7295 Precision: 0.7773 Recall: 0.7072 \n",
            "\n",
            "Epoch 4/19\n",
            "----------\n",
            "train Loss: 0.3829 Acc: 0.8336 F1 score: 0.7565 Precision: 0.7930 Recall: 0.7357 \n",
            "val Loss: 0.4029 Acc: 0.8090 F1 score: 0.6796 Precision: 0.8036 Recall: 0.6548 \n",
            "\n",
            "Epoch 5/19\n",
            "----------\n",
            "train Loss: 0.3782 Acc: 0.8368 F1 score: 0.7644 Precision: 0.7949 Recall: 0.7456 \n",
            "val Loss: 0.3694 Acc: 0.8229 F1 score: 0.7490 Precision: 0.7748 Recall: 0.7329 \n",
            "\n",
            "Epoch 6/19\n",
            "----------\n",
            "train Loss: 0.3771 Acc: 0.8345 F1 score: 0.7574 Precision: 0.7949 Recall: 0.7362 \n",
            "val Loss: 0.3785 Acc: 0.8247 F1 score: 0.7300 Precision: 0.7997 Recall: 0.7033 \n",
            "\n",
            "Epoch 7/19\n",
            "----------\n",
            "train Loss: 0.3701 Acc: 0.8395 F1 score: 0.7627 Precision: 0.8054 Recall: 0.7395 \n",
            "val Loss: 0.3789 Acc: 0.8238 F1 score: 0.7300 Precision: 0.7961 Recall: 0.7038 \n",
            "\n",
            "Epoch 8/19\n",
            "----------\n",
            "train Loss: 0.3687 Acc: 0.8408 F1 score: 0.7679 Precision: 0.8037 Recall: 0.7469 \n",
            "val Loss: 0.3740 Acc: 0.8173 F1 score: 0.7327 Precision: 0.7719 Recall: 0.7125 \n",
            "\n",
            "Epoch 9/19\n",
            "----------\n",
            "train Loss: 0.3671 Acc: 0.8399 F1 score: 0.7678 Precision: 0.8009 Recall: 0.7478 \n",
            "val Loss: 0.3704 Acc: 0.8201 F1 score: 0.7410 Precision: 0.7732 Recall: 0.7227 \n",
            "\n",
            "Epoch 10/19\n",
            "----------\n",
            "train Loss: 0.3680 Acc: 0.8408 F1 score: 0.7690 Precision: 0.8025 Recall: 0.7488 \n",
            "val Loss: 0.3734 Acc: 0.8210 F1 score: 0.7412 Precision: 0.7756 Recall: 0.7221 \n",
            "\n",
            "Epoch 11/19\n",
            "----------\n",
            "train Loss: 0.3670 Acc: 0.8409 F1 score: 0.7683 Precision: 0.8037 Recall: 0.7474 \n",
            "val Loss: 0.3759 Acc: 0.8201 F1 score: 0.7314 Precision: 0.7814 Recall: 0.7085 \n",
            "\n",
            "Epoch 12/19\n",
            "----------\n",
            "train Loss: 0.3677 Acc: 0.8412 F1 score: 0.7702 Precision: 0.8026 Recall: 0.7504 \n",
            "val Loss: 0.3710 Acc: 0.8210 F1 score: 0.7397 Precision: 0.7768 Recall: 0.7198 \n",
            "\n",
            "Epoch 13/19\n",
            "----------\n",
            "train Loss: 0.3679 Acc: 0.8381 F1 score: 0.7645 Precision: 0.7989 Recall: 0.7442 \n",
            "val Loss: 0.3708 Acc: 0.8238 F1 score: 0.7418 Precision: 0.7831 Recall: 0.7204 \n",
            "\n",
            "Epoch 14/19\n",
            "----------\n",
            "train Loss: 0.3657 Acc: 0.8397 F1 score: 0.7664 Precision: 0.8018 Recall: 0.7456 \n",
            "val Loss: 0.3841 Acc: 0.8266 F1 score: 0.7320 Precision: 0.8045 Recall: 0.7045 \n",
            "\n",
            "Epoch 15/19\n",
            "----------\n",
            "train Loss: 0.3642 Acc: 0.8404 F1 score: 0.7678 Precision: 0.8026 Recall: 0.7472 \n",
            "val Loss: 0.3721 Acc: 0.8238 F1 score: 0.7478 Precision: 0.7780 Recall: 0.7299 \n",
            "\n",
            "Epoch 16/19\n",
            "----------\n",
            "train Loss: 0.3663 Acc: 0.8412 F1 score: 0.7697 Precision: 0.8031 Recall: 0.7495 \n",
            "val Loss: 0.3722 Acc: 0.8201 F1 score: 0.7322 Precision: 0.7806 Recall: 0.7097 \n",
            "\n",
            "Epoch 17/19\n",
            "----------\n",
            "train Loss: 0.3655 Acc: 0.8396 F1 score: 0.7671 Precision: 0.8007 Recall: 0.7469 \n",
            "val Loss: 0.3734 Acc: 0.8247 F1 score: 0.7450 Precision: 0.7829 Recall: 0.7246 \n",
            "\n",
            "Epoch 18/19\n",
            "----------\n",
            "train Loss: 0.3689 Acc: 0.8410 F1 score: 0.7689 Precision: 0.8033 Recall: 0.7484 \n",
            "val Loss: 0.3714 Acc: 0.8229 F1 score: 0.7408 Precision: 0.7812 Recall: 0.7198 \n",
            "\n",
            "Epoch 19/19\n",
            "----------\n",
            "train Loss: 0.3652 Acc: 0.8398 F1 score: 0.7671 Precision: 0.8013 Recall: 0.7467 \n",
            "val Loss: 0.3792 Acc: 0.8238 F1 score: 0.7281 Precision: 0.7985 Recall: 0.7015 \n",
            "\n",
            "Training complete in 2m 52s\n",
            "Best val F1: 0.749035\n",
            "fold 1\n",
            "Epoch 0/19\n",
            "----------\n",
            "train Loss: 0.4751 Acc: 0.7761 F1 score: 0.6646 Precision: 0.6991 Recall: 0.6500 \n",
            "val Loss: 0.3512 Acc: 0.8404 F1 score: 0.7722 Precision: 0.7954 Recall: 0.7564 \n",
            "\n",
            "Epoch 1/19\n",
            "----------\n",
            "train Loss: 0.4007 Acc: 0.8264 F1 score: 0.7432 Precision: 0.7846 Recall: 0.7216 \n",
            "val Loss: 0.3390 Acc: 0.8469 F1 score: 0.7786 Precision: 0.8084 Recall: 0.7594 \n",
            "\n",
            "Epoch 2/19\n",
            "----------\n",
            "train Loss: 0.3916 Acc: 0.8267 F1 score: 0.7472 Precision: 0.7820 Recall: 0.7274 \n",
            "val Loss: 0.3419 Acc: 0.8478 F1 score: 0.7748 Precision: 0.8162 Recall: 0.7514 \n",
            "\n",
            "Epoch 3/19\n",
            "----------\n",
            "train Loss: 0.3843 Acc: 0.8338 F1 score: 0.7568 Precision: 0.7943 Recall: 0.7357 \n",
            "val Loss: 0.3385 Acc: 0.8469 F1 score: 0.7779 Precision: 0.8092 Recall: 0.7582 \n",
            "\n",
            "Epoch 4/19\n",
            "----------\n",
            "train Loss: 0.3786 Acc: 0.8334 F1 score: 0.7598 Precision: 0.7902 Recall: 0.7412 \n",
            "val Loss: 0.3404 Acc: 0.8487 F1 score: 0.7759 Precision: 0.8182 Recall: 0.7520 \n",
            "\n",
            "Epoch 5/19\n",
            "----------\n",
            "train Loss: 0.3817 Acc: 0.8365 F1 score: 0.7554 Precision: 0.8049 Recall: 0.7307 \n",
            "val Loss: 0.3381 Acc: 0.8496 F1 score: 0.7796 Precision: 0.8165 Recall: 0.7576 \n",
            "\n",
            "Epoch 6/19\n",
            "----------\n",
            "train Loss: 0.3771 Acc: 0.8356 F1 score: 0.7620 Precision: 0.7945 Recall: 0.7425 \n",
            "val Loss: 0.3406 Acc: 0.8450 F1 score: 0.7644 Precision: 0.8203 Recall: 0.7372 \n",
            "\n",
            "Epoch 7/19\n",
            "----------\n",
            "train Loss: 0.3735 Acc: 0.8373 F1 score: 0.7639 Precision: 0.7980 Recall: 0.7437 \n",
            "val Loss: 0.3441 Acc: 0.8376 F1 score: 0.7474 Precision: 0.8153 Recall: 0.7186 \n",
            "\n",
            "Epoch 8/19\n",
            "----------\n",
            "train Loss: 0.3731 Acc: 0.8378 F1 score: 0.7639 Precision: 0.7996 Recall: 0.7431 \n",
            "val Loss: 0.3370 Acc: 0.8515 F1 score: 0.7817 Precision: 0.8205 Recall: 0.7588 \n",
            "\n",
            "Epoch 9/19\n",
            "----------\n",
            "train Loss: 0.3705 Acc: 0.8381 F1 score: 0.7644 Precision: 0.8001 Recall: 0.7435 \n",
            "val Loss: 0.3404 Acc: 0.8423 F1 score: 0.7582 Precision: 0.8183 Recall: 0.7304 \n",
            "\n",
            "Epoch 10/19\n",
            "----------\n",
            "train Loss: 0.3697 Acc: 0.8377 F1 score: 0.7640 Precision: 0.7991 Recall: 0.7434 \n",
            "val Loss: 0.3391 Acc: 0.8459 F1 score: 0.7692 Precision: 0.8170 Recall: 0.7440 \n",
            "\n",
            "Epoch 11/19\n",
            "----------\n",
            "train Loss: 0.3737 Acc: 0.8343 F1 score: 0.7599 Precision: 0.7928 Recall: 0.7403 \n",
            "val Loss: 0.3384 Acc: 0.8533 F1 score: 0.7837 Precision: 0.8245 Recall: 0.7600 \n",
            "\n",
            "Epoch 12/19\n",
            "----------\n",
            "train Loss: 0.3696 Acc: 0.8382 F1 score: 0.7644 Precision: 0.8004 Recall: 0.7435 \n",
            "val Loss: 0.3392 Acc: 0.8487 F1 score: 0.7744 Precision: 0.8202 Recall: 0.7495 \n",
            "\n",
            "Epoch 13/19\n",
            "----------\n",
            "train Loss: 0.3701 Acc: 0.8372 F1 score: 0.7623 Precision: 0.7994 Recall: 0.7410 \n",
            "val Loss: 0.3385 Acc: 0.8459 F1 score: 0.7692 Precision: 0.8170 Recall: 0.7440 \n",
            "\n",
            "Epoch 14/19\n",
            "----------\n",
            "train Loss: 0.3671 Acc: 0.8388 F1 score: 0.7651 Precision: 0.8016 Recall: 0.7439 \n",
            "val Loss: 0.3387 Acc: 0.8459 F1 score: 0.7700 Precision: 0.8159 Recall: 0.7452 \n",
            "\n",
            "Epoch 15/19\n",
            "----------\n",
            "train Loss: 0.3696 Acc: 0.8386 F1 score: 0.7642 Precision: 0.8019 Recall: 0.7427 \n",
            "val Loss: 0.3377 Acc: 0.8496 F1 score: 0.7823 Precision: 0.8132 Recall: 0.7625 \n",
            "\n",
            "Epoch 16/19\n",
            "----------\n",
            "train Loss: 0.3671 Acc: 0.8407 F1 score: 0.7682 Precision: 0.8041 Recall: 0.7472 \n",
            "val Loss: 0.3395 Acc: 0.8478 F1 score: 0.7755 Precision: 0.8152 Recall: 0.7526 \n",
            "\n",
            "Epoch 17/19\n",
            "----------\n",
            "train Loss: 0.3690 Acc: 0.8386 F1 score: 0.7653 Precision: 0.8007 Recall: 0.7446 \n",
            "val Loss: 0.3441 Acc: 0.8367 F1 score: 0.7481 Precision: 0.8104 Recall: 0.7205 \n",
            "\n",
            "Epoch 18/19\n",
            "----------\n",
            "train Loss: 0.3687 Acc: 0.8395 F1 score: 0.7662 Precision: 0.8024 Recall: 0.7451 \n",
            "val Loss: 0.3377 Acc: 0.8469 F1 score: 0.7717 Precision: 0.8170 Recall: 0.7470 \n",
            "\n",
            "Epoch 19/19\n",
            "----------\n",
            "train Loss: 0.3687 Acc: 0.8399 F1 score: 0.7668 Precision: 0.8030 Recall: 0.7457 \n",
            "val Loss: 0.3393 Acc: 0.8506 F1 score: 0.7793 Precision: 0.8203 Recall: 0.7557 \n",
            "\n",
            "Training complete in 2m 52s\n",
            "Best val F1: 0.783698\n",
            "fold 2\n",
            "Epoch 0/19\n",
            "----------\n",
            "train Loss: 0.4739 Acc: 0.7767 F1 score: 0.6900 Precision: 0.7004 Recall: 0.6825 \n",
            "val Loss: 0.4062 Acc: 0.7970 F1 score: 0.6974 Precision: 0.7377 Recall: 0.6792 \n",
            "\n",
            "Epoch 1/19\n",
            "----------\n",
            "train Loss: 0.3947 Acc: 0.8287 F1 score: 0.7457 Precision: 0.7884 Recall: 0.7236 \n",
            "val Loss: 0.3867 Acc: 0.8072 F1 score: 0.6995 Precision: 0.7655 Recall: 0.6764 \n",
            "\n",
            "Epoch 2/19\n",
            "----------\n",
            "train Loss: 0.3849 Acc: 0.8311 F1 score: 0.7527 Precision: 0.7893 Recall: 0.7321 \n",
            "val Loss: 0.3874 Acc: 0.8118 F1 score: 0.7254 Precision: 0.7596 Recall: 0.7071 \n",
            "\n",
            "Epoch 3/19\n",
            "----------\n",
            "train Loss: 0.3820 Acc: 0.8328 F1 score: 0.7545 Precision: 0.7927 Recall: 0.7332 \n",
            "val Loss: 0.3800 Acc: 0.8109 F1 score: 0.7176 Precision: 0.7622 Recall: 0.6969 \n",
            "\n",
            "Epoch 4/19\n",
            "----------\n",
            "train Loss: 0.3789 Acc: 0.8367 F1 score: 0.7603 Precision: 0.7990 Recall: 0.7386 \n",
            "val Loss: 0.3881 Acc: 0.8072 F1 score: 0.7310 Precision: 0.7472 Recall: 0.7196 \n",
            "\n",
            "Epoch 5/19\n",
            "----------\n",
            "train Loss: 0.3764 Acc: 0.8376 F1 score: 0.7621 Precision: 0.8002 Recall: 0.7405 \n",
            "val Loss: 0.3780 Acc: 0.8155 F1 score: 0.7348 Precision: 0.7633 Recall: 0.7180 \n",
            "\n",
            "Epoch 6/19\n",
            "----------\n",
            "train Loss: 0.3727 Acc: 0.8380 F1 score: 0.7622 Precision: 0.8014 Recall: 0.7402 \n",
            "val Loss: 0.3794 Acc: 0.8137 F1 score: 0.7256 Precision: 0.7643 Recall: 0.7059 \n",
            "\n",
            "Epoch 7/19\n",
            "----------\n",
            "train Loss: 0.3695 Acc: 0.8398 F1 score: 0.7671 Precision: 0.8017 Recall: 0.7465 \n",
            "val Loss: 0.3818 Acc: 0.8192 F1 score: 0.7224 Precision: 0.7844 Recall: 0.6976 \n",
            "\n",
            "Epoch 8/19\n",
            "----------\n",
            "train Loss: 0.3676 Acc: 0.8431 F1 score: 0.7703 Precision: 0.8091 Recall: 0.7481 \n",
            "val Loss: 0.3786 Acc: 0.8201 F1 score: 0.7186 Precision: 0.7923 Recall: 0.6923 \n",
            "\n",
            "Epoch 9/19\n",
            "----------\n",
            "train Loss: 0.3669 Acc: 0.8414 F1 score: 0.7688 Precision: 0.8051 Recall: 0.7475 \n",
            "val Loss: 0.3816 Acc: 0.8127 F1 score: 0.6964 Precision: 0.7906 Recall: 0.6705 \n",
            "\n",
            "Epoch 10/19\n",
            "----------\n",
            "train Loss: 0.3676 Acc: 0.8418 F1 score: 0.7674 Precision: 0.8081 Recall: 0.7446 \n",
            "val Loss: 0.3758 Acc: 0.8183 F1 score: 0.7286 Precision: 0.7752 Recall: 0.7066 \n",
            "\n",
            "Epoch 11/19\n",
            "----------\n",
            "train Loss: 0.3666 Acc: 0.8418 F1 score: 0.7688 Precision: 0.8064 Recall: 0.7471 \n",
            "val Loss: 0.3763 Acc: 0.8155 F1 score: 0.7300 Precision: 0.7663 Recall: 0.7108 \n",
            "\n",
            "Epoch 12/19\n",
            "----------\n",
            "train Loss: 0.3664 Acc: 0.8413 F1 score: 0.7679 Precision: 0.8058 Recall: 0.7461 \n",
            "val Loss: 0.3766 Acc: 0.8173 F1 score: 0.7327 Precision: 0.7693 Recall: 0.7132 \n",
            "\n",
            "Epoch 13/19\n",
            "----------\n",
            "train Loss: 0.3640 Acc: 0.8455 F1 score: 0.7753 Precision: 0.8112 Recall: 0.7539 \n",
            "val Loss: 0.3770 Acc: 0.8155 F1 score: 0.7275 Precision: 0.7680 Recall: 0.7072 \n",
            "\n",
            "Epoch 14/19\n",
            "----------\n",
            "train Loss: 0.3638 Acc: 0.8423 F1 score: 0.7683 Precision: 0.8088 Recall: 0.7455 \n",
            "val Loss: 0.3764 Acc: 0.8127 F1 score: 0.7255 Precision: 0.7619 Recall: 0.7065 \n",
            "\n",
            "Epoch 15/19\n",
            "----------\n",
            "train Loss: 0.3635 Acc: 0.8438 F1 score: 0.7704 Precision: 0.8112 Recall: 0.7474 \n",
            "val Loss: 0.3792 Acc: 0.8183 F1 score: 0.7278 Precision: 0.7760 Recall: 0.7054 \n",
            "\n",
            "Epoch 16/19\n",
            "----------\n",
            "train Loss: 0.3624 Acc: 0.8434 F1 score: 0.7707 Precision: 0.8098 Recall: 0.7483 \n",
            "val Loss: 0.3945 Acc: 0.8090 F1 score: 0.6833 Precision: 0.7920 Recall: 0.6584 \n",
            "\n",
            "Epoch 17/19\n",
            "----------\n",
            "train Loss: 0.3628 Acc: 0.8414 F1 score: 0.7668 Precision: 0.8075 Recall: 0.7441 \n",
            "val Loss: 0.3764 Acc: 0.8155 F1 score: 0.7316 Precision: 0.7652 Recall: 0.7132 \n",
            "\n",
            "Epoch 18/19\n",
            "----------\n",
            "train Loss: 0.3635 Acc: 0.8416 F1 score: 0.7686 Precision: 0.8060 Recall: 0.7469 \n",
            "val Loss: 0.3774 Acc: 0.8137 F1 score: 0.7337 Precision: 0.7595 Recall: 0.7179 \n",
            "\n",
            "Epoch 19/19\n",
            "----------\n",
            "train Loss: 0.3636 Acc: 0.8445 F1 score: 0.7723 Precision: 0.8113 Recall: 0.7499 \n",
            "val Loss: 0.3790 Acc: 0.8173 F1 score: 0.7311 Precision: 0.7705 Recall: 0.7108 \n",
            "\n",
            "Training complete in 2m 52s\n",
            "Best val F1: 0.734786\n",
            "fold 3\n",
            "Epoch 0/19\n",
            "----------\n",
            "train Loss: 0.5004 Acc: 0.7510 F1 score: 0.6714 Precision: 0.6719 Recall: 0.6710 \n",
            "val Loss: 0.3366 Acc: 0.8432 F1 score: 0.7517 Precision: 0.7817 Recall: 0.7323 \n",
            "\n",
            "Epoch 1/19\n",
            "----------\n",
            "train Loss: 0.4044 Acc: 0.8233 F1 score: 0.7416 Precision: 0.7810 Recall: 0.7208 \n",
            "val Loss: 0.3297 Acc: 0.8349 F1 score: 0.7510 Precision: 0.7622 Recall: 0.7419 \n",
            "\n",
            "Epoch 2/19\n",
            "----------\n",
            "train Loss: 0.3922 Acc: 0.8296 F1 score: 0.7547 Precision: 0.7879 Recall: 0.7354 \n",
            "val Loss: 0.3250 Acc: 0.8413 F1 score: 0.7531 Precision: 0.7759 Recall: 0.7371 \n",
            "\n",
            "Epoch 3/19\n",
            "----------\n",
            "train Loss: 0.3936 Acc: 0.8290 F1 score: 0.7550 Precision: 0.7859 Recall: 0.7365 \n",
            "val Loss: 0.3257 Acc: 0.8376 F1 score: 0.7587 Precision: 0.7656 Recall: 0.7526 \n",
            "\n",
            "Epoch 4/19\n",
            "----------\n",
            "train Loss: 0.3850 Acc: 0.8305 F1 score: 0.7556 Precision: 0.7898 Recall: 0.7359 \n",
            "val Loss: 0.3232 Acc: 0.8469 F1 score: 0.7584 Precision: 0.7876 Recall: 0.7391 \n",
            "\n",
            "Epoch 5/19\n",
            "----------\n",
            "train Loss: 0.3899 Acc: 0.8331 F1 score: 0.7576 Precision: 0.7957 Recall: 0.7364 \n",
            "val Loss: 0.3243 Acc: 0.8441 F1 score: 0.7611 Precision: 0.7786 Recall: 0.7478 \n",
            "\n",
            "Epoch 6/19\n",
            "----------\n",
            "train Loss: 0.3826 Acc: 0.8304 F1 score: 0.7537 Precision: 0.7913 Recall: 0.7329 \n",
            "val Loss: 0.3233 Acc: 0.8450 F1 score: 0.7613 Precision: 0.7807 Recall: 0.7469 \n",
            "\n",
            "Epoch 7/19\n",
            "----------\n",
            "train Loss: 0.3807 Acc: 0.8360 F1 score: 0.7621 Precision: 0.8001 Recall: 0.7407 \n",
            "val Loss: 0.3241 Acc: 0.8469 F1 score: 0.7522 Precision: 0.7926 Recall: 0.7287 \n",
            "\n",
            "Epoch 8/19\n",
            "----------\n",
            "train Loss: 0.3803 Acc: 0.8347 F1 score: 0.7604 Precision: 0.7979 Recall: 0.7393 \n",
            "val Loss: 0.3221 Acc: 0.8469 F1 score: 0.7633 Precision: 0.7842 Recall: 0.7481 \n",
            "\n",
            "Epoch 9/19\n",
            "----------\n",
            "train Loss: 0.3807 Acc: 0.8319 F1 score: 0.7572 Precision: 0.7923 Recall: 0.7370 \n",
            "val Loss: 0.3229 Acc: 0.8413 F1 score: 0.7588 Precision: 0.7732 Recall: 0.7475 \n",
            "\n",
            "Epoch 10/19\n",
            "----------\n",
            "train Loss: 0.3758 Acc: 0.8367 F1 score: 0.7641 Precision: 0.8002 Recall: 0.7433 \n",
            "val Loss: 0.3238 Acc: 0.8450 F1 score: 0.7588 Precision: 0.7822 Recall: 0.7424 \n",
            "\n",
            "Epoch 11/19\n",
            "----------\n",
            "train Loss: 0.3799 Acc: 0.8341 F1 score: 0.7601 Precision: 0.7963 Recall: 0.7395 \n",
            "val Loss: 0.3232 Acc: 0.8404 F1 score: 0.7570 Precision: 0.7719 Recall: 0.7454 \n",
            "\n",
            "Epoch 12/19\n",
            "----------\n",
            "train Loss: 0.3778 Acc: 0.8340 F1 score: 0.7587 Precision: 0.7974 Recall: 0.7373 \n",
            "val Loss: 0.3225 Acc: 0.8459 F1 score: 0.7547 Precision: 0.7876 Recall: 0.7341 \n",
            "\n",
            "Epoch 13/19\n",
            "----------\n",
            "train Loss: 0.3782 Acc: 0.8360 F1 score: 0.7632 Precision: 0.7989 Recall: 0.7425 \n",
            "val Loss: 0.3235 Acc: 0.8423 F1 score: 0.7574 Precision: 0.7760 Recall: 0.7436 \n",
            "\n",
            "Epoch 14/19\n",
            "----------\n",
            "train Loss: 0.3755 Acc: 0.8378 F1 score: 0.7660 Precision: 0.8017 Recall: 0.7452 \n",
            "val Loss: 0.3265 Acc: 0.8413 F1 score: 0.7564 Precision: 0.7742 Recall: 0.7430 \n",
            "\n",
            "Epoch 15/19\n",
            "----------\n",
            "train Loss: 0.3747 Acc: 0.8382 F1 score: 0.7661 Precision: 0.8029 Recall: 0.7450 \n",
            "val Loss: 0.3252 Acc: 0.8386 F1 score: 0.7534 Precision: 0.7692 Recall: 0.7413 \n",
            "\n",
            "Epoch 16/19\n",
            "----------\n",
            "train Loss: 0.3767 Acc: 0.8373 F1 score: 0.7645 Precision: 0.8017 Recall: 0.7433 \n",
            "val Loss: 0.3236 Acc: 0.8450 F1 score: 0.7621 Precision: 0.7803 Recall: 0.7484 \n",
            "\n",
            "Epoch 17/19\n",
            "----------\n",
            "train Loss: 0.3760 Acc: 0.8359 F1 score: 0.7622 Precision: 0.7996 Recall: 0.7410 \n",
            "val Loss: 0.3222 Acc: 0.8459 F1 score: 0.7556 Precision: 0.7869 Recall: 0.7356 \n",
            "\n",
            "Epoch 18/19\n",
            "----------\n",
            "train Loss: 0.3764 Acc: 0.8348 F1 score: 0.7614 Precision: 0.7972 Recall: 0.7409 \n",
            "val Loss: 0.3236 Acc: 0.8395 F1 score: 0.7560 Precision: 0.7702 Recall: 0.7448 \n",
            "\n",
            "Epoch 19/19\n",
            "----------\n",
            "train Loss: 0.3745 Acc: 0.8375 F1 score: 0.7643 Precision: 0.8026 Recall: 0.7427 \n",
            "val Loss: 0.3229 Acc: 0.8459 F1 score: 0.7573 Precision: 0.7857 Recall: 0.7386 \n",
            "\n",
            "Training complete in 2m 52s\n",
            "Best val F1: 0.763331\n",
            "fold 4\n",
            "Epoch 0/19\n",
            "----------\n",
            "train Loss: 0.4615 Acc: 0.7964 F1 score: 0.6795 Precision: 0.7418 Recall: 0.6591 \n",
            "val Loss: 0.3484 Acc: 0.8423 F1 score: 0.7674 Precision: 0.8147 Recall: 0.7427 \n",
            "\n",
            "Epoch 1/19\n",
            "----------\n",
            "train Loss: 0.4012 Acc: 0.8248 F1 score: 0.7380 Precision: 0.7834 Recall: 0.7154 \n",
            "val Loss: 0.3409 Acc: 0.8496 F1 score: 0.7890 Precision: 0.8126 Recall: 0.7727 \n",
            "\n",
            "Epoch 2/19\n",
            "----------\n",
            "train Loss: 0.3901 Acc: 0.8308 F1 score: 0.7489 Precision: 0.7920 Recall: 0.7264 \n",
            "val Loss: 0.3350 Acc: 0.8570 F1 score: 0.7971 Precision: 0.8269 Recall: 0.7776 \n",
            "\n",
            "Epoch 3/19\n",
            "----------\n",
            "train Loss: 0.3914 Acc: 0.8286 F1 score: 0.7470 Precision: 0.7868 Recall: 0.7256 \n",
            "val Loss: 0.3350 Acc: 0.8515 F1 score: 0.7874 Precision: 0.8207 Recall: 0.7668 \n",
            "\n",
            "Epoch 4/19\n",
            "----------\n",
            "train Loss: 0.3841 Acc: 0.8324 F1 score: 0.7506 Precision: 0.7952 Recall: 0.7275 \n",
            "val Loss: 0.3350 Acc: 0.8542 F1 score: 0.7941 Precision: 0.8214 Recall: 0.7758 \n",
            "\n",
            "Epoch 5/19\n",
            "----------\n",
            "train Loss: 0.3806 Acc: 0.8344 F1 score: 0.7564 Precision: 0.7958 Recall: 0.7346 \n",
            "val Loss: 0.3355 Acc: 0.8469 F1 score: 0.7883 Precision: 0.8053 Recall: 0.7756 \n",
            "\n",
            "Epoch 6/19\n",
            "----------\n",
            "train Loss: 0.3785 Acc: 0.8350 F1 score: 0.7596 Precision: 0.7945 Recall: 0.7392 \n",
            "val Loss: 0.3398 Acc: 0.8450 F1 score: 0.7629 Precision: 0.8339 Recall: 0.7326 \n",
            "\n",
            "Epoch 7/19\n",
            "----------\n",
            "train Loss: 0.3743 Acc: 0.8355 F1 score: 0.7567 Precision: 0.7988 Recall: 0.7341 \n",
            "val Loss: 0.3419 Acc: 0.8432 F1 score: 0.7551 Precision: 0.8400 Recall: 0.7230 \n",
            "\n",
            "Epoch 8/19\n",
            "----------\n",
            "train Loss: 0.3764 Acc: 0.8335 F1 score: 0.7535 Precision: 0.7959 Recall: 0.7309 \n",
            "val Loss: 0.3338 Acc: 0.8441 F1 score: 0.7794 Precision: 0.8062 Recall: 0.7618 \n",
            "\n",
            "Epoch 9/19\n",
            "----------\n",
            "train Loss: 0.3733 Acc: 0.8356 F1 score: 0.7567 Precision: 0.7992 Recall: 0.7339 \n",
            "val Loss: 0.3331 Acc: 0.8487 F1 score: 0.7874 Precision: 0.8115 Recall: 0.7709 \n",
            "\n",
            "Epoch 10/19\n",
            "----------\n",
            "train Loss: 0.3746 Acc: 0.8361 F1 score: 0.7569 Precision: 0.8007 Recall: 0.7337 \n",
            "val Loss: 0.3338 Acc: 0.8404 F1 score: 0.7716 Precision: 0.8032 Recall: 0.7522 \n",
            "\n",
            "Epoch 11/19\n",
            "----------\n",
            "train Loss: 0.3708 Acc: 0.8382 F1 score: 0.7608 Precision: 0.8034 Recall: 0.7378 \n",
            "val Loss: 0.3358 Acc: 0.8423 F1 score: 0.7702 Precision: 0.8109 Recall: 0.7475 \n",
            "\n",
            "Epoch 12/19\n",
            "----------\n",
            "train Loss: 0.3734 Acc: 0.8365 F1 score: 0.7602 Precision: 0.7984 Recall: 0.7387 \n",
            "val Loss: 0.3355 Acc: 0.8432 F1 score: 0.7784 Precision: 0.8044 Recall: 0.7612 \n",
            "\n",
            "Epoch 13/19\n",
            "----------\n",
            "train Loss: 0.3713 Acc: 0.8369 F1 score: 0.7597 Precision: 0.8002 Recall: 0.7375 \n",
            "val Loss: 0.3384 Acc: 0.8478 F1 score: 0.7698 Precision: 0.8340 Recall: 0.7404 \n",
            "\n",
            "Epoch 14/19\n",
            "----------\n",
            "train Loss: 0.3723 Acc: 0.8374 F1 score: 0.7611 Precision: 0.8004 Recall: 0.7392 \n",
            "val Loss: 0.3420 Acc: 0.8450 F1 score: 0.7613 Precision: 0.8369 Recall: 0.7302 \n",
            "\n",
            "Epoch 15/19\n",
            "----------\n",
            "train Loss: 0.3715 Acc: 0.8384 F1 score: 0.7626 Precision: 0.8021 Recall: 0.7405 \n",
            "val Loss: 0.3344 Acc: 0.8395 F1 score: 0.7699 Precision: 0.8020 Recall: 0.7504 \n",
            "\n",
            "Epoch 16/19\n",
            "----------\n",
            "train Loss: 0.3699 Acc: 0.8408 F1 score: 0.7663 Precision: 0.8058 Recall: 0.7440 \n",
            "val Loss: 0.3347 Acc: 0.8413 F1 score: 0.7813 Precision: 0.7967 Recall: 0.7695 \n",
            "\n",
            "Epoch 17/19\n",
            "----------\n",
            "train Loss: 0.3720 Acc: 0.8380 F1 score: 0.7623 Precision: 0.8010 Recall: 0.7405 \n",
            "val Loss: 0.3335 Acc: 0.8478 F1 score: 0.7888 Precision: 0.8074 Recall: 0.7750 \n",
            "\n",
            "Epoch 18/19\n",
            "----------\n",
            "train Loss: 0.3726 Acc: 0.8384 F1 score: 0.7627 Precision: 0.8020 Recall: 0.7407 \n",
            "val Loss: 0.3341 Acc: 0.8478 F1 score: 0.7876 Precision: 0.8086 Recall: 0.7727 \n",
            "\n",
            "Epoch 19/19\n",
            "----------\n",
            "train Loss: 0.3701 Acc: 0.8358 F1 score: 0.7574 Precision: 0.7991 Recall: 0.7348 \n",
            "val Loss: 0.3361 Acc: 0.8423 F1 score: 0.7716 Precision: 0.8092 Recall: 0.7499 \n",
            "\n",
            "Training complete in 2m 52s\n",
            "Best val F1: 0.797110\n",
            "fold 5\n",
            "Epoch 0/19\n",
            "----------\n",
            "train Loss: 0.4761 Acc: 0.7775 F1 score: 0.6745 Precision: 0.6983 Recall: 0.6618 \n",
            "val Loss: 0.3637 Acc: 0.8303 F1 score: 0.7679 Precision: 0.7999 Recall: 0.7493 \n",
            "\n",
            "Epoch 1/19\n",
            "----------\n",
            "train Loss: 0.3984 Acc: 0.8301 F1 score: 0.7404 Precision: 0.7955 Recall: 0.7151 \n",
            "val Loss: 0.3736 Acc: 0.8284 F1 score: 0.7489 Precision: 0.8206 Recall: 0.7217 \n",
            "\n",
            "Epoch 2/19\n",
            "----------\n",
            "train Loss: 0.3945 Acc: 0.8315 F1 score: 0.7452 Precision: 0.7948 Recall: 0.7209 \n",
            "val Loss: 0.3575 Acc: 0.8395 F1 score: 0.7757 Precision: 0.8209 Recall: 0.7525 \n",
            "\n",
            "Epoch 3/19\n",
            "----------\n",
            "train Loss: 0.3899 Acc: 0.8303 F1 score: 0.7483 Precision: 0.7879 Recall: 0.7267 \n",
            "val Loss: 0.3555 Acc: 0.8358 F1 score: 0.7760 Precision: 0.8075 Recall: 0.7573 \n",
            "\n",
            "Epoch 4/19\n",
            "----------\n",
            "train Loss: 0.3830 Acc: 0.8361 F1 score: 0.7573 Precision: 0.7971 Recall: 0.7352 \n",
            "val Loss: 0.3559 Acc: 0.8229 F1 score: 0.7705 Precision: 0.7793 Recall: 0.7632 \n",
            "\n",
            "Epoch 5/19\n",
            "----------\n",
            "train Loss: 0.3793 Acc: 0.8363 F1 score: 0.7567 Precision: 0.7984 Recall: 0.7340 \n",
            "val Loss: 0.3526 Acc: 0.8367 F1 score: 0.7703 Precision: 0.8189 Recall: 0.7464 \n",
            "\n",
            "Epoch 6/19\n",
            "----------\n",
            "train Loss: 0.3822 Acc: 0.8347 F1 score: 0.7526 Precision: 0.7977 Recall: 0.7291 \n",
            "val Loss: 0.3500 Acc: 0.8376 F1 score: 0.7797 Precision: 0.8089 Recall: 0.7618 \n",
            "\n",
            "Epoch 7/19\n",
            "----------\n",
            "train Loss: 0.3745 Acc: 0.8377 F1 score: 0.7613 Precision: 0.7982 Recall: 0.7400 \n",
            "val Loss: 0.3489 Acc: 0.8413 F1 score: 0.7807 Precision: 0.8200 Recall: 0.7590 \n",
            "\n",
            "Epoch 8/19\n",
            "----------\n",
            "train Loss: 0.3758 Acc: 0.8368 F1 score: 0.7613 Precision: 0.7953 Recall: 0.7411 \n",
            "val Loss: 0.3520 Acc: 0.8413 F1 score: 0.7764 Precision: 0.8270 Recall: 0.7516 \n",
            "\n",
            "Epoch 9/19\n",
            "----------\n",
            "train Loss: 0.3745 Acc: 0.8372 F1 score: 0.7627 Precision: 0.7951 Recall: 0.7431 \n",
            "val Loss: 0.3491 Acc: 0.8358 F1 score: 0.7800 Precision: 0.8030 Recall: 0.7647 \n",
            "\n",
            "Epoch 10/19\n",
            "----------\n",
            "train Loss: 0.3736 Acc: 0.8386 F1 score: 0.7619 Precision: 0.8004 Recall: 0.7401 \n",
            "val Loss: 0.3514 Acc: 0.8349 F1 score: 0.7657 Precision: 0.8190 Recall: 0.7409 \n",
            "\n",
            "Epoch 11/19\n",
            "----------\n",
            "train Loss: 0.3717 Acc: 0.8396 F1 score: 0.7624 Precision: 0.8031 Recall: 0.7398 \n",
            "val Loss: 0.3486 Acc: 0.8358 F1 score: 0.7730 Precision: 0.8114 Recall: 0.7521 \n",
            "\n",
            "Epoch 12/19\n",
            "----------\n",
            "train Loss: 0.3711 Acc: 0.8381 F1 score: 0.7620 Precision: 0.7987 Recall: 0.7409 \n",
            "val Loss: 0.3536 Acc: 0.8367 F1 score: 0.7663 Precision: 0.8256 Recall: 0.7400 \n",
            "\n",
            "Epoch 13/19\n",
            "----------\n",
            "train Loss: 0.3717 Acc: 0.8378 F1 score: 0.7616 Precision: 0.7982 Recall: 0.7404 \n",
            "val Loss: 0.3506 Acc: 0.8404 F1 score: 0.7748 Precision: 0.8260 Recall: 0.7500 \n",
            "\n",
            "Epoch 14/19\n",
            "----------\n",
            "train Loss: 0.3739 Acc: 0.8386 F1 score: 0.7623 Precision: 0.8001 Recall: 0.7407 \n",
            "val Loss: 0.3486 Acc: 0.8376 F1 score: 0.7738 Precision: 0.8170 Recall: 0.7512 \n",
            "\n",
            "Epoch 15/19\n",
            "----------\n",
            "train Loss: 0.3720 Acc: 0.8381 F1 score: 0.7624 Precision: 0.7983 Recall: 0.7414 \n",
            "val Loss: 0.3492 Acc: 0.8376 F1 score: 0.7762 Precision: 0.8134 Recall: 0.7554 \n",
            "\n",
            "Epoch 16/19\n",
            "----------\n",
            "train Loss: 0.3738 Acc: 0.8355 F1 score: 0.7585 Precision: 0.7939 Recall: 0.7380 \n",
            "val Loss: 0.3484 Acc: 0.8376 F1 score: 0.7797 Precision: 0.8089 Recall: 0.7618 \n",
            "\n",
            "Epoch 17/19\n",
            "----------\n",
            "train Loss: 0.3732 Acc: 0.8383 F1 score: 0.7636 Precision: 0.7977 Recall: 0.7433 \n",
            "val Loss: 0.3477 Acc: 0.8349 F1 score: 0.7745 Precision: 0.8065 Recall: 0.7556 \n",
            "\n",
            "Epoch 18/19\n",
            "----------\n",
            "train Loss: 0.3711 Acc: 0.8391 F1 score: 0.7640 Precision: 0.7999 Recall: 0.7431 \n",
            "val Loss: 0.3486 Acc: 0.8423 F1 score: 0.7799 Precision: 0.8248 Recall: 0.7565 \n",
            "\n",
            "Epoch 19/19\n",
            "----------\n",
            "train Loss: 0.3714 Acc: 0.8371 F1 score: 0.7605 Precision: 0.7971 Recall: 0.7394 \n",
            "val Loss: 0.3492 Acc: 0.8367 F1 score: 0.7752 Precision: 0.8116 Recall: 0.7548 \n",
            "\n",
            "Training complete in 2m 53s\n",
            "Best val F1: 0.780690\n",
            "fold 6\n",
            "Epoch 0/19\n",
            "----------\n",
            "train Loss: 0.4853 Acc: 0.7593 F1 score: 0.6733 Precision: 0.6782 Recall: 0.6692 \n",
            "val Loss: 0.3391 Acc: 0.8303 F1 score: 0.7574 Precision: 0.7719 Recall: 0.7464 \n",
            "\n",
            "Epoch 1/19\n",
            "----------\n",
            "train Loss: 0.4029 Acc: 0.8265 F1 score: 0.7417 Precision: 0.7876 Recall: 0.7189 \n",
            "val Loss: 0.3283 Acc: 0.8303 F1 score: 0.7445 Precision: 0.7797 Recall: 0.7243 \n",
            "\n",
            "Epoch 2/19\n",
            "----------\n",
            "train Loss: 0.3949 Acc: 0.8321 F1 score: 0.7582 Precision: 0.7889 Recall: 0.7397 \n",
            "val Loss: 0.3254 Acc: 0.8284 F1 score: 0.7434 Precision: 0.7754 Recall: 0.7243 \n",
            "\n",
            "Epoch 3/19\n",
            "----------\n",
            "train Loss: 0.3900 Acc: 0.8336 F1 score: 0.7545 Precision: 0.7973 Recall: 0.7318 \n",
            "val Loss: 0.3339 Acc: 0.8376 F1 score: 0.7465 Precision: 0.8021 Recall: 0.7200 \n",
            "\n",
            "Epoch 4/19\n",
            "----------\n",
            "train Loss: 0.3857 Acc: 0.8315 F1 score: 0.7556 Precision: 0.7894 Recall: 0.7359 \n",
            "val Loss: 0.3252 Acc: 0.8321 F1 score: 0.7535 Precision: 0.7783 Recall: 0.7372 \n",
            "\n",
            "Epoch 5/19\n",
            "----------\n",
            "train Loss: 0.3826 Acc: 0.8350 F1 score: 0.7592 Precision: 0.7969 Recall: 0.7380 \n",
            "val Loss: 0.3186 Acc: 0.8395 F1 score: 0.7651 Precision: 0.7896 Recall: 0.7485 \n",
            "\n",
            "Epoch 6/19\n",
            "----------\n",
            "train Loss: 0.3908 Acc: 0.8331 F1 score: 0.7581 Precision: 0.7920 Recall: 0.7383 \n",
            "val Loss: 0.3340 Acc: 0.8386 F1 score: 0.7411 Precision: 0.8130 Recall: 0.7115 \n",
            "\n",
            "Epoch 7/19\n",
            "----------\n",
            "train Loss: 0.3819 Acc: 0.8343 F1 score: 0.7641 Precision: 0.7902 Recall: 0.7472 \n",
            "val Loss: 0.3242 Acc: 0.8312 F1 score: 0.7555 Precision: 0.7749 Recall: 0.7418 \n",
            "\n",
            "Epoch 8/19\n",
            "----------\n",
            "train Loss: 0.3831 Acc: 0.8347 F1 score: 0.7622 Precision: 0.7930 Recall: 0.7435 \n",
            "val Loss: 0.3223 Acc: 0.8266 F1 score: 0.7514 Precision: 0.7666 Recall: 0.7400 \n",
            "\n",
            "Epoch 9/19\n",
            "----------\n",
            "train Loss: 0.3788 Acc: 0.8353 F1 score: 0.7616 Precision: 0.7954 Recall: 0.7417 \n",
            "val Loss: 0.3231 Acc: 0.8358 F1 score: 0.7560 Precision: 0.7865 Recall: 0.7370 \n",
            "\n",
            "Epoch 10/19\n",
            "----------\n",
            "train Loss: 0.3781 Acc: 0.8370 F1 score: 0.7639 Precision: 0.7981 Recall: 0.7438 \n",
            "val Loss: 0.3232 Acc: 0.8386 F1 score: 0.7604 Precision: 0.7907 Recall: 0.7414 \n",
            "\n",
            "Epoch 11/19\n",
            "----------\n",
            "train Loss: 0.3773 Acc: 0.8351 F1 score: 0.7606 Precision: 0.7958 Recall: 0.7402 \n",
            "val Loss: 0.3216 Acc: 0.8339 F1 score: 0.7577 Precision: 0.7803 Recall: 0.7423 \n",
            "\n",
            "Epoch 12/19\n",
            "----------\n",
            "train Loss: 0.3763 Acc: 0.8376 F1 score: 0.7649 Precision: 0.7990 Recall: 0.7447 \n",
            "val Loss: 0.3204 Acc: 0.8349 F1 score: 0.7565 Precision: 0.7835 Recall: 0.7390 \n",
            "\n",
            "Epoch 13/19\n",
            "----------\n",
            "train Loss: 0.3762 Acc: 0.8380 F1 score: 0.7657 Precision: 0.7994 Recall: 0.7456 \n",
            "val Loss: 0.3224 Acc: 0.8386 F1 score: 0.7558 Precision: 0.7950 Recall: 0.7336 \n",
            "\n",
            "Epoch 14/19\n",
            "----------\n",
            "train Loss: 0.3778 Acc: 0.8364 F1 score: 0.7638 Precision: 0.7964 Recall: 0.7441 \n",
            "val Loss: 0.3200 Acc: 0.8358 F1 score: 0.7597 Precision: 0.7837 Recall: 0.7435 \n",
            "\n",
            "Epoch 15/19\n",
            "----------\n",
            "train Loss: 0.3765 Acc: 0.8371 F1 score: 0.7649 Precision: 0.7974 Recall: 0.7453 \n",
            "val Loss: 0.3204 Acc: 0.8312 F1 score: 0.7570 Precision: 0.7741 Recall: 0.7444 \n",
            "\n",
            "Epoch 16/19\n",
            "----------\n",
            "train Loss: 0.3753 Acc: 0.8375 F1 score: 0.7650 Precision: 0.7986 Recall: 0.7450 \n",
            "val Loss: 0.3323 Acc: 0.8450 F1 score: 0.7435 Precision: 0.8411 Recall: 0.7093 \n",
            "\n",
            "Epoch 17/19\n",
            "----------\n",
            "train Loss: 0.3743 Acc: 0.8395 F1 score: 0.7684 Precision: 0.8011 Recall: 0.7486 \n",
            "val Loss: 0.3211 Acc: 0.8358 F1 score: 0.7582 Precision: 0.7848 Recall: 0.7409 \n",
            "\n",
            "Epoch 18/19\n",
            "----------\n",
            "train Loss: 0.3758 Acc: 0.8367 F1 score: 0.7645 Precision: 0.7966 Recall: 0.7450 \n",
            "val Loss: 0.3220 Acc: 0.8358 F1 score: 0.7544 Precision: 0.7878 Recall: 0.7344 \n",
            "\n",
            "Epoch 19/19\n",
            "----------\n",
            "train Loss: 0.3769 Acc: 0.8346 F1 score: 0.7611 Precision: 0.7937 Recall: 0.7416 \n",
            "val Loss: 0.3208 Acc: 0.8367 F1 score: 0.7562 Precision: 0.7890 Recall: 0.7363 \n",
            "\n",
            "Training complete in 2m 52s\n",
            "Best val F1: 0.765098\n",
            "fold 7\n",
            "Epoch 0/19\n",
            "----------\n",
            "train Loss: 0.4469 Acc: 0.8059 F1 score: 0.6915 Precision: 0.7653 Recall: 0.6682 \n",
            "val Loss: 0.3714 Acc: 0.8441 F1 score: 0.7611 Precision: 0.8199 Recall: 0.7332 \n",
            "\n",
            "Epoch 1/19\n",
            "----------\n",
            "train Loss: 0.3976 Acc: 0.8295 F1 score: 0.7440 Precision: 0.7939 Recall: 0.7200 \n",
            "val Loss: 0.3579 Acc: 0.8339 F1 score: 0.7407 Precision: 0.8076 Recall: 0.7127 \n",
            "\n",
            "Epoch 2/19\n",
            "----------\n",
            "train Loss: 0.3877 Acc: 0.8324 F1 score: 0.7568 Precision: 0.7901 Recall: 0.7372 \n",
            "val Loss: 0.3533 Acc: 0.8339 F1 score: 0.7577 Precision: 0.7885 Recall: 0.7389 \n",
            "\n",
            "Epoch 3/19\n",
            "----------\n",
            "train Loss: 0.3874 Acc: 0.8327 F1 score: 0.7546 Precision: 0.7931 Recall: 0.7333 \n",
            "val Loss: 0.3535 Acc: 0.8376 F1 score: 0.7564 Precision: 0.8015 Recall: 0.7326 \n",
            "\n",
            "Epoch 4/19\n",
            "----------\n",
            "train Loss: 0.3845 Acc: 0.8323 F1 score: 0.7563 Precision: 0.7902 Recall: 0.7365 \n",
            "val Loss: 0.3514 Acc: 0.8367 F1 score: 0.7569 Precision: 0.7978 Recall: 0.7345 \n",
            "\n",
            "Epoch 5/19\n",
            "----------\n",
            "train Loss: 0.3810 Acc: 0.8350 F1 score: 0.7563 Precision: 0.7990 Recall: 0.7335 \n",
            "val Loss: 0.3515 Acc: 0.8432 F1 score: 0.7705 Precision: 0.8042 Recall: 0.7500 \n",
            "\n",
            "Epoch 6/19\n",
            "----------\n",
            "train Loss: 0.3772 Acc: 0.8376 F1 score: 0.7634 Precision: 0.7996 Recall: 0.7425 \n",
            "val Loss: 0.3546 Acc: 0.8459 F1 score: 0.7749 Precision: 0.8083 Recall: 0.7543 \n",
            "\n",
            "Epoch 7/19\n",
            "----------\n",
            "train Loss: 0.3750 Acc: 0.8382 F1 score: 0.7663 Precision: 0.7986 Recall: 0.7467 \n",
            "val Loss: 0.3525 Acc: 0.8423 F1 score: 0.7644 Precision: 0.8081 Recall: 0.7407 \n",
            "\n",
            "Epoch 8/19\n",
            "----------\n",
            "train Loss: 0.3717 Acc: 0.8396 F1 score: 0.7674 Precision: 0.8015 Recall: 0.7470 \n",
            "val Loss: 0.3515 Acc: 0.8404 F1 score: 0.7675 Precision: 0.7986 Recall: 0.7482 \n",
            "\n",
            "Epoch 9/19\n",
            "----------\n",
            "train Loss: 0.3735 Acc: 0.8368 F1 score: 0.7650 Precision: 0.7955 Recall: 0.7461 \n",
            "val Loss: 0.3523 Acc: 0.8404 F1 score: 0.7689 Precision: 0.7973 Recall: 0.7507 \n",
            "\n",
            "Epoch 10/19\n",
            "----------\n",
            "train Loss: 0.3745 Acc: 0.8371 F1 score: 0.7641 Precision: 0.7973 Recall: 0.7442 \n",
            "val Loss: 0.3512 Acc: 0.8413 F1 score: 0.7685 Precision: 0.8004 Recall: 0.7488 \n",
            "\n",
            "Epoch 11/19\n",
            "----------\n",
            "train Loss: 0.3715 Acc: 0.8399 F1 score: 0.7679 Precision: 0.8019 Recall: 0.7476 \n",
            "val Loss: 0.3513 Acc: 0.8413 F1 score: 0.7678 Precision: 0.8012 Recall: 0.7475 \n",
            "\n",
            "Epoch 12/19\n",
            "----------\n",
            "train Loss: 0.3715 Acc: 0.8397 F1 score: 0.7671 Precision: 0.8022 Recall: 0.7464 \n",
            "val Loss: 0.3504 Acc: 0.8413 F1 score: 0.7692 Precision: 0.7997 Recall: 0.7500 \n",
            "\n",
            "Epoch 13/19\n",
            "----------\n",
            "train Loss: 0.3695 Acc: 0.8381 F1 score: 0.7655 Precision: 0.7991 Recall: 0.7454 \n",
            "val Loss: 0.3511 Acc: 0.8432 F1 score: 0.7732 Precision: 0.8013 Recall: 0.7550 \n",
            "\n",
            "Epoch 14/19\n",
            "----------\n",
            "train Loss: 0.3701 Acc: 0.8405 F1 score: 0.7691 Precision: 0.8027 Recall: 0.7489 \n",
            "val Loss: 0.3509 Acc: 0.8404 F1 score: 0.7668 Precision: 0.7993 Recall: 0.7469 \n",
            "\n",
            "Epoch 15/19\n",
            "----------\n",
            "train Loss: 0.3702 Acc: 0.8406 F1 score: 0.7690 Precision: 0.8030 Recall: 0.7487 \n",
            "val Loss: 0.3508 Acc: 0.8404 F1 score: 0.7647 Precision: 0.8016 Recall: 0.7432 \n",
            "\n",
            "Epoch 16/19\n",
            "----------\n",
            "train Loss: 0.3697 Acc: 0.8400 F1 score: 0.7679 Precision: 0.8023 Recall: 0.7474 \n",
            "val Loss: 0.3515 Acc: 0.8441 F1 score: 0.7626 Precision: 0.8175 Recall: 0.7357 \n",
            "\n",
            "Epoch 17/19\n",
            "----------\n",
            "train Loss: 0.3693 Acc: 0.8381 F1 score: 0.7651 Precision: 0.7995 Recall: 0.7447 \n",
            "val Loss: 0.3501 Acc: 0.8432 F1 score: 0.7698 Precision: 0.8050 Recall: 0.7488 \n",
            "\n",
            "Epoch 18/19\n",
            "----------\n",
            "train Loss: 0.3691 Acc: 0.8378 F1 score: 0.7661 Precision: 0.7975 Recall: 0.7468 \n",
            "val Loss: 0.3503 Acc: 0.8413 F1 score: 0.7671 Precision: 0.8019 Recall: 0.7463 \n",
            "\n",
            "Epoch 19/19\n",
            "----------\n",
            "train Loss: 0.3677 Acc: 0.8400 F1 score: 0.7686 Precision: 0.8016 Recall: 0.7486 \n",
            "val Loss: 0.3513 Acc: 0.8386 F1 score: 0.7669 Precision: 0.7937 Recall: 0.7494 \n",
            "\n",
            "Training complete in 2m 53s\n",
            "Best val F1: 0.774890\n",
            "fold 8\n",
            "Epoch 0/19\n",
            "----------\n",
            "train Loss: 0.4612 Acc: 0.7935 F1 score: 0.6837 Precision: 0.7305 Recall: 0.6651 \n",
            "val Loss: 0.3637 Acc: 0.8144 F1 score: 0.7433 Precision: 0.7657 Recall: 0.7290 \n",
            "\n",
            "Epoch 1/19\n",
            "----------\n",
            "train Loss: 0.3955 Acc: 0.8273 F1 score: 0.7409 Precision: 0.7872 Recall: 0.7179 \n",
            "val Loss: 0.3731 Acc: 0.8163 F1 score: 0.7309 Precision: 0.7802 Recall: 0.7087 \n",
            "\n",
            "Epoch 2/19\n",
            "----------\n",
            "train Loss: 0.3891 Acc: 0.8331 F1 score: 0.7548 Precision: 0.7920 Recall: 0.7338 \n",
            "val Loss: 0.3629 Acc: 0.8292 F1 score: 0.7557 Precision: 0.7956 Recall: 0.7344 \n",
            "\n",
            "Epoch 3/19\n",
            "----------\n",
            "train Loss: 0.3844 Acc: 0.8349 F1 score: 0.7562 Precision: 0.7961 Recall: 0.7343 \n",
            "val Loss: 0.3627 Acc: 0.8283 F1 score: 0.7481 Precision: 0.8015 Recall: 0.7236 \n",
            "\n",
            "Epoch 4/19\n",
            "----------\n",
            "train Loss: 0.3801 Acc: 0.8346 F1 score: 0.7581 Precision: 0.7935 Recall: 0.7376 \n",
            "val Loss: 0.3682 Acc: 0.8246 F1 score: 0.7361 Precision: 0.8038 Recall: 0.7097 \n",
            "\n",
            "Epoch 5/19\n",
            "----------\n",
            "train Loss: 0.3792 Acc: 0.8361 F1 score: 0.7603 Precision: 0.7957 Recall: 0.7397 \n",
            "val Loss: 0.3557 Acc: 0.8366 F1 score: 0.7649 Precision: 0.8094 Recall: 0.7417 \n",
            "\n",
            "Epoch 6/19\n",
            "----------\n",
            "train Loss: 0.3785 Acc: 0.8387 F1 score: 0.7612 Precision: 0.8036 Recall: 0.7381 \n",
            "val Loss: 0.3591 Acc: 0.8283 F1 score: 0.7433 Precision: 0.8082 Recall: 0.7168 \n",
            "\n",
            "Epoch 7/19\n",
            "----------\n",
            "train Loss: 0.3732 Acc: 0.8393 F1 score: 0.7612 Precision: 0.8053 Recall: 0.7376 \n",
            "val Loss: 0.3531 Acc: 0.8375 F1 score: 0.7692 Precision: 0.8070 Recall: 0.7480 \n",
            "\n",
            "Epoch 8/19\n",
            "----------\n",
            "train Loss: 0.3711 Acc: 0.8415 F1 score: 0.7661 Precision: 0.8072 Recall: 0.7432 \n",
            "val Loss: 0.3546 Acc: 0.8356 F1 score: 0.7632 Precision: 0.8083 Recall: 0.7400 \n",
            "\n",
            "Epoch 9/19\n",
            "----------\n",
            "train Loss: 0.3736 Acc: 0.8395 F1 score: 0.7635 Precision: 0.8033 Recall: 0.7412 \n",
            "val Loss: 0.3569 Acc: 0.8319 F1 score: 0.7527 Precision: 0.8091 Recall: 0.7272 \n",
            "\n",
            "Epoch 10/19\n",
            "----------\n",
            "train Loss: 0.3687 Acc: 0.8418 F1 score: 0.7674 Precision: 0.8067 Recall: 0.7451 \n",
            "val Loss: 0.3569 Acc: 0.8356 F1 score: 0.7596 Precision: 0.8133 Recall: 0.7343 \n",
            "\n",
            "Epoch 11/19\n",
            "----------\n",
            "train Loss: 0.3680 Acc: 0.8397 F1 score: 0.7663 Precision: 0.8009 Recall: 0.7457 \n",
            "val Loss: 0.3544 Acc: 0.8338 F1 score: 0.7633 Precision: 0.8019 Recall: 0.7421 \n",
            "\n",
            "Epoch 12/19\n",
            "----------\n",
            "train Loss: 0.3660 Acc: 0.8428 F1 score: 0.7690 Precision: 0.8084 Recall: 0.7466 \n",
            "val Loss: 0.3536 Acc: 0.8356 F1 score: 0.7679 Precision: 0.8025 Recall: 0.7479 \n",
            "\n",
            "Epoch 13/19\n",
            "----------\n",
            "train Loss: 0.3680 Acc: 0.8383 F1 score: 0.7638 Precision: 0.7993 Recall: 0.7430 \n",
            "val Loss: 0.3554 Acc: 0.8356 F1 score: 0.7632 Precision: 0.8083 Recall: 0.7400 \n",
            "\n",
            "Epoch 14/19\n",
            "----------\n",
            "train Loss: 0.3679 Acc: 0.8424 F1 score: 0.7691 Precision: 0.8068 Recall: 0.7473 \n",
            "val Loss: 0.3566 Acc: 0.8384 F1 score: 0.7669 Precision: 0.8134 Recall: 0.7430 \n",
            "\n",
            "Epoch 15/19\n",
            "----------\n",
            "train Loss: 0.3658 Acc: 0.8423 F1 score: 0.7689 Precision: 0.8067 Recall: 0.7470 \n",
            "val Loss: 0.3553 Acc: 0.8375 F1 score: 0.7672 Precision: 0.8095 Recall: 0.7446 \n",
            "\n",
            "Epoch 16/19\n",
            "----------\n",
            "train Loss: 0.3679 Acc: 0.8412 F1 score: 0.7674 Precision: 0.8047 Recall: 0.7458 \n",
            "val Loss: 0.3733 Acc: 0.8209 F1 score: 0.7166 Precision: 0.8192 Recall: 0.6880 \n",
            "\n",
            "Epoch 17/19\n",
            "----------\n",
            "train Loss: 0.3685 Acc: 0.8392 F1 score: 0.7639 Precision: 0.8018 Recall: 0.7422 \n",
            "val Loss: 0.3562 Acc: 0.8366 F1 score: 0.7628 Precision: 0.8123 Recall: 0.7383 \n",
            "\n",
            "Epoch 18/19\n",
            "----------\n",
            "train Loss: 0.3648 Acc: 0.8414 F1 score: 0.7674 Precision: 0.8053 Recall: 0.7456 \n",
            "val Loss: 0.3548 Acc: 0.8375 F1 score: 0.7659 Precision: 0.8114 Recall: 0.7423 \n",
            "\n",
            "Epoch 19/19\n",
            "----------\n",
            "train Loss: 0.3687 Acc: 0.8411 F1 score: 0.7682 Precision: 0.8034 Recall: 0.7473 \n",
            "val Loss: 0.3589 Acc: 0.8310 F1 score: 0.7471 Precision: 0.8139 Recall: 0.7198 \n",
            "\n",
            "Training complete in 2m 53s\n",
            "Best val F1: 0.769231\n",
            "fold 9\n",
            "Epoch 0/19\n",
            "----------\n",
            "train Loss: 0.4573 Acc: 0.7986 F1 score: 0.6810 Precision: 0.7469 Recall: 0.6599 \n",
            "val Loss: 0.3683 Acc: 0.8218 F1 score: 0.7592 Precision: 0.7691 Recall: 0.7513 \n",
            "\n",
            "Epoch 1/19\n",
            "----------\n",
            "train Loss: 0.4008 Acc: 0.8241 F1 score: 0.7422 Precision: 0.7772 Recall: 0.7227 \n",
            "val Loss: 0.3538 Acc: 0.8329 F1 score: 0.7643 Precision: 0.7918 Recall: 0.7470 \n",
            "\n",
            "Epoch 2/19\n",
            "----------\n",
            "train Loss: 0.3907 Acc: 0.8325 F1 score: 0.7553 Precision: 0.7904 Recall: 0.7351 \n",
            "val Loss: 0.3565 Acc: 0.8292 F1 score: 0.7656 Precision: 0.7815 Recall: 0.7539 \n",
            "\n",
            "Epoch 3/19\n",
            "----------\n",
            "train Loss: 0.3886 Acc: 0.8325 F1 score: 0.7523 Precision: 0.7933 Recall: 0.7302 \n",
            "val Loss: 0.3527 Acc: 0.8273 F1 score: 0.7631 Precision: 0.7788 Recall: 0.7515 \n",
            "\n",
            "Epoch 4/19\n",
            "----------\n",
            "train Loss: 0.3841 Acc: 0.8330 F1 score: 0.7594 Precision: 0.7882 Recall: 0.7414 \n",
            "val Loss: 0.3514 Acc: 0.8384 F1 score: 0.7759 Precision: 0.7969 Recall: 0.7613 \n",
            "\n",
            "Epoch 5/19\n",
            "----------\n",
            "train Loss: 0.3796 Acc: 0.8348 F1 score: 0.7554 Precision: 0.7974 Recall: 0.7328 \n",
            "val Loss: 0.3577 Acc: 0.8356 F1 score: 0.7748 Precision: 0.7906 Recall: 0.7629 \n",
            "\n",
            "Epoch 6/19\n",
            "----------\n",
            "train Loss: 0.3815 Acc: 0.8341 F1 score: 0.7582 Precision: 0.7926 Recall: 0.7381 \n",
            "val Loss: 0.3525 Acc: 0.8347 F1 score: 0.7615 Precision: 0.8003 Recall: 0.7401 \n",
            "\n",
            "Epoch 7/19\n",
            "----------\n",
            "train Loss: 0.3726 Acc: 0.8371 F1 score: 0.7587 Precision: 0.8016 Recall: 0.7357 \n",
            "val Loss: 0.3510 Acc: 0.8375 F1 score: 0.7672 Precision: 0.8028 Recall: 0.7466 \n",
            "\n",
            "Epoch 8/19\n",
            "----------\n",
            "train Loss: 0.3718 Acc: 0.8381 F1 score: 0.7629 Precision: 0.8004 Recall: 0.7414 \n",
            "val Loss: 0.3546 Acc: 0.8356 F1 score: 0.7551 Precision: 0.8119 Recall: 0.7290 \n",
            "\n",
            "Epoch 9/19\n",
            "----------\n",
            "train Loss: 0.3687 Acc: 0.8393 F1 score: 0.7662 Precision: 0.8004 Recall: 0.7458 \n",
            "val Loss: 0.3516 Acc: 0.8329 F1 score: 0.7567 Precision: 0.7997 Recall: 0.7341 \n",
            "\n",
            "Epoch 10/19\n",
            "----------\n",
            "train Loss: 0.3705 Acc: 0.8383 F1 score: 0.7640 Precision: 0.7999 Recall: 0.7430 \n",
            "val Loss: 0.3514 Acc: 0.8393 F1 score: 0.7712 Precision: 0.8043 Recall: 0.7514 \n",
            "\n",
            "Epoch 11/19\n",
            "----------\n",
            "train Loss: 0.3715 Acc: 0.8367 F1 score: 0.7619 Precision: 0.7968 Recall: 0.7414 \n",
            "val Loss: 0.3540 Acc: 0.8310 F1 score: 0.7502 Precision: 0.8011 Recall: 0.7259 \n",
            "\n",
            "Epoch 12/19\n",
            "----------\n",
            "train Loss: 0.3706 Acc: 0.8396 F1 score: 0.7652 Precision: 0.8025 Recall: 0.7437 \n",
            "val Loss: 0.3529 Acc: 0.8384 F1 score: 0.7741 Precision: 0.7985 Recall: 0.7578 \n",
            "\n",
            "Epoch 13/19\n",
            "----------\n",
            "train Loss: 0.3670 Acc: 0.8422 F1 score: 0.7709 Precision: 0.8048 Recall: 0.7504 \n",
            "val Loss: 0.3511 Acc: 0.8384 F1 score: 0.7722 Precision: 0.8004 Recall: 0.7543 \n",
            "\n",
            "Epoch 14/19\n",
            "----------\n",
            "train Loss: 0.3667 Acc: 0.8408 F1 score: 0.7661 Precision: 0.8055 Recall: 0.7439 \n",
            "val Loss: 0.3502 Acc: 0.8366 F1 score: 0.7662 Precision: 0.8010 Recall: 0.7460 \n",
            "\n",
            "Epoch 15/19\n",
            "----------\n",
            "train Loss: 0.3676 Acc: 0.8411 F1 score: 0.7681 Precision: 0.8043 Recall: 0.7469 \n",
            "val Loss: 0.3496 Acc: 0.8347 F1 score: 0.7629 Precision: 0.7988 Recall: 0.7424 \n",
            "\n",
            "Epoch 16/19\n",
            "----------\n",
            "train Loss: 0.3685 Acc: 0.8409 F1 score: 0.7681 Precision: 0.8036 Recall: 0.7472 \n",
            "val Loss: 0.3521 Acc: 0.8356 F1 score: 0.7692 Precision: 0.7952 Recall: 0.7524 \n",
            "\n",
            "Epoch 17/19\n",
            "----------\n",
            "train Loss: 0.3667 Acc: 0.8392 F1 score: 0.7645 Precision: 0.8019 Recall: 0.7431 \n",
            "val Loss: 0.3502 Acc: 0.8366 F1 score: 0.7649 Precision: 0.8025 Recall: 0.7436 \n",
            "\n",
            "Epoch 18/19\n",
            "----------\n",
            "train Loss: 0.3656 Acc: 0.8410 F1 score: 0.7682 Precision: 0.8038 Recall: 0.7473 \n",
            "val Loss: 0.3535 Acc: 0.8356 F1 score: 0.7754 Precision: 0.7902 Recall: 0.7641 \n",
            "\n",
            "Epoch 19/19\n",
            "----------\n",
            "train Loss: 0.3687 Acc: 0.8385 F1 score: 0.7632 Precision: 0.8013 Recall: 0.7416 \n",
            "val Loss: 0.3519 Acc: 0.8384 F1 score: 0.7747 Precision: 0.7980 Recall: 0.7589 \n",
            "\n",
            "Training complete in 2m 53s\n",
            "Best val F1: 0.775897\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9THD5gkQpmZE"
      },
      "source": [
        "Across all folds we get around 0.7689 F1-score for 5 years prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x40oFCBvc0m1"
      },
      "source": [
        "#2 years"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZfYXJj0jAQ7V",
        "outputId": "a58bb761-efeb-44c4-89a1-c8171a80a68c"
      },
      "source": [
        "kfold = KFold(n_splits=10, shuffle=True)\n",
        "grdf2 = grdf2.drop(['IDS'],axis=1) #ID are not relevant\n",
        "# K-fold Cross Validation model evaluation\n",
        "for fold, (train_ids, test_ids) in enumerate(kfold.split(grdf2)):\n",
        "  print(f\"fold {fold}\")\n",
        "  model = Model()\n",
        "  model = model.to(device)\n",
        "  lr=0.005\n",
        "  optimizer = optim.Adam(model.parameters(),lr=lr)\n",
        "  criterion = nn.BCELoss()\n",
        "  scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "  train_subsampler = SubsetRandomSampler(train_ids)\n",
        "  test_subsampler = SubsetRandomSampler(test_ids)\n",
        "\n",
        "\n",
        "  dataf2 = DataforSet(grdf2, '2_years')\n",
        "\n",
        "  dataloaders =  {'train': DataLoader(dataf2, batch_size=150, sampler=train_subsampler),\n",
        "                  'val': DataLoader(dataf2, batch_size=150, sampler=test_subsampler)}\n",
        "\n",
        "  model = train_model(model, dataloaders, criterion, optimizer, scheduler, num_epochs=20)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fold 0\n",
            "Epoch 0/19\n",
            "----------\n",
            "train Loss: 0.5631 Acc: 0.7004 F1 score: 0.7000 Precision: 0.7015 Recall: 0.7004 \n",
            "val Loss: 0.4147 Acc: 0.8059 F1 score: 0.8058 Precision: 0.8064 Recall: 0.8061 \n",
            "\n",
            "Epoch 1/19\n",
            "----------\n",
            "train Loss: 0.4475 Acc: 0.7841 F1 score: 0.7830 Precision: 0.7896 Recall: 0.7840 \n",
            "val Loss: 0.3718 Acc: 0.8223 F1 score: 0.8214 Precision: 0.8310 Recall: 0.8232 \n",
            "\n",
            "Epoch 2/19\n",
            "----------\n",
            "train Loss: 0.4093 Acc: 0.8120 F1 score: 0.8109 Precision: 0.8195 Recall: 0.8119 \n",
            "val Loss: 0.3594 Acc: 0.8352 F1 score: 0.8349 Precision: 0.8380 Recall: 0.8357 \n",
            "\n",
            "Epoch 3/19\n",
            "----------\n",
            "train Loss: 0.3942 Acc: 0.8189 F1 score: 0.8185 Precision: 0.8217 Recall: 0.8189 \n",
            "val Loss: 0.3515 Acc: 0.8388 F1 score: 0.8384 Precision: 0.8439 Recall: 0.8395 \n",
            "\n",
            "Epoch 4/19\n",
            "----------\n",
            "train Loss: 0.3862 Acc: 0.8267 F1 score: 0.8262 Precision: 0.8303 Recall: 0.8266 \n",
            "val Loss: 0.3453 Acc: 0.8480 F1 score: 0.8477 Precision: 0.8517 Recall: 0.8486 \n",
            "\n",
            "Epoch 5/19\n",
            "----------\n",
            "train Loss: 0.3811 Acc: 0.8291 F1 score: 0.8288 Precision: 0.8316 Recall: 0.8291 \n",
            "val Loss: 0.3413 Acc: 0.8388 F1 score: 0.8387 Precision: 0.8405 Recall: 0.8392 \n",
            "\n",
            "Epoch 6/19\n",
            "----------\n",
            "train Loss: 0.3760 Acc: 0.8363 F1 score: 0.8360 Precision: 0.8383 Recall: 0.8362 \n",
            "val Loss: 0.3469 Acc: 0.8352 F1 score: 0.8351 Precision: 0.8365 Recall: 0.8355 \n",
            "\n",
            "Epoch 7/19\n",
            "----------\n",
            "train Loss: 0.3673 Acc: 0.8383 F1 score: 0.8380 Precision: 0.8406 Recall: 0.8382 \n",
            "val Loss: 0.3450 Acc: 0.8333 F1 score: 0.8332 Precision: 0.8355 Recall: 0.8338 \n",
            "\n",
            "Epoch 8/19\n",
            "----------\n",
            "train Loss: 0.3650 Acc: 0.8346 F1 score: 0.8343 Precision: 0.8369 Recall: 0.8346 \n",
            "val Loss: 0.3439 Acc: 0.8297 F1 score: 0.8296 Precision: 0.8311 Recall: 0.8300 \n",
            "\n",
            "Epoch 9/19\n",
            "----------\n",
            "train Loss: 0.3647 Acc: 0.8365 F1 score: 0.8361 Precision: 0.8389 Recall: 0.8364 \n",
            "val Loss: 0.3441 Acc: 0.8370 F1 score: 0.8368 Precision: 0.8401 Recall: 0.8375 \n",
            "\n",
            "Epoch 10/19\n",
            "----------\n",
            "train Loss: 0.3594 Acc: 0.8405 F1 score: 0.8402 Precision: 0.8433 Recall: 0.8405 \n",
            "val Loss: 0.3439 Acc: 0.8388 F1 score: 0.8385 Precision: 0.8433 Recall: 0.8395 \n",
            "\n",
            "Epoch 11/19\n",
            "----------\n",
            "train Loss: 0.3571 Acc: 0.8420 F1 score: 0.8417 Precision: 0.8444 Recall: 0.8419 \n",
            "val Loss: 0.3456 Acc: 0.8370 F1 score: 0.8368 Precision: 0.8392 Recall: 0.8374 \n",
            "\n",
            "Epoch 12/19\n",
            "----------\n",
            "train Loss: 0.3582 Acc: 0.8401 F1 score: 0.8398 Precision: 0.8430 Recall: 0.8401 \n",
            "val Loss: 0.3443 Acc: 0.8370 F1 score: 0.8367 Precision: 0.8411 Recall: 0.8376 \n",
            "\n",
            "Epoch 13/19\n",
            "----------\n",
            "train Loss: 0.3587 Acc: 0.8409 F1 score: 0.8407 Precision: 0.8431 Recall: 0.8409 \n",
            "val Loss: 0.3454 Acc: 0.8333 F1 score: 0.8331 Precision: 0.8364 Recall: 0.8339 \n",
            "\n",
            "Epoch 14/19\n",
            "----------\n",
            "train Loss: 0.3560 Acc: 0.8434 F1 score: 0.8431 Precision: 0.8459 Recall: 0.8433 \n",
            "val Loss: 0.3450 Acc: 0.8315 F1 score: 0.8312 Precision: 0.8348 Recall: 0.8320 \n",
            "\n",
            "Epoch 15/19\n",
            "----------\n",
            "train Loss: 0.3577 Acc: 0.8403 F1 score: 0.8400 Precision: 0.8426 Recall: 0.8403 \n",
            "val Loss: 0.3449 Acc: 0.8352 F1 score: 0.8349 Precision: 0.8380 Recall: 0.8357 \n",
            "\n",
            "Epoch 16/19\n",
            "----------\n",
            "train Loss: 0.3581 Acc: 0.8462 F1 score: 0.8459 Precision: 0.8487 Recall: 0.8462 \n",
            "val Loss: 0.3448 Acc: 0.8352 F1 score: 0.8348 Precision: 0.8390 Recall: 0.8357 \n",
            "\n",
            "Epoch 17/19\n",
            "----------\n",
            "train Loss: 0.3600 Acc: 0.8430 F1 score: 0.8427 Precision: 0.8452 Recall: 0.8429 \n",
            "val Loss: 0.3448 Acc: 0.8352 F1 score: 0.8349 Precision: 0.8385 Recall: 0.8357 \n",
            "\n",
            "Epoch 18/19\n",
            "----------\n",
            "train Loss: 0.3580 Acc: 0.8428 F1 score: 0.8424 Precision: 0.8456 Recall: 0.8427 \n",
            "val Loss: 0.3452 Acc: 0.8352 F1 score: 0.8349 Precision: 0.8385 Recall: 0.8357 \n",
            "\n",
            "Epoch 19/19\n",
            "----------\n",
            "train Loss: 0.3561 Acc: 0.8442 F1 score: 0.8438 Precision: 0.8473 Recall: 0.8441 \n",
            "val Loss: 0.3454 Acc: 0.8315 F1 score: 0.8312 Precision: 0.8348 Recall: 0.8320 \n",
            "\n",
            "Training complete in 1m 27s\n",
            "Best val F1: 0.847715\n",
            "fold 1\n",
            "Epoch 0/19\n",
            "----------\n",
            "train Loss: 0.5450 Acc: 0.7167 F1 score: 0.7149 Precision: 0.7222 Recall: 0.7166 \n",
            "val Loss: 0.3992 Acc: 0.7875 F1 score: 0.7874 Precision: 0.7888 Recall: 0.7878 \n",
            "\n",
            "Epoch 1/19\n",
            "----------\n",
            "train Loss: 0.4375 Acc: 0.7898 F1 score: 0.7888 Precision: 0.7952 Recall: 0.7898 \n",
            "val Loss: 0.3912 Acc: 0.8040 F1 score: 0.8022 Precision: 0.8143 Recall: 0.8034 \n",
            "\n",
            "Epoch 2/19\n",
            "----------\n",
            "train Loss: 0.4097 Acc: 0.8077 F1 score: 0.8070 Precision: 0.8122 Recall: 0.8077 \n",
            "val Loss: 0.3375 Acc: 0.8388 F1 score: 0.8388 Precision: 0.8394 Recall: 0.8390 \n",
            "\n",
            "Epoch 3/19\n",
            "----------\n",
            "train Loss: 0.3902 Acc: 0.8251 F1 score: 0.8246 Precision: 0.8287 Recall: 0.8250 \n",
            "val Loss: 0.3373 Acc: 0.8407 F1 score: 0.8407 Precision: 0.8407 Recall: 0.8407 \n",
            "\n",
            "Epoch 4/19\n",
            "----------\n",
            "train Loss: 0.3949 Acc: 0.8210 F1 score: 0.8203 Precision: 0.8261 Recall: 0.8209 \n",
            "val Loss: 0.3322 Acc: 0.8352 F1 score: 0.8352 Precision: 0.8353 Recall: 0.8352 \n",
            "\n",
            "Epoch 5/19\n",
            "----------\n",
            "train Loss: 0.3781 Acc: 0.8305 F1 score: 0.8302 Precision: 0.8335 Recall: 0.8305 \n",
            "val Loss: 0.3240 Acc: 0.8480 F1 score: 0.8480 Precision: 0.8482 Recall: 0.8481 \n",
            "\n",
            "Epoch 6/19\n",
            "----------\n",
            "train Loss: 0.3753 Acc: 0.8342 F1 score: 0.8339 Precision: 0.8367 Recall: 0.8342 \n",
            "val Loss: 0.3255 Acc: 0.8516 F1 score: 0.8516 Precision: 0.8517 Recall: 0.8517 \n",
            "\n",
            "Epoch 7/19\n",
            "----------\n",
            "train Loss: 0.3696 Acc: 0.8381 F1 score: 0.8377 Precision: 0.8416 Recall: 0.8380 \n",
            "val Loss: 0.3258 Acc: 0.8462 F1 score: 0.8461 Precision: 0.8461 Recall: 0.8461 \n",
            "\n",
            "Epoch 8/19\n",
            "----------\n",
            "train Loss: 0.3693 Acc: 0.8352 F1 score: 0.8348 Precision: 0.8390 Recall: 0.8352 \n",
            "val Loss: 0.3233 Acc: 0.8480 F1 score: 0.8479 Precision: 0.8496 Recall: 0.8482 \n",
            "\n",
            "Epoch 9/19\n",
            "----------\n",
            "train Loss: 0.3642 Acc: 0.8385 F1 score: 0.8381 Precision: 0.8418 Recall: 0.8385 \n",
            "val Loss: 0.3235 Acc: 0.8535 F1 score: 0.8535 Precision: 0.8536 Recall: 0.8536 \n",
            "\n",
            "Epoch 10/19\n",
            "----------\n",
            "train Loss: 0.3683 Acc: 0.8424 F1 score: 0.8420 Precision: 0.8457 Recall: 0.8423 \n",
            "val Loss: 0.3251 Acc: 0.8480 F1 score: 0.8479 Precision: 0.8481 Recall: 0.8479 \n",
            "\n",
            "Epoch 11/19\n",
            "----------\n",
            "train Loss: 0.3593 Acc: 0.8428 F1 score: 0.8424 Precision: 0.8458 Recall: 0.8427 \n",
            "val Loss: 0.3237 Acc: 0.8498 F1 score: 0.8498 Precision: 0.8499 Recall: 0.8499 \n",
            "\n",
            "Epoch 12/19\n",
            "----------\n",
            "train Loss: 0.3615 Acc: 0.8434 F1 score: 0.8431 Precision: 0.8462 Recall: 0.8433 \n",
            "val Loss: 0.3242 Acc: 0.8553 F1 score: 0.8553 Precision: 0.8553 Recall: 0.8553 \n",
            "\n",
            "Epoch 13/19\n",
            "----------\n",
            "train Loss: 0.3638 Acc: 0.8369 F1 score: 0.8365 Precision: 0.8400 Recall: 0.8368 \n",
            "val Loss: 0.3228 Acc: 0.8498 F1 score: 0.8498 Precision: 0.8499 Recall: 0.8499 \n",
            "\n",
            "Epoch 14/19\n",
            "----------\n",
            "train Loss: 0.3586 Acc: 0.8413 F1 score: 0.8410 Precision: 0.8444 Recall: 0.8413 \n",
            "val Loss: 0.3235 Acc: 0.8498 F1 score: 0.8498 Precision: 0.8499 Recall: 0.8499 \n",
            "\n",
            "Epoch 15/19\n",
            "----------\n",
            "train Loss: 0.3583 Acc: 0.8446 F1 score: 0.8443 Precision: 0.8476 Recall: 0.8446 \n",
            "val Loss: 0.3234 Acc: 0.8535 F1 score: 0.8535 Precision: 0.8535 Recall: 0.8535 \n",
            "\n",
            "Epoch 16/19\n",
            "----------\n",
            "train Loss: 0.3610 Acc: 0.8444 F1 score: 0.8441 Precision: 0.8474 Recall: 0.8444 \n",
            "val Loss: 0.3249 Acc: 0.8480 F1 score: 0.8479 Precision: 0.8481 Recall: 0.8479 \n",
            "\n",
            "Epoch 17/19\n",
            "----------\n",
            "train Loss: 0.3601 Acc: 0.8407 F1 score: 0.8403 Precision: 0.8443 Recall: 0.8407 \n",
            "val Loss: 0.3229 Acc: 0.8516 F1 score: 0.8516 Precision: 0.8516 Recall: 0.8517 \n",
            "\n",
            "Epoch 18/19\n",
            "----------\n",
            "train Loss: 0.3635 Acc: 0.8454 F1 score: 0.8451 Precision: 0.8485 Recall: 0.8454 \n",
            "val Loss: 0.3242 Acc: 0.8480 F1 score: 0.8480 Precision: 0.8480 Recall: 0.8480 \n",
            "\n",
            "Epoch 19/19\n",
            "----------\n",
            "train Loss: 0.3605 Acc: 0.8442 F1 score: 0.8438 Precision: 0.8473 Recall: 0.8442 \n",
            "val Loss: 0.3235 Acc: 0.8535 F1 score: 0.8535 Precision: 0.8535 Recall: 0.8535 \n",
            "\n",
            "Training complete in 1m 27s\n",
            "Best val F1: 0.855299\n",
            "fold 2\n",
            "Epoch 0/19\n",
            "----------\n",
            "train Loss: 0.5510 Acc: 0.7051 F1 score: 0.7047 Precision: 0.7063 Recall: 0.7052 \n",
            "val Loss: 0.4552 Acc: 0.7436 F1 score: 0.7402 Precision: 0.7535 Recall: 0.7421 \n",
            "\n",
            "Epoch 1/19\n",
            "----------\n",
            "train Loss: 0.4478 Acc: 0.7866 F1 score: 0.7854 Precision: 0.7933 Recall: 0.7867 \n",
            "val Loss: 0.4121 Acc: 0.7802 F1 score: 0.7793 Precision: 0.7833 Recall: 0.7794 \n",
            "\n",
            "Epoch 2/19\n",
            "----------\n",
            "train Loss: 0.4093 Acc: 0.8134 F1 score: 0.8127 Precision: 0.8184 Recall: 0.8135 \n",
            "val Loss: 0.3855 Acc: 0.8077 F1 score: 0.8068 Precision: 0.8114 Recall: 0.8069 \n",
            "\n",
            "Epoch 3/19\n",
            "----------\n",
            "train Loss: 0.3918 Acc: 0.8238 F1 score: 0.8234 Precision: 0.8274 Recall: 0.8239 \n",
            "val Loss: 0.3778 Acc: 0.8168 F1 score: 0.8149 Precision: 0.8273 Recall: 0.8155 \n",
            "\n",
            "Epoch 4/19\n",
            "----------\n",
            "train Loss: 0.3781 Acc: 0.8340 F1 score: 0.8336 Precision: 0.8375 Recall: 0.8341 \n",
            "val Loss: 0.3727 Acc: 0.8187 F1 score: 0.8182 Precision: 0.8207 Recall: 0.8181 \n",
            "\n",
            "Epoch 5/19\n",
            "----------\n",
            "train Loss: 0.3731 Acc: 0.8367 F1 score: 0.8364 Precision: 0.8393 Recall: 0.8367 \n",
            "val Loss: 0.3632 Acc: 0.8205 F1 score: 0.8202 Precision: 0.8217 Recall: 0.8200 \n",
            "\n",
            "Epoch 6/19\n",
            "----------\n",
            "train Loss: 0.3689 Acc: 0.8342 F1 score: 0.8340 Precision: 0.8362 Recall: 0.8343 \n",
            "val Loss: 0.3731 Acc: 0.8114 F1 score: 0.8109 Precision: 0.8130 Recall: 0.8108 \n",
            "\n",
            "Epoch 7/19\n",
            "----------\n",
            "train Loss: 0.3668 Acc: 0.8395 F1 score: 0.8393 Precision: 0.8413 Recall: 0.8396 \n",
            "val Loss: 0.3664 Acc: 0.8187 F1 score: 0.8179 Precision: 0.8220 Recall: 0.8179 \n",
            "\n",
            "Epoch 8/19\n",
            "----------\n",
            "train Loss: 0.3600 Acc: 0.8405 F1 score: 0.8402 Precision: 0.8434 Recall: 0.8406 \n",
            "val Loss: 0.3657 Acc: 0.8242 F1 score: 0.8230 Precision: 0.8302 Recall: 0.8232 \n",
            "\n",
            "Epoch 9/19\n",
            "----------\n",
            "train Loss: 0.3602 Acc: 0.8428 F1 score: 0.8426 Precision: 0.8446 Recall: 0.8428 \n",
            "val Loss: 0.3635 Acc: 0.8187 F1 score: 0.8179 Precision: 0.8220 Recall: 0.8179 \n",
            "\n",
            "Epoch 10/19\n",
            "----------\n",
            "train Loss: 0.3521 Acc: 0.8470 F1 score: 0.8469 Precision: 0.8488 Recall: 0.8471 \n",
            "val Loss: 0.3642 Acc: 0.8187 F1 score: 0.8179 Precision: 0.8220 Recall: 0.8179 \n",
            "\n",
            "Epoch 11/19\n",
            "----------\n",
            "train Loss: 0.3552 Acc: 0.8434 F1 score: 0.8431 Precision: 0.8457 Recall: 0.8434 \n",
            "val Loss: 0.3649 Acc: 0.8242 F1 score: 0.8230 Precision: 0.8302 Recall: 0.8232 \n",
            "\n",
            "Epoch 12/19\n",
            "----------\n",
            "train Loss: 0.3509 Acc: 0.8444 F1 score: 0.8442 Precision: 0.8467 Recall: 0.8445 \n",
            "val Loss: 0.3635 Acc: 0.8205 F1 score: 0.8200 Precision: 0.8224 Recall: 0.8199 \n",
            "\n",
            "Epoch 13/19\n",
            "----------\n",
            "train Loss: 0.3550 Acc: 0.8454 F1 score: 0.8452 Precision: 0.8474 Recall: 0.8455 \n",
            "val Loss: 0.3633 Acc: 0.8114 F1 score: 0.8107 Precision: 0.8141 Recall: 0.8106 \n",
            "\n",
            "Epoch 14/19\n",
            "----------\n",
            "train Loss: 0.3521 Acc: 0.8468 F1 score: 0.8466 Precision: 0.8489 Recall: 0.8469 \n",
            "val Loss: 0.3634 Acc: 0.8205 F1 score: 0.8195 Precision: 0.8252 Recall: 0.8196 \n",
            "\n",
            "Epoch 15/19\n",
            "----------\n",
            "train Loss: 0.3581 Acc: 0.8424 F1 score: 0.8422 Precision: 0.8444 Recall: 0.8424 \n",
            "val Loss: 0.3646 Acc: 0.8260 F1 score: 0.8247 Precision: 0.8331 Recall: 0.8249 \n",
            "\n",
            "Epoch 16/19\n",
            "----------\n",
            "train Loss: 0.3521 Acc: 0.8509 F1 score: 0.8507 Precision: 0.8532 Recall: 0.8510 \n",
            "val Loss: 0.3638 Acc: 0.8223 F1 score: 0.8212 Precision: 0.8280 Recall: 0.8214 \n",
            "\n",
            "Epoch 17/19\n",
            "----------\n",
            "train Loss: 0.3540 Acc: 0.8450 F1 score: 0.8448 Precision: 0.8472 Recall: 0.8451 \n",
            "val Loss: 0.3632 Acc: 0.8150 F1 score: 0.8143 Precision: 0.8183 Recall: 0.8143 \n",
            "\n",
            "Epoch 18/19\n",
            "----------\n",
            "train Loss: 0.3502 Acc: 0.8456 F1 score: 0.8454 Precision: 0.8480 Recall: 0.8457 \n",
            "val Loss: 0.3634 Acc: 0.8168 F1 score: 0.8161 Precision: 0.8204 Recall: 0.8161 \n",
            "\n",
            "Epoch 19/19\n",
            "----------\n",
            "train Loss: 0.3495 Acc: 0.8462 F1 score: 0.8460 Precision: 0.8484 Recall: 0.8463 \n",
            "val Loss: 0.3638 Acc: 0.8168 F1 score: 0.8160 Precision: 0.8209 Recall: 0.8160 \n",
            "\n",
            "Training complete in 1m 27s\n",
            "Best val F1: 0.824708\n",
            "fold 3\n",
            "Epoch 0/19\n",
            "----------\n",
            "train Loss: 0.5508 Acc: 0.7063 F1 score: 0.7058 Precision: 0.7075 Recall: 0.7062 \n",
            "val Loss: 0.4386 Acc: 0.7637 F1 score: 0.7618 Precision: 0.7808 Recall: 0.7681 \n",
            "\n",
            "Epoch 1/19\n",
            "----------\n",
            "train Loss: 0.4506 Acc: 0.7798 F1 score: 0.7787 Precision: 0.7852 Recall: 0.7796 \n",
            "val Loss: 0.4123 Acc: 0.7894 F1 score: 0.7881 Precision: 0.8044 Recall: 0.7933 \n",
            "\n",
            "Epoch 2/19\n",
            "----------\n",
            "train Loss: 0.4141 Acc: 0.8092 F1 score: 0.8084 Precision: 0.8138 Recall: 0.8089 \n",
            "val Loss: 0.3851 Acc: 0.8095 F1 score: 0.8095 Precision: 0.8121 Recall: 0.8111 \n",
            "\n",
            "Epoch 3/19\n",
            "----------\n",
            "train Loss: 0.3862 Acc: 0.8255 F1 score: 0.8248 Precision: 0.8295 Recall: 0.8252 \n",
            "val Loss: 0.3848 Acc: 0.8095 F1 score: 0.8094 Precision: 0.8136 Recall: 0.8116 \n",
            "\n",
            "Epoch 4/19\n",
            "----------\n",
            "train Loss: 0.3816 Acc: 0.8291 F1 score: 0.8286 Precision: 0.8327 Recall: 0.8289 \n",
            "val Loss: 0.3724 Acc: 0.8187 F1 score: 0.8187 Precision: 0.8211 Recall: 0.8203 \n",
            "\n",
            "Epoch 5/19\n",
            "----------\n",
            "train Loss: 0.3741 Acc: 0.8393 F1 score: 0.8390 Precision: 0.8416 Recall: 0.8391 \n",
            "val Loss: 0.3709 Acc: 0.8114 F1 score: 0.8113 Precision: 0.8129 Recall: 0.8126 \n",
            "\n",
            "Epoch 6/19\n",
            "----------\n",
            "train Loss: 0.3723 Acc: 0.8338 F1 score: 0.8334 Precision: 0.8363 Recall: 0.8336 \n",
            "val Loss: 0.3758 Acc: 0.8205 F1 score: 0.8202 Precision: 0.8272 Recall: 0.8231 \n",
            "\n",
            "Epoch 7/19\n",
            "----------\n",
            "train Loss: 0.3610 Acc: 0.8403 F1 score: 0.8401 Precision: 0.8418 Recall: 0.8402 \n",
            "val Loss: 0.3710 Acc: 0.8150 F1 score: 0.8149 Precision: 0.8188 Recall: 0.8170 \n",
            "\n",
            "Epoch 8/19\n",
            "----------\n",
            "train Loss: 0.3608 Acc: 0.8401 F1 score: 0.8398 Precision: 0.8421 Recall: 0.8400 \n",
            "val Loss: 0.3714 Acc: 0.8150 F1 score: 0.8149 Precision: 0.8194 Recall: 0.8171 \n",
            "\n",
            "Epoch 9/19\n",
            "----------\n",
            "train Loss: 0.3631 Acc: 0.8409 F1 score: 0.8406 Precision: 0.8432 Recall: 0.8408 \n",
            "val Loss: 0.3693 Acc: 0.8187 F1 score: 0.8185 Precision: 0.8231 Recall: 0.8208 \n",
            "\n",
            "Epoch 10/19\n",
            "----------\n",
            "train Loss: 0.3579 Acc: 0.8413 F1 score: 0.8410 Precision: 0.8441 Recall: 0.8412 \n",
            "val Loss: 0.3699 Acc: 0.8150 F1 score: 0.8150 Precision: 0.8178 Recall: 0.8167 \n",
            "\n",
            "Epoch 11/19\n",
            "----------\n",
            "train Loss: 0.3540 Acc: 0.8454 F1 score: 0.8451 Precision: 0.8476 Recall: 0.8453 \n",
            "val Loss: 0.3719 Acc: 0.8187 F1 score: 0.8185 Precision: 0.8237 Recall: 0.8209 \n",
            "\n",
            "Epoch 12/19\n",
            "----------\n",
            "train Loss: 0.3587 Acc: 0.8434 F1 score: 0.8431 Precision: 0.8458 Recall: 0.8432 \n",
            "val Loss: 0.3697 Acc: 0.8168 F1 score: 0.8168 Precision: 0.8194 Recall: 0.8185 \n",
            "\n",
            "Epoch 13/19\n",
            "----------\n",
            "train Loss: 0.3533 Acc: 0.8473 F1 score: 0.8470 Precision: 0.8494 Recall: 0.8471 \n",
            "val Loss: 0.3703 Acc: 0.8114 F1 score: 0.8113 Precision: 0.8146 Recall: 0.8132 \n",
            "\n",
            "Epoch 14/19\n",
            "----------\n",
            "train Loss: 0.3574 Acc: 0.8432 F1 score: 0.8429 Precision: 0.8455 Recall: 0.8430 \n",
            "val Loss: 0.3705 Acc: 0.8168 F1 score: 0.8167 Precision: 0.8209 Recall: 0.8189 \n",
            "\n",
            "Epoch 15/19\n",
            "----------\n",
            "train Loss: 0.3527 Acc: 0.8464 F1 score: 0.8461 Precision: 0.8490 Recall: 0.8463 \n",
            "val Loss: 0.3711 Acc: 0.8205 F1 score: 0.8204 Precision: 0.8252 Recall: 0.8227 \n",
            "\n",
            "Epoch 16/19\n",
            "----------\n",
            "train Loss: 0.3523 Acc: 0.8442 F1 score: 0.8439 Precision: 0.8464 Recall: 0.8440 \n",
            "val Loss: 0.3710 Acc: 0.8168 F1 score: 0.8168 Precision: 0.8199 Recall: 0.8186 \n",
            "\n",
            "Epoch 17/19\n",
            "----------\n",
            "train Loss: 0.3538 Acc: 0.8475 F1 score: 0.8472 Precision: 0.8496 Recall: 0.8473 \n",
            "val Loss: 0.3713 Acc: 0.8168 F1 score: 0.8167 Precision: 0.8215 Recall: 0.8190 \n",
            "\n",
            "Epoch 18/19\n",
            "----------\n",
            "train Loss: 0.3537 Acc: 0.8462 F1 score: 0.8459 Precision: 0.8484 Recall: 0.8461 \n",
            "val Loss: 0.3724 Acc: 0.8187 F1 score: 0.8185 Precision: 0.8231 Recall: 0.8208 \n",
            "\n",
            "Epoch 19/19\n",
            "----------\n",
            "train Loss: 0.3547 Acc: 0.8440 F1 score: 0.8437 Precision: 0.8460 Recall: 0.8438 \n",
            "val Loss: 0.3714 Acc: 0.8168 F1 score: 0.8167 Precision: 0.8209 Recall: 0.8189 \n",
            "\n",
            "Training complete in 1m 27s\n",
            "Best val F1: 0.820359\n",
            "fold 4\n",
            "Epoch 0/19\n",
            "----------\n",
            "train Loss: 0.5579 Acc: 0.7037 F1 score: 0.7030 Precision: 0.7057 Recall: 0.7037 \n",
            "val Loss: 0.4405 Acc: 0.7601 F1 score: 0.7597 Precision: 0.7611 Recall: 0.7598 \n",
            "\n",
            "Epoch 1/19\n",
            "----------\n",
            "train Loss: 0.4446 Acc: 0.7827 F1 score: 0.7818 Precision: 0.7877 Recall: 0.7827 \n",
            "val Loss: 0.3830 Acc: 0.7985 F1 score: 0.7973 Precision: 0.8045 Recall: 0.7980 \n",
            "\n",
            "Epoch 2/19\n",
            "----------\n",
            "train Loss: 0.4095 Acc: 0.8104 F1 score: 0.8097 Precision: 0.8147 Recall: 0.8104 \n",
            "val Loss: 0.3608 Acc: 0.8333 F1 score: 0.8309 Precision: 0.8512 Recall: 0.8325 \n",
            "\n",
            "Epoch 3/19\n",
            "----------\n",
            "train Loss: 0.3959 Acc: 0.8206 F1 score: 0.8201 Precision: 0.8242 Recall: 0.8206 \n",
            "val Loss: 0.3390 Acc: 0.8333 F1 score: 0.8323 Precision: 0.8405 Recall: 0.8328 \n",
            "\n",
            "Epoch 4/19\n",
            "----------\n",
            "train Loss: 0.3861 Acc: 0.8257 F1 score: 0.8254 Precision: 0.8277 Recall: 0.8257 \n",
            "val Loss: 0.3359 Acc: 0.8425 F1 score: 0.8409 Precision: 0.8547 Recall: 0.8418 \n",
            "\n",
            "Epoch 5/19\n",
            "----------\n",
            "train Loss: 0.3811 Acc: 0.8297 F1 score: 0.8293 Precision: 0.8333 Recall: 0.8298 \n",
            "val Loss: 0.3383 Acc: 0.8370 F1 score: 0.8353 Precision: 0.8495 Recall: 0.8363 \n",
            "\n",
            "Epoch 6/19\n",
            "----------\n",
            "train Loss: 0.3728 Acc: 0.8338 F1 score: 0.8336 Precision: 0.8359 Recall: 0.8338 \n",
            "val Loss: 0.3307 Acc: 0.8315 F1 score: 0.8310 Precision: 0.8346 Recall: 0.8311 \n",
            "\n",
            "Epoch 7/19\n",
            "----------\n",
            "train Loss: 0.3707 Acc: 0.8320 F1 score: 0.8317 Precision: 0.8340 Recall: 0.8320 \n",
            "val Loss: 0.3300 Acc: 0.8333 F1 score: 0.8326 Precision: 0.8384 Recall: 0.8329 \n",
            "\n",
            "Epoch 8/19\n",
            "----------\n",
            "train Loss: 0.3670 Acc: 0.8395 F1 score: 0.8392 Precision: 0.8420 Recall: 0.8395 \n",
            "val Loss: 0.3305 Acc: 0.8443 F1 score: 0.8433 Precision: 0.8525 Recall: 0.8438 \n",
            "\n",
            "Epoch 9/19\n",
            "----------\n",
            "train Loss: 0.3645 Acc: 0.8377 F1 score: 0.8374 Precision: 0.8402 Recall: 0.8377 \n",
            "val Loss: 0.3302 Acc: 0.8425 F1 score: 0.8414 Precision: 0.8510 Recall: 0.8419 \n",
            "\n",
            "Epoch 10/19\n",
            "----------\n",
            "train Loss: 0.3609 Acc: 0.8426 F1 score: 0.8423 Precision: 0.8450 Recall: 0.8426 \n",
            "val Loss: 0.3294 Acc: 0.8407 F1 score: 0.8398 Precision: 0.8472 Recall: 0.8402 \n",
            "\n",
            "Epoch 11/19\n",
            "----------\n",
            "train Loss: 0.3612 Acc: 0.8409 F1 score: 0.8407 Precision: 0.8430 Recall: 0.8410 \n",
            "val Loss: 0.3290 Acc: 0.8388 F1 score: 0.8379 Precision: 0.8457 Recall: 0.8383 \n",
            "\n",
            "Epoch 12/19\n",
            "----------\n",
            "train Loss: 0.3599 Acc: 0.8391 F1 score: 0.8389 Precision: 0.8409 Recall: 0.8391 \n",
            "val Loss: 0.3295 Acc: 0.8407 F1 score: 0.8397 Precision: 0.8480 Recall: 0.8401 \n",
            "\n",
            "Epoch 13/19\n",
            "----------\n",
            "train Loss: 0.3619 Acc: 0.8430 F1 score: 0.8428 Precision: 0.8449 Recall: 0.8430 \n",
            "val Loss: 0.3275 Acc: 0.8388 F1 score: 0.8380 Precision: 0.8450 Recall: 0.8383 \n",
            "\n",
            "Epoch 14/19\n",
            "----------\n",
            "train Loss: 0.3600 Acc: 0.8397 F1 score: 0.8395 Precision: 0.8418 Recall: 0.8397 \n",
            "val Loss: 0.3282 Acc: 0.8370 F1 score: 0.8361 Precision: 0.8435 Recall: 0.8365 \n",
            "\n",
            "Epoch 15/19\n",
            "----------\n",
            "train Loss: 0.3586 Acc: 0.8426 F1 score: 0.8424 Precision: 0.8443 Recall: 0.8426 \n",
            "val Loss: 0.3275 Acc: 0.8370 F1 score: 0.8361 Precision: 0.8435 Recall: 0.8365 \n",
            "\n",
            "Epoch 16/19\n",
            "----------\n",
            "train Loss: 0.3570 Acc: 0.8430 F1 score: 0.8428 Precision: 0.8449 Recall: 0.8430 \n",
            "val Loss: 0.3284 Acc: 0.8370 F1 score: 0.8361 Precision: 0.8435 Recall: 0.8365 \n",
            "\n",
            "Epoch 17/19\n",
            "----------\n",
            "train Loss: 0.3596 Acc: 0.8432 F1 score: 0.8430 Precision: 0.8451 Recall: 0.8432 \n",
            "val Loss: 0.3273 Acc: 0.8370 F1 score: 0.8361 Precision: 0.8435 Recall: 0.8365 \n",
            "\n",
            "Epoch 18/19\n",
            "----------\n",
            "train Loss: 0.3565 Acc: 0.8415 F1 score: 0.8413 Precision: 0.8441 Recall: 0.8416 \n",
            "val Loss: 0.3289 Acc: 0.8370 F1 score: 0.8361 Precision: 0.8435 Recall: 0.8365 \n",
            "\n",
            "Epoch 19/19\n",
            "----------\n",
            "train Loss: 0.3562 Acc: 0.8444 F1 score: 0.8442 Precision: 0.8466 Recall: 0.8444 \n",
            "val Loss: 0.3288 Acc: 0.8352 F1 score: 0.8342 Precision: 0.8420 Recall: 0.8346 \n",
            "\n",
            "Training complete in 1m 27s\n",
            "Best val F1: 0.843258\n",
            "fold 5\n",
            "Epoch 0/19\n",
            "----------\n",
            "train Loss: 0.5534 Acc: 0.7112 F1 score: 0.7089 Precision: 0.7189 Recall: 0.7117 \n",
            "val Loss: 0.4146 Acc: 0.7967 F1 score: 0.7934 Precision: 0.8054 Recall: 0.7927 \n",
            "\n",
            "Epoch 1/19\n",
            "----------\n",
            "train Loss: 0.4528 Acc: 0.7788 F1 score: 0.7781 Precision: 0.7829 Recall: 0.7791 \n",
            "val Loss: 0.3837 Acc: 0.8114 F1 score: 0.8108 Precision: 0.8112 Recall: 0.8106 \n",
            "\n",
            "Epoch 2/19\n",
            "----------\n",
            "train Loss: 0.4124 Acc: 0.8118 F1 score: 0.8110 Precision: 0.8180 Recall: 0.8122 \n",
            "val Loss: 0.3539 Acc: 0.8333 F1 score: 0.8315 Precision: 0.8389 Recall: 0.8303 \n",
            "\n",
            "Epoch 3/19\n",
            "----------\n",
            "train Loss: 0.3935 Acc: 0.8228 F1 score: 0.8225 Precision: 0.8257 Recall: 0.8230 \n",
            "val Loss: 0.3588 Acc: 0.8132 F1 score: 0.8126 Precision: 0.8131 Recall: 0.8123 \n",
            "\n",
            "Epoch 4/19\n",
            "----------\n",
            "train Loss: 0.3822 Acc: 0.8342 F1 score: 0.8339 Precision: 0.8375 Recall: 0.8345 \n",
            "val Loss: 0.3447 Acc: 0.8425 F1 score: 0.8414 Precision: 0.8451 Recall: 0.8404 \n",
            "\n",
            "Epoch 5/19\n",
            "----------\n",
            "train Loss: 0.3745 Acc: 0.8381 F1 score: 0.8379 Precision: 0.8404 Recall: 0.8383 \n",
            "val Loss: 0.3462 Acc: 0.8242 F1 score: 0.8236 Precision: 0.8243 Recall: 0.8232 \n",
            "\n",
            "Epoch 6/19\n",
            "----------\n",
            "train Loss: 0.3712 Acc: 0.8381 F1 score: 0.8379 Precision: 0.8396 Recall: 0.8382 \n",
            "val Loss: 0.3450 Acc: 0.8187 F1 score: 0.8182 Precision: 0.8184 Recall: 0.8181 \n",
            "\n",
            "Epoch 7/19\n",
            "----------\n",
            "train Loss: 0.3625 Acc: 0.8411 F1 score: 0.8410 Precision: 0.8429 Recall: 0.8413 \n",
            "val Loss: 0.3432 Acc: 0.8223 F1 score: 0.8219 Precision: 0.8221 Recall: 0.8218 \n",
            "\n",
            "Epoch 8/19\n",
            "----------\n",
            "train Loss: 0.3625 Acc: 0.8405 F1 score: 0.8403 Precision: 0.8429 Recall: 0.8407 \n",
            "val Loss: 0.3426 Acc: 0.8333 F1 score: 0.8325 Precision: 0.8344 Recall: 0.8318 \n",
            "\n",
            "Epoch 9/19\n",
            "----------\n",
            "train Loss: 0.3584 Acc: 0.8444 F1 score: 0.8443 Precision: 0.8460 Recall: 0.8446 \n",
            "val Loss: 0.3438 Acc: 0.8242 F1 score: 0.8237 Precision: 0.8240 Recall: 0.8235 \n",
            "\n",
            "Epoch 10/19\n",
            "----------\n",
            "train Loss: 0.3593 Acc: 0.8452 F1 score: 0.8451 Precision: 0.8465 Recall: 0.8454 \n",
            "val Loss: 0.3429 Acc: 0.8278 F1 score: 0.8272 Precision: 0.8280 Recall: 0.8269 \n",
            "\n",
            "Epoch 11/19\n",
            "----------\n",
            "train Loss: 0.3622 Acc: 0.8391 F1 score: 0.8389 Precision: 0.8409 Recall: 0.8393 \n",
            "val Loss: 0.3425 Acc: 0.8260 F1 score: 0.8254 Precision: 0.8261 Recall: 0.8251 \n",
            "\n",
            "Epoch 12/19\n",
            "----------\n",
            "train Loss: 0.3561 Acc: 0.8415 F1 score: 0.8414 Precision: 0.8429 Recall: 0.8417 \n",
            "val Loss: 0.3451 Acc: 0.8242 F1 score: 0.8238 Precision: 0.8239 Recall: 0.8237 \n",
            "\n",
            "Epoch 13/19\n",
            "----------\n",
            "train Loss: 0.3531 Acc: 0.8448 F1 score: 0.8447 Precision: 0.8463 Recall: 0.8450 \n",
            "val Loss: 0.3442 Acc: 0.8223 F1 score: 0.8218 Precision: 0.8222 Recall: 0.8216 \n",
            "\n",
            "Epoch 14/19\n",
            "----------\n",
            "train Loss: 0.3545 Acc: 0.8454 F1 score: 0.8453 Precision: 0.8465 Recall: 0.8456 \n",
            "val Loss: 0.3449 Acc: 0.8223 F1 score: 0.8219 Precision: 0.8221 Recall: 0.8218 \n",
            "\n",
            "Epoch 15/19\n",
            "----------\n",
            "train Loss: 0.3514 Acc: 0.8446 F1 score: 0.8444 Precision: 0.8466 Recall: 0.8448 \n",
            "val Loss: 0.3459 Acc: 0.8205 F1 score: 0.8202 Precision: 0.8202 Recall: 0.8202 \n",
            "\n",
            "Epoch 16/19\n",
            "----------\n",
            "train Loss: 0.3531 Acc: 0.8460 F1 score: 0.8459 Precision: 0.8476 Recall: 0.8462 \n",
            "val Loss: 0.3462 Acc: 0.8223 F1 score: 0.8219 Precision: 0.8221 Recall: 0.8218 \n",
            "\n",
            "Epoch 17/19\n",
            "----------\n",
            "train Loss: 0.3541 Acc: 0.8444 F1 score: 0.8443 Precision: 0.8457 Recall: 0.8445 \n",
            "val Loss: 0.3437 Acc: 0.8223 F1 score: 0.8218 Precision: 0.8224 Recall: 0.8214 \n",
            "\n",
            "Epoch 18/19\n",
            "----------\n",
            "train Loss: 0.3540 Acc: 0.8460 F1 score: 0.8459 Precision: 0.8474 Recall: 0.8462 \n",
            "val Loss: 0.3445 Acc: 0.8205 F1 score: 0.8200 Precision: 0.8203 Recall: 0.8198 \n",
            "\n",
            "Epoch 19/19\n",
            "----------\n",
            "train Loss: 0.3509 Acc: 0.8507 F1 score: 0.8506 Precision: 0.8521 Recall: 0.8509 \n",
            "val Loss: 0.3448 Acc: 0.8223 F1 score: 0.8219 Precision: 0.8221 Recall: 0.8218 \n",
            "\n",
            "Training complete in 1m 27s\n",
            "Best val F1: 0.841365\n",
            "fold 6\n",
            "Epoch 0/19\n",
            "----------\n",
            "train Loss: 0.5547 Acc: 0.7127 F1 score: 0.7113 Precision: 0.7170 Recall: 0.7128 \n",
            "val Loss: 0.4255 Acc: 0.7835 F1 score: 0.7835 Precision: 0.7835 Recall: 0.7835 \n",
            "\n",
            "Epoch 1/19\n",
            "----------\n",
            "train Loss: 0.4470 Acc: 0.7827 F1 score: 0.7818 Precision: 0.7879 Recall: 0.7828 \n",
            "val Loss: 0.3700 Acc: 0.8110 F1 score: 0.8082 Precision: 0.8267 Recall: 0.8096 \n",
            "\n",
            "Epoch 2/19\n",
            "----------\n",
            "train Loss: 0.4086 Acc: 0.8121 F1 score: 0.8114 Precision: 0.8170 Recall: 0.8121 \n",
            "val Loss: 0.3511 Acc: 0.8422 F1 score: 0.8420 Precision: 0.8429 Recall: 0.8419 \n",
            "\n",
            "Epoch 3/19\n",
            "----------\n",
            "train Loss: 0.3936 Acc: 0.8204 F1 score: 0.8198 Precision: 0.8253 Recall: 0.8205 \n",
            "val Loss: 0.3476 Acc: 0.8385 F1 score: 0.8376 Precision: 0.8442 Recall: 0.8377 \n",
            "\n",
            "Epoch 4/19\n",
            "----------\n",
            "train Loss: 0.3817 Acc: 0.8259 F1 score: 0.8255 Precision: 0.8289 Recall: 0.8260 \n",
            "val Loss: 0.3486 Acc: 0.8330 F1 score: 0.8330 Precision: 0.8330 Recall: 0.8330 \n",
            "\n",
            "Epoch 5/19\n",
            "----------\n",
            "train Loss: 0.3778 Acc: 0.8351 F1 score: 0.8347 Precision: 0.8381 Recall: 0.8351 \n",
            "val Loss: 0.3378 Acc: 0.8422 F1 score: 0.8415 Precision: 0.8461 Recall: 0.8415 \n",
            "\n",
            "Epoch 6/19\n",
            "----------\n",
            "train Loss: 0.3768 Acc: 0.8330 F1 score: 0.8328 Precision: 0.8353 Recall: 0.8331 \n",
            "val Loss: 0.3378 Acc: 0.8477 F1 score: 0.8475 Precision: 0.8484 Recall: 0.8474 \n",
            "\n",
            "Epoch 7/19\n",
            "----------\n",
            "train Loss: 0.3690 Acc: 0.8336 F1 score: 0.8331 Precision: 0.8384 Recall: 0.8337 \n",
            "val Loss: 0.3350 Acc: 0.8422 F1 score: 0.8418 Precision: 0.8446 Recall: 0.8417 \n",
            "\n",
            "Epoch 8/19\n",
            "----------\n",
            "train Loss: 0.3628 Acc: 0.8422 F1 score: 0.8418 Precision: 0.8455 Recall: 0.8423 \n",
            "val Loss: 0.3343 Acc: 0.8440 F1 score: 0.8436 Precision: 0.8467 Recall: 0.8435 \n",
            "\n",
            "Epoch 9/19\n",
            "----------\n",
            "train Loss: 0.3627 Acc: 0.8424 F1 score: 0.8421 Precision: 0.8450 Recall: 0.8425 \n",
            "val Loss: 0.3343 Acc: 0.8477 F1 score: 0.8473 Precision: 0.8500 Recall: 0.8472 \n",
            "\n",
            "Epoch 10/19\n",
            "----------\n",
            "train Loss: 0.3610 Acc: 0.8430 F1 score: 0.8427 Precision: 0.8455 Recall: 0.8431 \n",
            "val Loss: 0.3351 Acc: 0.8440 F1 score: 0.8436 Precision: 0.8467 Recall: 0.8435 \n",
            "\n",
            "Epoch 11/19\n",
            "----------\n",
            "train Loss: 0.3637 Acc: 0.8367 F1 score: 0.8364 Precision: 0.8396 Recall: 0.8368 \n",
            "val Loss: 0.3364 Acc: 0.8440 F1 score: 0.8437 Precision: 0.8455 Recall: 0.8436 \n",
            "\n",
            "Epoch 12/19\n",
            "----------\n",
            "train Loss: 0.3609 Acc: 0.8397 F1 score: 0.8395 Precision: 0.8423 Recall: 0.8398 \n",
            "val Loss: 0.3349 Acc: 0.8440 F1 score: 0.8435 Precision: 0.8472 Recall: 0.8434 \n",
            "\n",
            "Epoch 13/19\n",
            "----------\n",
            "train Loss: 0.3585 Acc: 0.8410 F1 score: 0.8407 Precision: 0.8432 Recall: 0.8410 \n",
            "val Loss: 0.3372 Acc: 0.8440 F1 score: 0.8437 Precision: 0.8459 Recall: 0.8436 \n",
            "\n",
            "Epoch 14/19\n",
            "----------\n",
            "train Loss: 0.3617 Acc: 0.8402 F1 score: 0.8399 Precision: 0.8422 Recall: 0.8402 \n",
            "val Loss: 0.3370 Acc: 0.8440 F1 score: 0.8437 Precision: 0.8459 Recall: 0.8436 \n",
            "\n",
            "Epoch 15/19\n",
            "----------\n",
            "train Loss: 0.3544 Acc: 0.8416 F1 score: 0.8413 Precision: 0.8442 Recall: 0.8416 \n",
            "val Loss: 0.3369 Acc: 0.8440 F1 score: 0.8437 Precision: 0.8455 Recall: 0.8436 \n",
            "\n",
            "Epoch 16/19\n",
            "----------\n",
            "train Loss: 0.3578 Acc: 0.8473 F1 score: 0.8471 Precision: 0.8493 Recall: 0.8473 \n",
            "val Loss: 0.3375 Acc: 0.8477 F1 score: 0.8475 Precision: 0.8486 Recall: 0.8474 \n",
            "\n",
            "Epoch 17/19\n",
            "----------\n",
            "train Loss: 0.3579 Acc: 0.8424 F1 score: 0.8421 Precision: 0.8448 Recall: 0.8425 \n",
            "val Loss: 0.3368 Acc: 0.8440 F1 score: 0.8437 Precision: 0.8455 Recall: 0.8436 \n",
            "\n",
            "Epoch 18/19\n",
            "----------\n",
            "train Loss: 0.3584 Acc: 0.8418 F1 score: 0.8415 Precision: 0.8441 Recall: 0.8418 \n",
            "val Loss: 0.3362 Acc: 0.8422 F1 score: 0.8417 Precision: 0.8451 Recall: 0.8416 \n",
            "\n",
            "Epoch 19/19\n",
            "----------\n",
            "train Loss: 0.3592 Acc: 0.8406 F1 score: 0.8403 Precision: 0.8431 Recall: 0.8406 \n",
            "val Loss: 0.3368 Acc: 0.8459 F1 score: 0.8456 Precision: 0.8472 Recall: 0.8455 \n",
            "\n",
            "Training complete in 1m 27s\n",
            "Best val F1: 0.847540\n",
            "fold 7\n",
            "Epoch 0/19\n",
            "----------\n",
            "train Loss: 0.5530 Acc: 0.7157 F1 score: 0.7147 Precision: 0.7183 Recall: 0.7154 \n",
            "val Loss: 0.4015 Acc: 0.7853 F1 score: 0.7853 Precision: 0.7871 Recall: 0.7874 \n",
            "\n",
            "Epoch 1/19\n",
            "----------\n",
            "train Loss: 0.4515 Acc: 0.7838 F1 score: 0.7824 Precision: 0.7900 Recall: 0.7833 \n",
            "val Loss: 0.3839 Acc: 0.8055 F1 score: 0.8046 Precision: 0.8220 Recall: 0.8114 \n",
            "\n",
            "Epoch 2/19\n",
            "----------\n",
            "train Loss: 0.4134 Acc: 0.8119 F1 score: 0.8109 Precision: 0.8174 Recall: 0.8115 \n",
            "val Loss: 0.3654 Acc: 0.8294 F1 score: 0.8290 Precision: 0.8408 Recall: 0.8343 \n",
            "\n",
            "Epoch 3/19\n",
            "----------\n",
            "train Loss: 0.4017 Acc: 0.8180 F1 score: 0.8173 Precision: 0.8215 Recall: 0.8176 \n",
            "val Loss: 0.3534 Acc: 0.8385 F1 score: 0.8384 Precision: 0.8447 Recall: 0.8422 \n",
            "\n",
            "Epoch 4/19\n",
            "----------\n",
            "train Loss: 0.3804 Acc: 0.8290 F1 score: 0.8285 Precision: 0.8317 Recall: 0.8287 \n",
            "val Loss: 0.3525 Acc: 0.8294 F1 score: 0.8294 Precision: 0.8317 Recall: 0.8317 \n",
            "\n",
            "Epoch 5/19\n",
            "----------\n",
            "train Loss: 0.3809 Acc: 0.8328 F1 score: 0.8325 Precision: 0.8348 Recall: 0.8326 \n",
            "val Loss: 0.3461 Acc: 0.8349 F1 score: 0.8348 Precision: 0.8385 Recall: 0.8377 \n",
            "\n",
            "Epoch 6/19\n",
            "----------\n",
            "train Loss: 0.3760 Acc: 0.8320 F1 score: 0.8315 Precision: 0.8351 Recall: 0.8317 \n",
            "val Loss: 0.3445 Acc: 0.8349 F1 score: 0.8348 Precision: 0.8385 Recall: 0.8377 \n",
            "\n",
            "Epoch 7/19\n",
            "----------\n",
            "train Loss: 0.3659 Acc: 0.8387 F1 score: 0.8384 Precision: 0.8409 Recall: 0.8385 \n",
            "val Loss: 0.3456 Acc: 0.8367 F1 score: 0.8367 Precision: 0.8412 Recall: 0.8399 \n",
            "\n",
            "Epoch 8/19\n",
            "----------\n",
            "train Loss: 0.3615 Acc: 0.8400 F1 score: 0.8396 Precision: 0.8426 Recall: 0.8397 \n",
            "val Loss: 0.3467 Acc: 0.8367 F1 score: 0.8367 Precision: 0.8412 Recall: 0.8399 \n",
            "\n",
            "Epoch 9/19\n",
            "----------\n",
            "train Loss: 0.3627 Acc: 0.8426 F1 score: 0.8423 Precision: 0.8445 Recall: 0.8424 \n",
            "val Loss: 0.3441 Acc: 0.8385 F1 score: 0.8385 Precision: 0.8428 Recall: 0.8416 \n",
            "\n",
            "Epoch 10/19\n",
            "----------\n",
            "train Loss: 0.3604 Acc: 0.8454 F1 score: 0.8451 Precision: 0.8482 Recall: 0.8452 \n",
            "val Loss: 0.3477 Acc: 0.8385 F1 score: 0.8385 Precision: 0.8434 Recall: 0.8418 \n",
            "\n",
            "Epoch 11/19\n",
            "----------\n",
            "train Loss: 0.3611 Acc: 0.8434 F1 score: 0.8431 Precision: 0.8456 Recall: 0.8432 \n",
            "val Loss: 0.3456 Acc: 0.8367 F1 score: 0.8367 Precision: 0.8412 Recall: 0.8399 \n",
            "\n",
            "Epoch 12/19\n",
            "----------\n",
            "train Loss: 0.3604 Acc: 0.8438 F1 score: 0.8434 Precision: 0.8466 Recall: 0.8436 \n",
            "val Loss: 0.3446 Acc: 0.8367 F1 score: 0.8367 Precision: 0.8401 Recall: 0.8395 \n",
            "\n",
            "Epoch 13/19\n",
            "----------\n",
            "train Loss: 0.3618 Acc: 0.8432 F1 score: 0.8429 Precision: 0.8456 Recall: 0.8430 \n",
            "val Loss: 0.3453 Acc: 0.8349 F1 score: 0.8348 Precision: 0.8391 Recall: 0.8379 \n",
            "\n",
            "Epoch 14/19\n",
            "----------\n",
            "train Loss: 0.3567 Acc: 0.8477 F1 score: 0.8474 Precision: 0.8498 Recall: 0.8475 \n",
            "val Loss: 0.3475 Acc: 0.8349 F1 score: 0.8348 Precision: 0.8391 Recall: 0.8379 \n",
            "\n",
            "Epoch 15/19\n",
            "----------\n",
            "train Loss: 0.3618 Acc: 0.8397 F1 score: 0.8394 Precision: 0.8421 Recall: 0.8395 \n",
            "val Loss: 0.3458 Acc: 0.8349 F1 score: 0.8348 Precision: 0.8391 Recall: 0.8379 \n",
            "\n",
            "Epoch 16/19\n",
            "----------\n",
            "train Loss: 0.3557 Acc: 0.8426 F1 score: 0.8422 Precision: 0.8450 Recall: 0.8423 \n",
            "val Loss: 0.3465 Acc: 0.8349 F1 score: 0.8348 Precision: 0.8391 Recall: 0.8379 \n",
            "\n",
            "Epoch 17/19\n",
            "----------\n",
            "train Loss: 0.3547 Acc: 0.8446 F1 score: 0.8443 Precision: 0.8472 Recall: 0.8444 \n",
            "val Loss: 0.3459 Acc: 0.8349 F1 score: 0.8348 Precision: 0.8391 Recall: 0.8379 \n",
            "\n",
            "Epoch 18/19\n",
            "----------\n",
            "train Loss: 0.3574 Acc: 0.8467 F1 score: 0.8463 Precision: 0.8493 Recall: 0.8464 \n",
            "val Loss: 0.3457 Acc: 0.8367 F1 score: 0.8367 Precision: 0.8412 Recall: 0.8399 \n",
            "\n",
            "Epoch 19/19\n",
            "----------\n",
            "train Loss: 0.3569 Acc: 0.8387 F1 score: 0.8384 Precision: 0.8410 Recall: 0.8385 \n",
            "val Loss: 0.3454 Acc: 0.8367 F1 score: 0.8367 Precision: 0.8412 Recall: 0.8399 \n",
            "\n",
            "Training complete in 1m 27s\n",
            "Best val F1: 0.838505\n",
            "fold 8\n",
            "Epoch 0/19\n",
            "----------\n",
            "train Loss: 0.5514 Acc: 0.7111 F1 score: 0.7081 Precision: 0.7202 Recall: 0.7112 \n",
            "val Loss: 0.3981 Acc: 0.7872 F1 score: 0.7863 Precision: 0.7903 Recall: 0.7865 \n",
            "\n",
            "Epoch 1/19\n",
            "----------\n",
            "train Loss: 0.4507 Acc: 0.7842 F1 score: 0.7826 Precision: 0.7929 Recall: 0.7843 \n",
            "val Loss: 0.3606 Acc: 0.8000 F1 score: 0.7987 Precision: 0.8058 Recall: 0.7991 \n",
            "\n",
            "Epoch 2/19\n",
            "----------\n",
            "train Loss: 0.4116 Acc: 0.8108 F1 score: 0.8104 Precision: 0.8141 Recall: 0.8109 \n",
            "val Loss: 0.3577 Acc: 0.8092 F1 score: 0.8074 Precision: 0.8185 Recall: 0.8081 \n",
            "\n",
            "Epoch 3/19\n",
            "----------\n",
            "train Loss: 0.3913 Acc: 0.8231 F1 score: 0.8226 Precision: 0.8267 Recall: 0.8231 \n",
            "val Loss: 0.3424 Acc: 0.8349 F1 score: 0.8337 Precision: 0.8418 Recall: 0.8339 \n",
            "\n",
            "Epoch 4/19\n",
            "----------\n",
            "train Loss: 0.3851 Acc: 0.8292 F1 score: 0.8287 Precision: 0.8331 Recall: 0.8292 \n",
            "val Loss: 0.3376 Acc: 0.8349 F1 score: 0.8338 Precision: 0.8411 Recall: 0.8340 \n",
            "\n",
            "Epoch 5/19\n",
            "----------\n",
            "train Loss: 0.3795 Acc: 0.8308 F1 score: 0.8306 Precision: 0.8321 Recall: 0.8308 \n",
            "val Loss: 0.3383 Acc: 0.8275 F1 score: 0.8265 Precision: 0.8329 Recall: 0.8267 \n",
            "\n",
            "Epoch 6/19\n",
            "----------\n",
            "train Loss: 0.3775 Acc: 0.8310 F1 score: 0.8307 Precision: 0.8336 Recall: 0.8311 \n",
            "val Loss: 0.3366 Acc: 0.8312 F1 score: 0.8304 Precision: 0.8355 Recall: 0.8305 \n",
            "\n",
            "Epoch 7/19\n",
            "----------\n",
            "train Loss: 0.3685 Acc: 0.8351 F1 score: 0.8347 Precision: 0.8380 Recall: 0.8351 \n",
            "val Loss: 0.3366 Acc: 0.8330 F1 score: 0.8321 Precision: 0.8382 Recall: 0.8322 \n",
            "\n",
            "Epoch 8/19\n",
            "----------\n",
            "train Loss: 0.3662 Acc: 0.8446 F1 score: 0.8444 Precision: 0.8467 Recall: 0.8447 \n",
            "val Loss: 0.3352 Acc: 0.8294 F1 score: 0.8286 Precision: 0.8333 Recall: 0.8286 \n",
            "\n",
            "Epoch 9/19\n",
            "----------\n",
            "train Loss: 0.3598 Acc: 0.8404 F1 score: 0.8401 Precision: 0.8428 Recall: 0.8404 \n",
            "val Loss: 0.3350 Acc: 0.8239 F1 score: 0.8231 Precision: 0.8275 Recall: 0.8232 \n",
            "\n",
            "Epoch 10/19\n",
            "----------\n",
            "train Loss: 0.3607 Acc: 0.8406 F1 score: 0.8403 Precision: 0.8432 Recall: 0.8406 \n",
            "val Loss: 0.3350 Acc: 0.8312 F1 score: 0.8304 Precision: 0.8355 Recall: 0.8305 \n",
            "\n",
            "Epoch 11/19\n",
            "----------\n",
            "train Loss: 0.3614 Acc: 0.8414 F1 score: 0.8412 Precision: 0.8433 Recall: 0.8414 \n",
            "val Loss: 0.3365 Acc: 0.8312 F1 score: 0.8303 Precision: 0.8361 Recall: 0.8304 \n",
            "\n",
            "Epoch 12/19\n",
            "----------\n",
            "train Loss: 0.3588 Acc: 0.8434 F1 score: 0.8432 Precision: 0.8458 Recall: 0.8435 \n",
            "val Loss: 0.3355 Acc: 0.8257 F1 score: 0.8248 Precision: 0.8302 Recall: 0.8249 \n",
            "\n",
            "Epoch 13/19\n",
            "----------\n",
            "train Loss: 0.3611 Acc: 0.8422 F1 score: 0.8419 Precision: 0.8449 Recall: 0.8423 \n",
            "val Loss: 0.3360 Acc: 0.8294 F1 score: 0.8285 Precision: 0.8339 Recall: 0.8286 \n",
            "\n",
            "Epoch 14/19\n",
            "----------\n",
            "train Loss: 0.3560 Acc: 0.8444 F1 score: 0.8443 Precision: 0.8461 Recall: 0.8445 \n",
            "val Loss: 0.3351 Acc: 0.8330 F1 score: 0.8323 Precision: 0.8371 Recall: 0.8323 \n",
            "\n",
            "Epoch 15/19\n",
            "----------\n",
            "train Loss: 0.3542 Acc: 0.8448 F1 score: 0.8446 Precision: 0.8474 Recall: 0.8449 \n",
            "val Loss: 0.3360 Acc: 0.8275 F1 score: 0.8266 Precision: 0.8323 Recall: 0.8267 \n",
            "\n",
            "Epoch 16/19\n",
            "----------\n",
            "train Loss: 0.3589 Acc: 0.8408 F1 score: 0.8405 Precision: 0.8428 Recall: 0.8408 \n",
            "val Loss: 0.3348 Acc: 0.8330 F1 score: 0.8323 Precision: 0.8371 Recall: 0.8323 \n",
            "\n",
            "Epoch 17/19\n",
            "----------\n",
            "train Loss: 0.3558 Acc: 0.8452 F1 score: 0.8450 Precision: 0.8474 Recall: 0.8453 \n",
            "val Loss: 0.3358 Acc: 0.8294 F1 score: 0.8285 Precision: 0.8339 Recall: 0.8286 \n",
            "\n",
            "Epoch 18/19\n",
            "----------\n",
            "train Loss: 0.3583 Acc: 0.8432 F1 score: 0.8429 Precision: 0.8458 Recall: 0.8433 \n",
            "val Loss: 0.3368 Acc: 0.8275 F1 score: 0.8265 Precision: 0.8329 Recall: 0.8267 \n",
            "\n",
            "Epoch 19/19\n",
            "----------\n",
            "train Loss: 0.3541 Acc: 0.8481 F1 score: 0.8479 Precision: 0.8504 Recall: 0.8482 \n",
            "val Loss: 0.3362 Acc: 0.8275 F1 score: 0.8266 Precision: 0.8323 Recall: 0.8267 \n",
            "\n",
            "Training complete in 1m 27s\n",
            "Best val F1: 0.833828\n",
            "fold 9\n",
            "Epoch 0/19\n",
            "----------\n",
            "train Loss: 0.5572 Acc: 0.7045 F1 score: 0.7039 Precision: 0.7065 Recall: 0.7046 \n",
            "val Loss: 0.4319 Acc: 0.7615 F1 score: 0.7614 Precision: 0.7615 Recall: 0.7615 \n",
            "\n",
            "Epoch 1/19\n",
            "----------\n",
            "train Loss: 0.4539 Acc: 0.7905 F1 score: 0.7893 Precision: 0.7975 Recall: 0.7906 \n",
            "val Loss: 0.3839 Acc: 0.8037 F1 score: 0.8034 Precision: 0.8042 Recall: 0.8033 \n",
            "\n",
            "Epoch 2/19\n",
            "----------\n",
            "train Loss: 0.4125 Acc: 0.8102 F1 score: 0.8095 Precision: 0.8153 Recall: 0.8103 \n",
            "val Loss: 0.3709 Acc: 0.8165 F1 score: 0.8143 Precision: 0.8280 Recall: 0.8149 \n",
            "\n",
            "Epoch 3/19\n",
            "----------\n",
            "train Loss: 0.3897 Acc: 0.8267 F1 score: 0.8262 Precision: 0.8311 Recall: 0.8268 \n",
            "val Loss: 0.3521 Acc: 0.8385 F1 score: 0.8380 Precision: 0.8410 Recall: 0.8378 \n",
            "\n",
            "Epoch 4/19\n",
            "----------\n",
            "train Loss: 0.3881 Acc: 0.8243 F1 score: 0.8239 Precision: 0.8274 Recall: 0.8244 \n",
            "val Loss: 0.3531 Acc: 0.8312 F1 score: 0.8303 Precision: 0.8355 Recall: 0.8302 \n",
            "\n",
            "Epoch 5/19\n",
            "----------\n",
            "train Loss: 0.3774 Acc: 0.8322 F1 score: 0.8318 Precision: 0.8359 Recall: 0.8323 \n",
            "val Loss: 0.3510 Acc: 0.8367 F1 score: 0.8361 Precision: 0.8393 Recall: 0.8360 \n",
            "\n",
            "Epoch 6/19\n",
            "----------\n",
            "train Loss: 0.3678 Acc: 0.8355 F1 score: 0.8352 Precision: 0.8382 Recall: 0.8356 \n",
            "val Loss: 0.3560 Acc: 0.8220 F1 score: 0.8203 Precision: 0.8315 Recall: 0.8206 \n",
            "\n",
            "Epoch 7/19\n",
            "----------\n",
            "train Loss: 0.3636 Acc: 0.8402 F1 score: 0.8398 Precision: 0.8432 Recall: 0.8402 \n",
            "val Loss: 0.3493 Acc: 0.8367 F1 score: 0.8361 Precision: 0.8398 Recall: 0.8359 \n",
            "\n",
            "Epoch 8/19\n",
            "----------\n",
            "train Loss: 0.3614 Acc: 0.8369 F1 score: 0.8366 Precision: 0.8395 Recall: 0.8370 \n",
            "val Loss: 0.3483 Acc: 0.8422 F1 score: 0.8417 Precision: 0.8447 Recall: 0.8415 \n",
            "\n",
            "Epoch 9/19\n",
            "----------\n",
            "train Loss: 0.3609 Acc: 0.8457 F1 score: 0.8454 Precision: 0.8484 Recall: 0.8457 \n",
            "val Loss: 0.3487 Acc: 0.8440 F1 score: 0.8436 Precision: 0.8459 Recall: 0.8434 \n",
            "\n",
            "Epoch 10/19\n",
            "----------\n",
            "train Loss: 0.3574 Acc: 0.8377 F1 score: 0.8374 Precision: 0.8401 Recall: 0.8378 \n",
            "val Loss: 0.3494 Acc: 0.8330 F1 score: 0.8324 Precision: 0.8356 Recall: 0.8323 \n",
            "\n",
            "Epoch 11/19\n",
            "----------\n",
            "train Loss: 0.3597 Acc: 0.8416 F1 score: 0.8413 Precision: 0.8446 Recall: 0.8417 \n",
            "val Loss: 0.3506 Acc: 0.8330 F1 score: 0.8323 Precision: 0.8366 Recall: 0.8322 \n",
            "\n",
            "Epoch 12/19\n",
            "----------\n",
            "train Loss: 0.3570 Acc: 0.8418 F1 score: 0.8415 Precision: 0.8442 Recall: 0.8419 \n",
            "val Loss: 0.3496 Acc: 0.8330 F1 score: 0.8324 Precision: 0.8356 Recall: 0.8323 \n",
            "\n",
            "Epoch 13/19\n",
            "----------\n",
            "train Loss: 0.3557 Acc: 0.8436 F1 score: 0.8434 Precision: 0.8461 Recall: 0.8437 \n",
            "val Loss: 0.3503 Acc: 0.8312 F1 score: 0.8305 Precision: 0.8345 Recall: 0.8304 \n",
            "\n",
            "Epoch 14/19\n",
            "----------\n",
            "train Loss: 0.3563 Acc: 0.8434 F1 score: 0.8432 Precision: 0.8458 Recall: 0.8435 \n",
            "val Loss: 0.3501 Acc: 0.8385 F1 score: 0.8381 Precision: 0.8405 Recall: 0.8379 \n",
            "\n",
            "Epoch 15/19\n",
            "----------\n",
            "train Loss: 0.3555 Acc: 0.8422 F1 score: 0.8419 Precision: 0.8449 Recall: 0.8423 \n",
            "val Loss: 0.3504 Acc: 0.8349 F1 score: 0.8343 Precision: 0.8372 Recall: 0.8342 \n",
            "\n",
            "Epoch 16/19\n",
            "----------\n",
            "train Loss: 0.3534 Acc: 0.8463 F1 score: 0.8460 Precision: 0.8490 Recall: 0.8463 \n",
            "val Loss: 0.3502 Acc: 0.8349 F1 score: 0.8343 Precision: 0.8372 Recall: 0.8342 \n",
            "\n",
            "Epoch 17/19\n",
            "----------\n",
            "train Loss: 0.3543 Acc: 0.8463 F1 score: 0.8460 Precision: 0.8491 Recall: 0.8463 \n",
            "val Loss: 0.3504 Acc: 0.8349 F1 score: 0.8343 Precision: 0.8372 Recall: 0.8342 \n",
            "\n",
            "Epoch 18/19\n",
            "----------\n",
            "train Loss: 0.3561 Acc: 0.8434 F1 score: 0.8431 Precision: 0.8459 Recall: 0.8435 \n",
            "val Loss: 0.3498 Acc: 0.8367 F1 score: 0.8363 Precision: 0.8385 Recall: 0.8361 \n",
            "\n",
            "Epoch 19/19\n",
            "----------\n",
            "train Loss: 0.3520 Acc: 0.8467 F1 score: 0.8464 Precision: 0.8495 Recall: 0.8468 \n",
            "val Loss: 0.3502 Acc: 0.8404 F1 score: 0.8399 Precision: 0.8422 Recall: 0.8397 \n",
            "\n",
            "Training complete in 1m 27s\n",
            "Best val F1: 0.843624\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bI4C631JqEz9"
      },
      "source": [
        "Across all folds we get around 0.8391 F1-score for 2 years prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tW91jikCNoIC"
      },
      "source": [
        "# Finding what groups are more prone to."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHoJyXQJNtSl"
      },
      "source": [
        "first we train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PAHYmuXbc-Pr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ee5cd9f-4bd0-436b-8275-bbe6269e3307"
      },
      "source": [
        "model = Model()\n",
        "model = model.to(device)\n",
        "lr=0.005\n",
        "optimizer = optim.Adam(model.parameters(),lr=lr)\n",
        "criterion = nn.BCELoss()\n",
        "scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "dataloaders10 = create_dataloaders(label_type =10, scase=False)\n",
        "model = train_model(model, dataloaders10, criterion, optimizer, scheduler, num_epochs=20)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/19\n",
            "----------\n",
            "train Loss: 0.3873 Acc: 0.8366 F1 score: 0.6560 Precision: 0.6644 Recall: 0.6491 \n",
            "val Loss: 0.2843 Acc: 0.8880 F1 score: 0.7406 Precision: 0.7931 Recall: 0.7096 \n",
            "\n",
            "Epoch 1/19\n",
            "----------\n",
            "train Loss: 0.2968 Acc: 0.8884 F1 score: 0.7322 Precision: 0.7983 Recall: 0.6974 \n",
            "val Loss: 0.2687 Acc: 0.8960 F1 score: 0.7627 Precision: 0.8121 Recall: 0.7317 \n",
            "\n",
            "Epoch 2/19\n",
            "----------\n",
            "train Loss: 0.2902 Acc: 0.8901 F1 score: 0.7413 Precision: 0.7991 Recall: 0.7084 \n",
            "val Loss: 0.2683 Acc: 0.8952 F1 score: 0.7446 Precision: 0.8276 Recall: 0.7041 \n",
            "\n",
            "Epoch 3/19\n",
            "----------\n",
            "train Loss: 0.2893 Acc: 0.8898 F1 score: 0.7367 Precision: 0.8013 Recall: 0.7019 \n",
            "val Loss: 0.2655 Acc: 0.8963 F1 score: 0.7461 Precision: 0.8324 Recall: 0.7047 \n",
            "\n",
            "Epoch 4/19\n",
            "----------\n",
            "train Loss: 0.2875 Acc: 0.8913 F1 score: 0.7351 Precision: 0.8110 Recall: 0.6973 \n",
            "val Loss: 0.2681 Acc: 0.8976 F1 score: 0.7429 Precision: 0.8466 Recall: 0.6979 \n",
            "\n",
            "Epoch 5/19\n",
            "----------\n",
            "train Loss: 0.2871 Acc: 0.8918 F1 score: 0.7382 Precision: 0.8108 Recall: 0.7011 \n",
            "val Loss: 0.2694 Acc: 0.8981 F1 score: 0.7510 Precision: 0.8381 Recall: 0.7088 \n",
            "\n",
            "Epoch 6/19\n",
            "----------\n",
            "train Loss: 0.2839 Acc: 0.8917 F1 score: 0.7361 Precision: 0.8122 Recall: 0.6981 \n",
            "val Loss: 0.2679 Acc: 0.8963 F1 score: 0.7404 Precision: 0.8407 Recall: 0.6964 \n",
            "\n",
            "Epoch 7/19\n",
            "----------\n",
            "train Loss: 0.2792 Acc: 0.8943 F1 score: 0.7448 Precision: 0.8174 Recall: 0.7070 \n",
            "val Loss: 0.2672 Acc: 0.8968 F1 score: 0.7422 Precision: 0.8417 Recall: 0.6982 \n",
            "\n",
            "Epoch 8/19\n",
            "----------\n",
            "train Loss: 0.2788 Acc: 0.8946 F1 score: 0.7439 Precision: 0.8204 Recall: 0.7051 \n",
            "val Loss: 0.2681 Acc: 0.8957 F1 score: 0.7357 Precision: 0.8439 Recall: 0.6908 \n",
            "\n",
            "Epoch 9/19\n",
            "----------\n",
            "train Loss: 0.2786 Acc: 0.8932 F1 score: 0.7430 Precision: 0.8133 Recall: 0.7060 \n",
            "val Loss: 0.2658 Acc: 0.8965 F1 score: 0.7460 Precision: 0.8343 Recall: 0.7041 \n",
            "\n",
            "Epoch 10/19\n",
            "----------\n",
            "train Loss: 0.2783 Acc: 0.8925 F1 score: 0.7375 Precision: 0.8153 Recall: 0.6990 \n",
            "val Loss: 0.2656 Acc: 0.8984 F1 score: 0.7543 Precision: 0.8351 Recall: 0.7135 \n",
            "\n",
            "Epoch 11/19\n",
            "----------\n",
            "train Loss: 0.2761 Acc: 0.8926 F1 score: 0.7406 Precision: 0.8129 Recall: 0.7032 \n",
            "val Loss: 0.2651 Acc: 0.8992 F1 score: 0.7551 Precision: 0.8394 Recall: 0.7132 \n",
            "\n",
            "Epoch 12/19\n",
            "----------\n",
            "train Loss: 0.2765 Acc: 0.8953 F1 score: 0.7473 Precision: 0.8209 Recall: 0.7090 \n",
            "val Loss: 0.2668 Acc: 0.8992 F1 score: 0.7516 Precision: 0.8446 Recall: 0.7079 \n",
            "\n",
            "Epoch 13/19\n",
            "----------\n",
            "train Loss: 0.2768 Acc: 0.8929 F1 score: 0.7434 Precision: 0.8115 Recall: 0.7070 \n",
            "val Loss: 0.2689 Acc: 0.8963 F1 score: 0.7376 Precision: 0.8449 Recall: 0.6926 \n",
            "\n",
            "Epoch 14/19\n",
            "----------\n",
            "train Loss: 0.2752 Acc: 0.8942 F1 score: 0.7436 Precision: 0.8184 Recall: 0.7053 \n",
            "val Loss: 0.2670 Acc: 0.8981 F1 score: 0.7464 Precision: 0.8450 Recall: 0.7020 \n",
            "\n",
            "Epoch 15/19\n",
            "----------\n",
            "train Loss: 0.2753 Acc: 0.8934 F1 score: 0.7424 Precision: 0.8155 Recall: 0.7047 \n",
            "val Loss: 0.2673 Acc: 0.8976 F1 score: 0.7424 Precision: 0.8475 Recall: 0.6972 \n",
            "\n",
            "Epoch 16/19\n",
            "----------\n",
            "train Loss: 0.2767 Acc: 0.8937 F1 score: 0.7440 Precision: 0.8152 Recall: 0.7067 \n",
            "val Loss: 0.2677 Acc: 0.8968 F1 score: 0.7412 Precision: 0.8434 Recall: 0.6967 \n",
            "\n",
            "Epoch 17/19\n",
            "----------\n",
            "train Loss: 0.2769 Acc: 0.8932 F1 score: 0.7430 Precision: 0.8137 Recall: 0.7059 \n",
            "val Loss: 0.2671 Acc: 0.8981 F1 score: 0.7469 Precision: 0.8442 Recall: 0.7028 \n",
            "\n",
            "Epoch 18/19\n",
            "----------\n",
            "train Loss: 0.2776 Acc: 0.8923 F1 score: 0.7398 Precision: 0.8118 Recall: 0.7027 \n",
            "val Loss: 0.2678 Acc: 0.8968 F1 score: 0.7412 Precision: 0.8434 Recall: 0.6967 \n",
            "\n",
            "Epoch 19/19\n",
            "----------\n",
            "train Loss: 0.2762 Acc: 0.8943 F1 score: 0.7440 Precision: 0.8187 Recall: 0.7057 \n",
            "val Loss: 0.2655 Acc: 0.8989 F1 score: 0.7542 Precision: 0.8389 Recall: 0.7123 \n",
            "\n",
            "Training complete in 7m 14s\n",
            "Best val F1: 0.762696\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqhx7zOJsFJR"
      },
      "source": [
        "Save the input data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3i5fbc9fNroB"
      },
      "source": [
        "train, test = split_df_train_test_val(grdf10)\n",
        "test = test.drop(['IDS'],axis=1) #ID are not relevant\n",
        "dataTest = DataforSet(test, '10_years')\n",
        "\n",
        "test_data = DataLoader(dataTest, batch_size=len(dataTest), shuffle=True)"
      ],
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZdQW54fQWDD",
        "outputId": "a76be0bc-4eea-4d72-91c5-bf2789ee9cf0"
      },
      "source": [
        "ig = IntegratedGradients(model)\n",
        "\n",
        "for cont, cat0, cat1, cat2, _ in test_data:\n",
        "  break\n",
        "cont.requires_grad_()\n",
        "cat0.requires_grad_()\n",
        "cat1.requires_grad_()\n",
        "cat2.requires_grad_()"
      ],
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 1., 0.,  ..., 1., 1., 1.], dtype=torch.float64, requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXZ6OlABQqn2"
      },
      "source": [
        "attr, delta = ig.attribute(cont, additional_forward_args=(cat0, cat1, cat2),target=0, return_convergence_delta=True)\n",
        "attr = attr.detach().numpy()"
      ],
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 709
        },
        "id": "vFmb2Qq9Rau9",
        "outputId": "ab6b0d09-d305-43bc-b415-452a38afbd8b"
      },
      "source": [
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "font = {'family' : 'DejaVu Sans',\n",
        "        'weight' : 'bold',\n",
        "        'size'   : 5}\n",
        "\n",
        "matplotlib.rc('font', **font)\n",
        "\n",
        "def visualize_importances(feature_names, importances, title=\"Average Feature Importances\", plot=True, axis_title=\"Features\"):\n",
        "    print(title)\n",
        "    for i in range(len(feature_names)):\n",
        "        print(feature_names[i], \": \", '%.3f'%(importances[i]))\n",
        "    x_pos = (np.arange(len(feature_names)))\n",
        "    if plot:\n",
        "        plt.figure(figsize=(27,6))\n",
        "        plt.bar(x_pos, importances, align='center')\n",
        "        plt.xticks(x_pos, feature_names, wrap=True)\n",
        "        plt.xlabel(axis_title)\n",
        "        plt.title(title)\n",
        "feature_names = [name for name in nums.columns[1:-3]]\n",
        "visualize_importances(feature_names, np.mean(attr, axis=0))"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Feature Importances\n",
            "IS_MALE :  0.001\n",
            "AGE_AT_SDATE :  0.007\n",
            "IS_HYPERTENSION :  -0.002\n",
            "IS_ISCHEMIC_MI :  -0.001\n",
            "IS_CVA_TIA :  -0.000\n",
            "IS_DEMENTIA :  0.001\n",
            "IS_ART_SCLE_GEN :  0.000\n",
            "IS_TROMBOPHILIA :  0.000\n",
            "IS_IBD :  0.000\n",
            "BMI_AT_BASELINE :  0.003\n",
            "SYSTOLA_AT_BASELINE :  0.002\n",
            "DIASTOLA_AT_BASELINE :  -0.001\n",
            "Creatinine_B_AT_BASELINE :  0.088\n",
            "Albumin_B_AT_BASELINE :  -0.005\n",
            "Urea_B_AT_BASELINE :  0.056\n",
            "Glucose_B_AT_BASELINE :  -0.000\n",
            "HbA1C_AT_BASELINE :  0.000\n",
            "RBCRed_Blood_Cells_AT_BASELINE :  -0.001\n",
            "Hemoglobin_AT_BASELINE :  -0.015\n",
            "AST_GOT_AT_BASELINE :  0.001\n",
            "ALT_GPT_AT_BASELINE :  -0.002\n",
            "Na_Sodium_B_AT_BASELINE :  -0.014\n",
            "K_Potassium_B_AT_BASELINE :  0.001\n",
            "CaCalcium_B_AT_BASELINE :  -0.001\n",
            "HDLCholesterol_AT_BASELINE :  -0.001\n",
            "LDLCholesterol_AT_BASELINE :  -0.011\n",
            "Triglycerides_AT_BASELINE :  0.001\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1944x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brp5V01HbTpp"
      },
      "source": [
        "It seems that Creatanine in the blood is the most correlated for this case,  after that Urea in the blood and then Sodium and Hemoglobin in the blood"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0_5aG3FbP4_"
      },
      "source": [
        "cond = LayerConductance(model, model.seq[5])\n",
        "cond_vals = cond.attribute((cont, cat0, cat1, cat2),target=0)\n",
        "cond_vals = cond_vals.detach().numpy()"
      ],
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 674
        },
        "id": "jPUbAjFfZmlv",
        "outputId": "9c196261-f1f2-4fca-906c-5666a8b7d1a1"
      },
      "source": [
        "visualize_importances(range(25),np.mean(cond_vals, axis=0),title=\"Average Neuron Importances\", axis_title=\"Neurons\")"
      ],
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Neuron Importances\n",
            "0 :  0.007\n",
            "1 :  0.003\n",
            "2 :  0.002\n",
            "3 :  0.002\n",
            "4 :  0.003\n",
            "5 :  0.006\n",
            "6 :  -0.000\n",
            "7 :  -0.000\n",
            "8 :  0.000\n",
            "9 :  0.000\n",
            "10 :  -0.000\n",
            "11 :  0.010\n",
            "12 :  -0.002\n",
            "13 :  0.011\n",
            "14 :  -0.001\n",
            "15 :  0.006\n",
            "16 :  0.012\n",
            "17 :  0.001\n",
            "18 :  0.001\n",
            "19 :  0.008\n",
            "20 :  -0.002\n",
            "21 :  0.009\n",
            "22 :  0.010\n",
            "23 :  0.000\n",
            "24 :  0.024\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1944x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StrLKa8wo4yj"
      },
      "source": [
        "We see that the last Neuron is the most meaningfull"
      ]
    }
  ]
}